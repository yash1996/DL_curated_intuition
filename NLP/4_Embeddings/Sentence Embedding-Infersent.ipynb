{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quora question pairs-kaggle\n",
    "df = pd.read_csv(\"/home/uv/Downloads/train.csv\",nrows=1000)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
       "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>Should I buy tiago?</td>\n",
       "      <td>What keeps childern active and far from phone ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>How can I be a good geologist?</td>\n",
       "      <td>What should I do to be a great geologist?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>When do you use シ instead of し?</td>\n",
       "      <td>When do you use \"&amp;\" instead of \"and\"?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>Motorola (company): Can I hack my Charter Moto...</td>\n",
       "      <td>How do I hack Motorola DCX3400 for free internet?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "5   5    11    12  Astrology: I am a Capricorn Sun Cap moon and c...   \n",
       "6   6    13    14                                Should I buy tiago?   \n",
       "7   7    15    16                     How can I be a good geologist?   \n",
       "8   8    17    18                    When do you use シ instead of し?   \n",
       "9   9    19    20  Motorola (company): Can I hack my Charter Moto...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  \n",
       "5  I'm a triple Capricorn (Sun, Moon and ascendan...             1  \n",
       "6  What keeps childern active and far from phone ...             0  \n",
       "7          What should I do to be a great geologist?             1  \n",
       "8              When do you use \"&\" instead of \"and\"?             0  \n",
       "9  How do I hack Motorola DCX3400 for free internet?             0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infersent Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferSent(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(InferSent, self).__init__()\n",
    "        self.bsize = config['bsize']\n",
    "        self.word_emb_dim = config['word_emb_dim']\n",
    "        self.enc_lstm_dim = config['enc_lstm_dim']\n",
    "        self.pool_type = config['pool_type']\n",
    "        self.dpout_model = config['dpout_model']\n",
    "        self.version = 1 if 'version' not in config else config['version']\n",
    "\n",
    "        self.enc_lstm = nn.LSTM(self.word_emb_dim, self.enc_lstm_dim, 1,\n",
    "                                bidirectional=True, dropout=self.dpout_model)\n",
    "\n",
    "        assert self.version in [1, 2]\n",
    "        if self.version == 1:\n",
    "            self.bos = '<s>'\n",
    "            self.eos = '</s>'\n",
    "            self.max_pad = True\n",
    "            self.moses_tok = False\n",
    "        elif self.version == 2:\n",
    "            self.bos = '<p>'\n",
    "            self.eos = '</p>'\n",
    "            self.max_pad = False\n",
    "            self.moses_tok = True\n",
    "\n",
    "    def is_cuda(self):\n",
    "        # either all weights are on cpu or they are on gpu\n",
    "        return self.enc_lstm.bias_hh_l0.data.is_cuda\n",
    "\n",
    "    def forward(self, sent_tuple):\n",
    "        # sent_len: [max_len, ..., min_len] (bsize)\n",
    "        # sent: (seqlen x bsize x worddim)\n",
    "        sent, sent_len = sent_tuple\n",
    "        print(sent.shape,sent_len.shape)\n",
    "        # Sort by length (keep idx)\n",
    "        sent_len_sorted, idx_sort = np.sort(sent_len)[::-1], np.argsort(-sent_len)\n",
    "        sent_len_sorted = sent_len_sorted.copy()\n",
    "        idx_unsort = np.argsort(idx_sort)\n",
    "\n",
    "        idx_sort = torch.from_numpy(idx_sort).cuda() if self.is_cuda() \\\n",
    "            else torch.from_numpy(idx_sort)\n",
    "        sent = sent.index_select(1, idx_sort)\n",
    "\n",
    "        # Handling padding in Recurrent Networks\n",
    "        sent_packed = nn.utils.rnn.pack_padded_sequence(sent, sent_len_sorted)\n",
    "        print(\"sentpacked\",sent_packed)\n",
    "        print(\"sent_sorted\",sent_len_sorted)\n",
    "        sent_output = self.enc_lstm(sent_packed)[0]  # seqlen x batch x 2*nhid\n",
    "        sent_output = nn.utils.rnn.pad_packed_sequence(sent_output)[0]\n",
    "\n",
    "        # Un-sort by length\n",
    "        idx_unsort = torch.from_numpy(idx_unsort).cuda() if self.is_cuda() \\\n",
    "            else torch.from_numpy(idx_unsort)\n",
    "        sent_output = sent_output.index_select(1, idx_unsort)\n",
    "        print(\"sent_output\",sent_output.shape)\n",
    "\n",
    "        # Pooling\n",
    "        if self.pool_type == \"mean\":\n",
    "            sent_len = torch.FloatTensor(sent_len.copy()).unsqueeze(1).cuda()\n",
    "            emb = torch.sum(sent_output, 0).squeeze(0)\n",
    "            emb = emb / sent_len.expand_as(emb)\n",
    "        elif self.pool_type == \"max\":\n",
    "            if not self.max_pad:\n",
    "                sent_output[sent_output == 0] = -1e9\n",
    "            emb = torch.max(sent_output, 0)[0]\n",
    "            if emb.ndimension() == 3:\n",
    "                emb = emb.squeeze(0)\n",
    "                assert emb.ndimension() == 2\n",
    "\n",
    "        return emb\n",
    "\n",
    "    def set_w2v_path(self, w2v_path):\n",
    "        self.w2v_path = w2v_path\n",
    "\n",
    "    def get_word_dict(self, sentences, tokenize=True):\n",
    "        # create vocab of words\n",
    "        word_dict = {}\n",
    "        sentences = [s.split() if not tokenize else self.tokenize(s) for s in sentences]\n",
    "        print(\"sentences after tokenization\",sentences)\n",
    "        for sent in sentences:\n",
    "            for word in sent:\n",
    "                if word not in word_dict:\n",
    "                    word_dict[word] = ''\n",
    "        word_dict[self.bos] = ''\n",
    "        word_dict[self.eos] = ''\n",
    "        return word_dict\n",
    "\n",
    "    def get_w2v(self, word_dict):\n",
    "        assert hasattr(self, 'w2v_path'), 'w2v path not set'\n",
    "        # create word_vec with w2v vectors\n",
    "        word_vec = {}\n",
    "        with open(self.w2v_path, encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                word, vec = line.split(' ', 1)\n",
    "                if word in word_dict:\n",
    "                    word_vec[word] = np.fromstring(vec, sep=' ')\n",
    "        print('Found %s(/%s) words with w2v vectors' % (len(word_vec), len(word_dict)))\n",
    "        print(\"word_vec\",word_vec.keys())\n",
    "        return word_vec\n",
    "\n",
    "    def get_w2v_k(self, K):\n",
    "        assert hasattr(self, 'w2v_path'), 'w2v path not set'\n",
    "        # create word_vec with k first w2v vectors\n",
    "        k = 0\n",
    "        word_vec = {}\n",
    "        with open(self.w2v_path, encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                word, vec = line.split(' ', 1)\n",
    "                if k <= K:\n",
    "                    word_vec[word] = np.fromstring(vec, sep=' ')\n",
    "                    k += 1\n",
    "                if k > K:\n",
    "                    if word in [self.bos, self.eos]:\n",
    "                        word_vec[word] = np.fromstring(vec, sep=' ')\n",
    "\n",
    "                if k > K and all([w in word_vec for w in [self.bos, self.eos]]):\n",
    "                    break\n",
    "        return word_vec\n",
    "\n",
    "    def build_vocab(self, sentences, tokenize=True):\n",
    "        assert hasattr(self, 'w2v_path'), 'w2v path not set'\n",
    "        word_dict = self.get_word_dict(sentences, tokenize)\n",
    "        self.word_vec = self.get_w2v(word_dict)\n",
    "        print('Vocab size : %s' % (len(self.word_vec)))\n",
    "        #print(self.word_vec)\n",
    "\n",
    "    # build w2v vocab with k most frequent words\n",
    "    def build_vocab_k_words(self, K):\n",
    "        assert hasattr(self, 'w2v_path'), 'w2v path not set'\n",
    "        self.word_vec = self.get_w2v_k(K)\n",
    "        print('Vocab size : %s' % (K))\n",
    "\n",
    "    def update_vocab(self, sentences, tokenize=True):\n",
    "        assert hasattr(self, 'w2v_path'), 'warning : w2v path not set'\n",
    "        assert hasattr(self, 'word_vec'), 'build_vocab before updating it'\n",
    "        word_dict = self.get_word_dict(sentences, tokenize)\n",
    "\n",
    "#         # keep only new words\n",
    "#         for word in self.word_vec:\n",
    "#             if word in word_dict:\n",
    "#                 del word_dict[word]\n",
    "\n",
    "        # udpate vocabulary\n",
    "        if word_dict:\n",
    "            new_word_vec = self.get_w2v(word_dict)\n",
    "            self.word_vec.update(new_word_vec)\n",
    "        else:\n",
    "            new_word_vec = []\n",
    "        print('New vocab size : %s (added %s words)'% (len(self.word_vec), len(new_word_vec)))\n",
    "\n",
    "    def get_batch(self, batch):\n",
    "        # sent in batch in decreasing order of lengths\n",
    "        # batch: (bsize, max_len, word_dim)\n",
    "        embed = np.zeros((len(batch[0]), len(batch), self.word_emb_dim))\n",
    "        print(\"embed\",embed.shape)\n",
    "        for i in range(len(batch)):\n",
    "            for j in range(len(batch[i])):\n",
    "                embed[j, i, :] = self.word_vec[batch[i][j]]\n",
    "\n",
    "        return torch.FloatTensor(embed)\n",
    "\n",
    "    def tokenize(self, s):\n",
    "        from nltk.tokenize import word_tokenize\n",
    "        if self.moses_tok:\n",
    "            s = ' '.join(word_tokenize(s))\n",
    "            s = s.replace(\" n't \", \"n 't \")  # HACK to get ~MOSES tokenization\n",
    "            return s.split()\n",
    "        else:\n",
    "            return word_tokenize(s)\n",
    "\n",
    "    def prepare_samples(self, sentences, bsize, tokenize, verbose):\n",
    "        sentences = [[self.bos] + s.split() + [self.eos] if not tokenize else\n",
    "                     [self.bos] + self.tokenize(s) + [self.eos] for s in sentences]\n",
    "        n_w = np.sum([len(x) for x in sentences])\n",
    "\n",
    "        # filters words without w2v vectors\n",
    "        for i in range(len(sentences)):\n",
    "            s_f = [word for word in sentences[i] if word in self.word_vec]\n",
    "            if not s_f:\n",
    "                import warnings\n",
    "                warnings.warn('No words in \"%s\" (idx=%s) have w2v vectors. \\\n",
    "                               Replacing by \"</s>\"..' % (sentences[i], i))\n",
    "                s_f = [self.eos]\n",
    "            sentences[i] = s_f\n",
    "\n",
    "        lengths = np.array([len(s) for s in sentences])\n",
    "        n_wk = np.sum(lengths)\n",
    "        if verbose:\n",
    "            print('Nb words kept : %s/%s (%.1f%s)' % (\n",
    "                        n_wk, n_w, 100.0 * n_wk / n_w, '%'))\n",
    "\n",
    "        # sort by decreasing length\n",
    "        lengths, idx_sort = np.sort(lengths)[::-1], np.argsort(-lengths)\n",
    "        sentences = np.array(sentences)[idx_sort]\n",
    "\n",
    "        return sentences, lengths, idx_sort\n",
    "\n",
    "    def encode(self, sentences, bsize=64, tokenize=True, verbose=False):\n",
    "        tic = time.time()\n",
    "        sentences, lengths, idx_sort = self.prepare_samples(\n",
    "                        sentences, bsize, tokenize, verbose)   #[[sentense1_tokens],[\"sentense_2_tokens\"]]\n",
    "                                                               # [sent1_len,sent2_len]\n",
    "                                                               # [flagofsentence]\n",
    "\n",
    "        print(f\"Sentences:{sentences}, length{lengths},idx_sort{idx_sort}\")\n",
    "        embeddings = []\n",
    "        for stidx in range(0, len(sentences), bsize):\n",
    "            print(\"stidx\",stidx)\n",
    "            print(\"before_get_batch\",sentences[stidx:stidx + bsize])\n",
    "            batch = self.get_batch(sentences[stidx:stidx + bsize])\n",
    "            print(\"batch\",batch,batch.shape)\n",
    "            if self.is_cuda():\n",
    "                batch = batch.cuda()\n",
    "            with torch.no_grad():\n",
    "                batch = self.forward((batch, lengths[stidx:stidx + bsize])).data.cpu().numpy()\n",
    "                print(batch.shape)\n",
    "            embeddings.append(batch)\n",
    "        embeddings = np.vstack(embeddings)\n",
    "\n",
    "        # unsort\n",
    "        idx_unsort = np.argsort(idx_sort)\n",
    "        embeddings = embeddings[idx_unsort]\n",
    "\n",
    "        if verbose:\n",
    "            print('Speed : %.1f sentences/s (%s mode, bsize=%s)' % (\n",
    "                    len(embeddings)/(time.time()-tic),\n",
    "                    'gpu' if self.is_cuda() else 'cpu', bsize))\n",
    "        return embeddings\n",
    "\n",
    "    def visualize(self, sent, tokenize=True):\n",
    "\n",
    "        sent = sent.split() if not tokenize else self.tokenize(sent)\n",
    "        sent = [[self.bos] + [word for word in sent if word in self.word_vec] + [self.eos]]\n",
    "\n",
    "        if ' '.join(sent[0]) == '%s %s' % (self.bos, self.eos):\n",
    "            import warnings\n",
    "            warnings.warn('No words in \"%s\" have w2v vectors. Replacing \\\n",
    "                           by \"%s %s\"..' % (sent, self.bos, self.eos))\n",
    "        batch = self.get_batch(sent)\n",
    "\n",
    "        if self.is_cuda():\n",
    "            batch = batch.cuda()\n",
    "        output = self.enc_lstm(batch)[0]\n",
    "        output, idxs = torch.max(output, 0)\n",
    "        # output, idxs = output.squeeze(), idxs.squeeze()\n",
    "        idxs = idxs.data.cpu().numpy()\n",
    "        argmaxs = [np.sum((idxs == k)) for k in range(len(sent[0]))]\n",
    "\n",
    "        # visualize model\n",
    "        import matplotlib.pyplot as plt\n",
    "        x = range(len(sent[0]))\n",
    "        y = [100.0 * n / np.sum(argmaxs) for n in argmaxs]\n",
    "        plt.xticks(x, sent[0], rotation=45)\n",
    "        plt.bar(x, y)\n",
    "        plt.ylabel('%')\n",
    "        plt.title('Visualisation of words importance')\n",
    "        plt.show()\n",
    "\n",
    "        return output, idxs, x, y,sent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_version = 2\n",
    "MODEL_PATH = \"/home/uv/Documents/document_embedding/encoder/infersent%s.pkl\" % model_version\n",
    "params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n",
    "                'pool_type': 'max', 'dpout_model': 0.0, 'version': model_version}\n",
    "model = InferSent(params_model)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep it on CPU or put it on GPU\n",
    "use_cuda = False\n",
    "model = model.cuda() if use_cuda else model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If infersent1 -> use GloVe embeddings. If infersent2 -> use InferSent embeddings.\n",
    "W2V_PATH = 'GloVe/glove.840B.300d.txt' if model_version == 1 else '/home/uv/Documents/document_embedding/fastText/crawl-300d-2M.vec'\n",
    "model.set_w2v_path(W2V_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
       "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>How can I be a good geologist?</td>\n",
       "      <td>What should I do to be a great geologist?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "5   5    11    12  Astrology: I am a Capricorn Sun Cap moon and c...   \n",
       "7   7    15    16                     How can I be a good geologist?   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "5  I'm a triple Capricorn (Sun, Moon and ascendan...             1  \n",
       "7          What should I do to be a great geologist?             1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = df[df.is_duplicate==1][:2]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentences after tokenization [['Astrology', ':', 'I', 'am', 'a', 'Capricorn', 'Sun', 'Cap', 'moon', 'and', 'cap', 'rising', '...', 'what', 'does', 'that', 'say', 'about', 'me', '?'], ['How', 'can', 'I', 'be', 'a', 'good', 'geologist', '?']]\n",
      "Found 27(/27) words with w2v vectors\n",
      "word_vec dict_keys(['and', 'a', 'that', 'I', ':', '?', 'be', '...', 'can', 'about', 'what', 'me', 'good', 'say', 'does', 'am', 'How', 'Sun', 'cap', 'moon', 'rising', 'Cap', 'Astrology', 'Capricorn', 'geologist', '</p>', '<p>'])\n",
      "Vocab size : 27\n"
     ]
    }
   ],
   "source": [
    "model.build_vocab(sample.question1.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences:[list(['<p>', 'Astrology', ':', 'I', 'am', 'a', 'Capricorn', 'Sun', 'Cap', 'moon', 'and', 'cap', 'rising', '...', 'what', 'does', 'that', 'say', 'about', 'me', '?', '</p>'])\n",
      " list(['<p>', 'How', 'can', 'I', 'be', 'a', 'good', 'geologist', '?', '</p>'])], length[22 10],idx_sort[0 1]\n",
      "stidx 0\n",
      "before_get_batch [list(['<p>', 'Astrology', ':', 'I', 'am', 'a', 'Capricorn', 'Sun', 'Cap', 'moon', 'and', 'cap', 'rising', '...', 'what', 'does', 'that', 'say', 'about', 'me', '?', '</p>'])\n",
      " list(['<p>', 'How', 'can', 'I', 'be', 'a', 'good', 'geologist', '?', '</p>'])]\n",
      "embed (22, 2, 300)\n",
      "batch tensor([[[-0.3398,  0.3010,  0.1689,  ...,  0.0639,  0.0120, -0.1761],\n",
      "         [-0.3398,  0.3010,  0.1689,  ...,  0.0639,  0.0120, -0.1761]],\n",
      "\n",
      "        [[-0.1706,  0.4861,  0.8041,  ...,  0.1317,  0.1522,  0.0472],\n",
      "         [ 0.2556,  0.2020,  0.1471,  ...,  0.4596,  0.0446, -0.1606]],\n",
      "\n",
      "        [[-0.0731,  0.0320,  0.0507,  ...,  0.0880, -0.0027,  0.1899],\n",
      "         [-0.1720,  0.0026, -0.0409,  ...,  0.1958,  0.1303, -0.0978]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2161, -0.2337,  0.0548,  ..., -0.1334, -0.0926, -0.1469],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.3364, -0.0195,  0.2355,  ..., -0.0773, -0.0827, -0.0083],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.2010,  0.3212, -0.0270,  ...,  0.1667, -0.0982, -0.0186],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]) torch.Size([22, 2, 300])\n",
      "torch.Size([22, 2, 300]) (2,)\n",
      "sentpacked PackedSequence(data=tensor([[-0.3398,  0.3010,  0.1689,  ...,  0.0639,  0.0120, -0.1761],\n",
      "        [-0.3398,  0.3010,  0.1689,  ...,  0.0639,  0.0120, -0.1761],\n",
      "        [-0.1706,  0.4861,  0.8041,  ...,  0.1317,  0.1522,  0.0472],\n",
      "        ...,\n",
      "        [-0.2161, -0.2337,  0.0548,  ..., -0.1334, -0.0926, -0.1469],\n",
      "        [ 0.3364, -0.0195,  0.2355,  ..., -0.0773, -0.0827, -0.0083],\n",
      "        [-0.2010,  0.3212, -0.0270,  ...,  0.1667, -0.0982, -0.0186]]), batch_sizes=tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), sorted_indices=None, unsorted_indices=None)\n",
      "sent_sorted [22 10]\n",
      "sent_output torch.Size([22, 2, 4096])\n",
      "(2, 4096)\n"
     ]
    }
   ],
   "source": [
    "embedding = model.encode(sample.question1.values,tokenize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4096)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9999995, 0.3336536],\n",
       "       [0.3336536, 1.0000004]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences:[list(['<p>', 'I', 'a', 'Capricorn', 'Sun', 'and', 'Capricorn', 'does', 'say', 'about', 'me', '?', '</p>'])\n",
      " list(['<p>', 'I', 'be', 'a', 'geologist', '?', '</p>'])], length[13  7],idx_sort[0 1]\n",
      "stidx 0\n",
      "before_get_batch [list(['<p>', 'I', 'a', 'Capricorn', 'Sun', 'and', 'Capricorn', 'does', 'say', 'about', 'me', '?', '</p>'])\n",
      " list(['<p>', 'I', 'be', 'a', 'geologist', '?', '</p>'])]\n",
      "embed (13, 2, 300)\n",
      "batch tensor([[[-0.3398,  0.3010,  0.1689,  ...,  0.0639,  0.0120, -0.1761],\n",
      "         [-0.3398,  0.3010,  0.1689,  ...,  0.0639,  0.0120, -0.1761]],\n",
      "\n",
      "        [[-0.1615, -0.0980,  0.0185,  ...,  0.0735, -0.0265, -0.1398],\n",
      "         [-0.1615, -0.0980,  0.0185,  ...,  0.0735, -0.0265, -0.1398]],\n",
      "\n",
      "        [[ 0.0064,  0.0333,  0.0225,  ..., -0.0825,  0.0519, -0.0796],\n",
      "         [-0.1151, -0.1231,  0.0115,  ..., -0.3133,  0.0388,  0.0048]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2161, -0.2337,  0.0548,  ..., -0.1334, -0.0926, -0.1469],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.3364, -0.0195,  0.2355,  ..., -0.0773, -0.0827, -0.0083],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.2010,  0.3212, -0.0270,  ...,  0.1667, -0.0982, -0.0186],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]) torch.Size([13, 2, 300])\n",
      "torch.Size([13, 2, 300]) (2,)\n",
      "sentpacked PackedSequence(data=tensor([[-0.3398,  0.3010,  0.1689,  ...,  0.0639,  0.0120, -0.1761],\n",
      "        [-0.3398,  0.3010,  0.1689,  ...,  0.0639,  0.0120, -0.1761],\n",
      "        [-0.1615, -0.0980,  0.0185,  ...,  0.0735, -0.0265, -0.1398],\n",
      "        ...,\n",
      "        [-0.2161, -0.2337,  0.0548,  ..., -0.1334, -0.0926, -0.1469],\n",
      "        [ 0.3364, -0.0195,  0.2355,  ..., -0.0773, -0.0827, -0.0083],\n",
      "        [-0.2010,  0.3212, -0.0270,  ...,  0.1667, -0.0982, -0.0186]]), batch_sizes=tensor([2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1]), sorted_indices=None, unsorted_indices=None)\n",
      "sent_sorted [13  7]\n",
      "sent_output torch.Size([13, 2, 4096])\n",
      "(2, 4096)\n"
     ]
    }
   ],
   "source": [
    "embedding2 = model.encode(sample.question2.values,tokenize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = np.vstack([embedding,embedding2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9999995 , 0.3336536 , 0.7530447 , 0.19622421],\n",
       "       [0.3336536 , 1.0000004 , 0.3960089 , 0.79095197],\n",
       "       [0.7530447 , 0.3960089 , 1.0000005 , 0.31975242],\n",
       "       [0.19622421, 0.79095197, 0.31975242, 1.0000001 ]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed (21, 1, 300)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_,_,x,y,sent = model.visualize(str(sample.question1[:1].values),tokenize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6.6650390625, '<p>'),\n",
       " (3.076171875, ':'),\n",
       " (5.1513671875, 'I'),\n",
       " (6.591796875, 'am'),\n",
       " (4.150390625, 'a'),\n",
       " (9.1796875, 'Capricorn'),\n",
       " (7.71484375, 'Sun'),\n",
       " (3.369140625, 'Cap'),\n",
       " (7.1044921875, 'moon'),\n",
       " (1.46484375, 'and'),\n",
       " (4.2724609375, 'cap'),\n",
       " (5.2490234375, 'rising'),\n",
       " (1.5380859375, '...'),\n",
       " (3.3447265625, 'what'),\n",
       " (5.126953125, 'does'),\n",
       " (1.9287109375, 'that'),\n",
       " (4.0771484375, 'say'),\n",
       " (4.736328125, 'about'),\n",
       " (4.541015625, 'me'),\n",
       " (5.1025390625, '?'),\n",
       " (5.615234375, '</p>')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(y[i],j) for i,j in enumerate(sent[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "1. [Facebook-Infersent](https://github.com/facebookresearch/InferSent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
