{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SSD Helper File.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "g1DHUvdAwC-P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ]
    },
    {
      "metadata": {
        "id": "DY7MtVPwx912",
        "colab_type": "code",
        "outputId": "0b74291a-3991-4c6e-ba21-eea420024023",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import patches,patheffects\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets,transforms,models\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader , Dataset\n",
        "import torchvision.transforms.functional as FT\n",
        "\n",
        "from PIL import Image\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "from tqdm import tqdm,trange\n",
        "import time\n",
        "from math import sqrt\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f\"{torch.__version__} and {device}\")"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0.1.post2 and cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z1S3fcynC9Js",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def xy_to_cxcy(xy):\n",
        "    \"\"\"\n",
        "    Convert bounding boxes from boundary coordinates (x_min, y_min, x_max, y_max) to center-size coordinates (c_x, c_y, w, h).\n",
        "\n",
        "    :param xy: bounding boxes in boundary coordinates, a tensor of size (n_boxes, 4)\n",
        "    :return: bounding boxes in center-size coordinates, a tensor of size (n_boxes, 4)\n",
        "    \"\"\"\n",
        "    return torch.cat([(xy[:, 2:] + xy[:, :2]) / 2,  # c_x=(x_max+x_min)/2, similarly for c_y = (y_max+y_min)/2\n",
        "                      xy[:, 2:] - xy[:, :2]], 1)  # w = x_max-x_min, similarly for h\n",
        "\n",
        "\n",
        "def cxcy_to_xy(cxcy):\n",
        "    \"\"\"\n",
        "    Convert bounding boxes from center-size coordinates (c_x, c_y, w, h) to boundary coordinates (x_min, y_min, x_max, y_max).\n",
        "\n",
        "    :param cxcy: bounding boxes in center-size coordinates, a tensor of size (n_boxes, 4)\n",
        "    :return: bounding boxes in boundary coordinates, a tensor of size (n_boxes, 4)\n",
        "    \"\"\"\n",
        "    return torch.cat([cxcy[:, :2] - (cxcy[:, 2:] / 2),  # c_x-w=x_min, c_y-h=y_min\n",
        "                      cxcy[:, :2] + (cxcy[:, 2:] / 2)], 1)  # x_max, y_max\n",
        "\n",
        "\n",
        "def cxcy_to_gcxgcy(cxcy, priors_cxcy):\n",
        "    \"\"\"\n",
        "    Encode bounding boxes (that are in center-size form) w.r.t. the corresponding prior boxes (that are in center-size form).\n",
        "\n",
        "    For the center coordinates, find the offset with respect to the prior box, and scale by the size of the prior box.\n",
        "    For the size coordinates, scale by the size of the prior box, and convert to the log-space.\n",
        "\n",
        "    In the model, we are predicting bounding box coordinates in this encoded form.\n",
        "\n",
        "    :param cxcy: bounding boxes in center-size coordinates, a tensor of size (n_priors, 4)\n",
        "    :param priors_cxcy: prior boxes with respect to which the encoding must be performed, a tensor of size (n_priors, 4)\n",
        "    :return: encoded bounding boxes, a tensor of size (n_priors, 4)\n",
        "    \"\"\"\n",
        "\n",
        "    # The 10 and 5 below are referred to as 'variances' in the original Caffe repo, completely empirical\n",
        "    # They are for some sort of numerical conditioning, for 'scaling the localization gradient'\n",
        "    # See https://github.com/weiliu89/caffe/issues/155\n",
        "    return torch.cat([(cxcy[:, :2] - priors_cxcy[:, :2]) / (priors_cxcy[:, 2:] / 10),  # g_c_x, g_c_y\n",
        "                      torch.log(cxcy[:, 2:] / priors_cxcy[:, 2:]) * 5], 1)  # g_w, g_h\n",
        "\n",
        "\n",
        "def gcxgcy_to_cxcy(gcxgcy, priors_cxcy):\n",
        "    \"\"\"\n",
        "    Decode bounding box coordinates predicted by the model, since they are encoded in the form mentioned above.\n",
        "\n",
        "    They are decoded into center-size coordinates.\n",
        "\n",
        "    This is the inverse of the function above.\n",
        "\n",
        "    :param gcxgcy: encoded bounding boxes, i.e. output of the model, a tensor of size (n_priors, 4)\n",
        "    :param priors_cxcy: prior boxes with respect to which the encoding is defined, a tensor of size (n_priors, 4)\n",
        "    :return: decoded bounding boxes in center-size form, a tensor of size (n_priors, 4)\n",
        "    \"\"\"\n",
        "\n",
        "    return torch.cat([gcxgcy[:, :2] * priors_cxcy[:, 2:] / 10 + priors_cxcy[:, :2],  # c_x, c_y\n",
        "                      torch.exp(gcxgcy[:, 2:] / 5) * priors_cxcy[:, 2:]], 1)  # w, h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FwOrD4TIPAwk",
        "colab_type": "code",
        "outputId": "fac330b0-0444-45d3-dd48-816e20bcce8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "s1=[[0,0,3,4],[0,0,3,4]]\n",
        "set1=torch.tensor(s1,dtype=torch.float)\n",
        "cxcy=xy_to_cxcy(set1)\n",
        "print(\"Cx_C_y\",cxcy)\n",
        "gcxgcy=cxcy_to_gcxgcy(cxcy,set1)\n",
        "print(\"G_cx_G_cy\",gcxgcy)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cx_C_y tensor([[1.5000, 2.0000, 3.0000, 4.0000],\n",
            "        [1.5000, 2.0000, 3.0000, 4.0000]])\n",
            "G_cx_G_cy tensor([[5., 5., 0., 0.],\n",
            "        [5., 5., 0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5QSn3FX7LcIb",
        "colab_type": "code",
        "outputId": "46a18f69-449e-4c37-ec58-e426703bd31e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "s1=[[0,0,3,4],[2,1,3,4]]\n",
        "set1=torch.tensor(s1,dtype=torch.float)\n",
        "cxcy=xy_to_cxcy(set1)\n",
        "print(\"Cx_C_y\",cxcy)\n",
        "print(\"xy\",cxcy_to_xy(cxcy))\n",
        "gcxgcy=cxcy_to_gcxgcy(cxcy,set1)\n",
        "print(\"G_cx_G_cy\",gcxgcy)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cx_C_y tensor([[1.5000, 2.0000, 3.0000, 4.0000],\n",
            "        [2.5000, 2.5000, 1.0000, 3.0000]])\n",
            "xy tensor([[0., 0., 3., 4.],\n",
            "        [2., 1., 3., 4.]])\n",
            "G_cx_G_cy tensor([[ 5.0000,  5.0000,  0.0000,  0.0000],\n",
            "        [ 1.6667,  3.7500, -5.4931, -1.4384]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EUxtXRyBwK6A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Jaccard Overlap"
      ]
    },
    {
      "metadata": {
        "id": "ywkvHv0oxzMh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def find_intersection(set_1, set_2):\n",
        "    \"\"\"\n",
        "    Find the intersection of every box combination between two sets of boxes that are in boundary coordinates.\n",
        "\n",
        "    :param set_1: set 1, a tensor of dimensions (n1, 4)\n",
        "    :param set_2: set 2, a tensor of dimensions (n2, 4)\n",
        "    :return: intersection of each of the boxes in set 1 with respect to each of the boxes in set 2, a tensor of dimensions (n1, n2)\n",
        "    \"\"\"\n",
        "\n",
        "    # PyTorch auto-broadcasts singleton dimensions\n",
        "    lower_bounds = torch.max(set_1[:, :2].unsqueeze(1), set_2[:, :2].unsqueeze(0))  # (n1, n2, 2)\n",
        "    upper_bounds = torch.min(set_1[:, 2:].unsqueeze(1), set_2[:, 2:].unsqueeze(0))  # (n1, n2, 2)\n",
        "    intersection_dims = torch.clamp(upper_bounds - lower_bounds, min=0)  # (n1, n2, 2)\n",
        "    return intersection_dims[:, :, 0] * intersection_dims[:, :, 1]  # (n1, n2)\n",
        "\n",
        "\n",
        "def find_jaccard_overlap(set_1, set_2):\n",
        "    \"\"\"\n",
        "    Find the Jaccard Overlap (IoU) of every box combination between two sets of boxes that are in boundary coordinates.\n",
        "\n",
        "    :param set_1: set 1, a tensor of dimensions (n1, 4)\n",
        "    :param set_2: set 2, a tensor of dimensions (n2, 4)\n",
        "    :return: Jaccard Overlap of each of the boxes in set 1 with respect to each of the boxes in set 2, a tensor of dimensions (n1, n2)\n",
        "    \"\"\"\n",
        "\n",
        "    # Find intersections\n",
        "    intersection = find_intersection(set_1, set_2)  # (n1, n2)\n",
        "\n",
        "    # Find areas of each box in both sets\n",
        "    areas_set_1 = (set_1[:, 2] - set_1[:, 0]) * (set_1[:, 3] - set_1[:, 1])  # (n1)\n",
        "    areas_set_2 = (set_2[:, 2] - set_2[:, 0]) * (set_2[:, 3] - set_2[:, 1])  # (n2)\n",
        "\n",
        "    # Find the union\n",
        "    # PyTorch auto-broadcasts singleton dimensions\n",
        "    union = areas_set_1.unsqueeze(1) + areas_set_2.unsqueeze(0) - intersection  # (n1, n2)\n",
        "\n",
        "    return intersection / union  # (n1, n2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8buqtswvydy9",
        "colab_type": "code",
        "outputId": "7cccebd6-28ca-4372-e225-fdba43689879",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "s1=[[0,0,3,4],[0,0,3,4]]\n",
        "set1=torch.tensor(s1,dtype=torch.float)\n",
        "s2=[[2,0,5,4],[1,3,3,6],[1,0,2,2]]\n",
        "set2=torch.tensor(s2,dtype=torch.float)\n",
        "#find_jaccard_overlap(set1,set2)\n",
        "print(\"Bounding boxes\",set1)\n",
        "print(\"Anchor Boxes\",set2)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bounding boxes tensor([[0., 0., 3., 4.],\n",
            "        [0., 0., 3., 4.]])\n",
            "Anchor Boxes tensor([[2., 0., 5., 4.],\n",
            "        [1., 3., 3., 6.],\n",
            "        [1., 0., 2., 2.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "L3aYjnr1rXVl",
        "colab_type": "code",
        "outputId": "a598315b-6513-47b5-e887-f2c59d01261b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "set1.shape"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "metadata": {
        "id": "OMSiczgfzUus",
        "colab_type": "code",
        "outputId": "65b7d2be-239a-4b96-870f-5a5002700f4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "set1[:, :2].unsqueeze(dim=1)  #2x1x2"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0.]],\n",
              "\n",
              "        [[0., 0.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "metadata": {
        "id": "hoP-YSWS3qz3",
        "colab_type": "code",
        "outputId": "b7a6e835-9c79-4e83-e383-586c3a790b28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "set2[:, :2].unsqueeze(dim=0) #1x3x2"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[2., 0.],\n",
              "         [1., 3.],\n",
              "         [1., 0.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "metadata": {
        "id": "cBF8uPAwz_P-",
        "colab_type": "code",
        "outputId": "59280a7f-8618-4a0e-c5f3-7826d30ea916",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "cell_type": "code",
      "source": [
        "#lower_bound\n",
        "torch.max(set1[:, :2].unsqueeze(1), set2[:, :2].unsqueeze(0))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[2., 0.],\n",
              "         [1., 3.],\n",
              "         [1., 0.]],\n",
              "\n",
              "        [[2., 0.],\n",
              "         [1., 3.],\n",
              "         [1., 0.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "metadata": {
        "id": "dNlMoABJ47FR",
        "colab_type": "code",
        "outputId": "adce1ea0-d1d9-4e95-e15f-66442a613b34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "cell_type": "code",
      "source": [
        "#upper_bound\n",
        "torch.min(set1[:, 2:].unsqueeze(1), set2[:, 2:].unsqueeze(0))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[3., 4.],\n",
              "         [3., 4.],\n",
              "         [2., 2.]],\n",
              "\n",
              "        [[3., 4.],\n",
              "         [3., 4.],\n",
              "         [2., 2.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "metadata": {
        "id": "GqJbAThj4wNS",
        "colab_type": "code",
        "outputId": "00a0f9cd-dd8a-4dd8-9ea0-c43451f66647",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "cell_type": "code",
      "source": [
        "lower_bounds = torch.max(set1[:, :2].unsqueeze(1), set2[:, :2].unsqueeze(0))  # (n1, n2, 2)\n",
        "upper_bounds = torch.min(set1[:, 2:].unsqueeze(1), set2[:, 2:].unsqueeze(0))  # (n1, n2, 2)\n",
        "intersection_dims = torch.clamp(upper_bounds - lower_bounds, min=0)\n",
        "print(\"Width and Height of Intersection\",intersection_dims)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Width and Height of Intersection tensor([[[1., 4.],\n",
            "         [2., 1.],\n",
            "         [1., 2.]],\n",
            "\n",
            "        [[1., 4.],\n",
            "         [2., 1.],\n",
            "         [1., 2.]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xNgKO2Yr1hAE",
        "colab_type": "code",
        "outputId": "2ceed21a-52ce-4748-85dd-49a709e9c70e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "x=find_intersection(set1,set2)\n",
        "print(\"Area of intersection\",x)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Area of intersection tensor([[4., 2., 2.],\n",
            "        [4., 2., 2.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gVxbV275Uwhg",
        "colab_type": "code",
        "outputId": "cf5dd89f-e96d-42bd-c41f-57f016049187",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "areas_set_1 = (set1[:, 2] - set1[:, 0]) * (set1[:, 3] - set1[:, 1])  # (n1)\n",
        "print(\"Area Set1 :\",areas_set_1[0])\n",
        "areas_set_2 = (set2[:, 2] - set2[:, 0]) * (set2[:, 3] - set2[:, 1])  # (n2)\n",
        "print(\"Area Set2 :\",areas_set_2)\n",
        "union = areas_set_1.unsqueeze(1) + areas_set_2.unsqueeze(0) - x  # (n1, n2)\n",
        "print(\"Union: \",union[0])"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Area Set1 : tensor(12.)\n",
            "Area Set2 : tensor([12.,  6.,  2.])\n",
            "Union:  tensor([20., 16., 12.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MNEGMHmk1n-K",
        "colab_type": "code",
        "outputId": "f1b1ddb8-a76e-4f09-d417-3e3d6122feb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "find_jaccard_overlap(set1,set2)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2000, 0.1250, 0.1667],\n",
              "        [0.2000, 0.1250, 0.1667]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "metadata": {
        "id": "5EkNDC2FwUpo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Decimate"
      ]
    },
    {
      "metadata": {
        "id": "J6oK3ou96va9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def decimate(tensor, m):\n",
        "    \"\"\"\n",
        "    Decimate a tensor by a factor 'm', i.e. downsample by keeping every 'm'th value.\n",
        "\n",
        "    This is used when we convert FC layers to equivalent Convolutional layers, BUT of a smaller size.\n",
        "\n",
        "    :param tensor: tensor to be decimated\n",
        "    :param m: list of decimation factors for each dimension of the tensor; None if not to be decimated along a dimension\n",
        "    :return: decimated tensor\n",
        "    \"\"\"\n",
        "    assert tensor.dim() == len(m)\n",
        "    for d in range(tensor.dim()):\n",
        "        if m[d] is not None:\n",
        "            print(\"Index:\",d)\n",
        "            print(\"Number of elements in d = {} (dimension) : {}\".format(d,tensor.size(d)))\n",
        "            print(\"Step Size:\",m[d])\n",
        "            '''\n",
        "            Returns a new tensor which indexes the input tensor along dimension dim using the entries in index which is a LongTensor.\n",
        "            1st iteration start-0 - end-2 step_size-4   -selects just 1st element\n",
        "            2nd iteration Ignore \n",
        "            3rd iteration start-0 - end-7 step_size-3   -selects  1st , 4th and 7th element of current axis\n",
        "            4th iteration start-0 - end-2 step_size-3   -selects 1st , 4th and 7th element of  current axis\n",
        "            '''\n",
        "            #Keep subsetting across dimensions \n",
        "            tensor = tensor.index_select(dim=d,\n",
        "                                         index=torch.arange(start=0, end=tensor.size(d), step=m[d]).long())\n",
        "            print(tensor)\n",
        "\n",
        "    return tensor\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mOQV5CyA6vUH",
        "colab_type": "code",
        "outputId": "f6f880c3-f364-41a1-c44d-c9aaad705194",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        }
      },
      "cell_type": "code",
      "source": [
        "s1=torch.randn([2,2,7,7])\n",
        "print(\"Dimension of s1:\", s1.dim())\n",
        "m=[4,None,3,3]  #Number of filters (Divide by 4(4096/4)),None-Input Channels,\n",
        "print(s1)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dimension of s1: 4\n",
            "tensor([[[[-0.2546, -1.5330,  0.9464,  0.8398, -2.0292,  0.2078, -0.1742],\n",
            "          [-0.9466, -0.3097, -1.5996,  1.0044,  0.1724,  0.1705, -0.7411],\n",
            "          [-1.2677,  0.3842,  1.6150, -0.9137, -1.1277,  1.9705, -0.5900],\n",
            "          [ 1.3535,  0.1026, -1.4232, -0.2712, -0.6568, -2.1320,  1.2154],\n",
            "          [-0.9880, -1.6161, -0.2654,  0.1858,  0.5914,  0.2180, -1.3067],\n",
            "          [ 0.0613, -2.4601, -0.7081, -1.0835, -1.0823,  0.4095, -2.2745],\n",
            "          [ 0.7307,  0.0312, -0.6315, -0.8049, -0.0664,  0.3020,  0.3811]],\n",
            "\n",
            "         [[ 0.0514, -0.9905, -1.2673, -0.3777,  1.1829, -1.0737,  0.6938],\n",
            "          [-0.4404,  0.0302,  1.1418, -0.1971, -0.5233,  0.0451,  0.8625],\n",
            "          [-0.4771, -1.4032,  0.4864, -1.5147, -0.5819,  0.5870, -1.3267],\n",
            "          [ 1.3249,  0.1047,  0.4748,  0.2062, -0.3078,  0.3360,  1.1187],\n",
            "          [ 0.1928, -0.8406, -2.8185, -0.0976,  0.5295, -1.6954, -0.4845],\n",
            "          [-0.9378,  1.2767, -0.9744, -0.3748,  1.0450, -0.9261,  0.5624],\n",
            "          [-1.9278, -0.9398,  0.9314, -1.0151, -0.2800,  0.4686,  2.1334]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1197, -0.0056, -0.6972,  0.7323, -0.8429,  0.8057,  0.2856],\n",
            "          [-0.0181, -0.9619,  0.2261,  2.3195,  0.5351,  1.3965, -0.1891],\n",
            "          [ 0.7481, -1.4766,  0.6688,  0.0970,  0.7817,  1.1784, -0.1257],\n",
            "          [ 0.8175, -0.8925,  1.2931,  0.3082, -0.5404,  0.0846, -0.8843],\n",
            "          [ 0.3757, -0.4045, -0.3483, -0.7193, -1.2343,  1.0362,  0.2185],\n",
            "          [-0.2856,  2.0177,  1.1865,  0.6289,  2.3564,  0.2124,  1.4202],\n",
            "          [-0.4325,  0.4013, -0.7397,  0.1769, -0.4392, -0.5550, -0.0496]],\n",
            "\n",
            "         [[-0.8529, -0.2547, -0.8071,  0.4800, -0.2927, -0.9750, -1.3519],\n",
            "          [-2.1539,  0.7393, -0.0496,  0.7654,  0.5549, -0.8732,  0.4671],\n",
            "          [-0.7182, -0.2421, -0.2499, -0.9141, -0.1032, -0.2559, -0.6734],\n",
            "          [ 0.6055,  0.3750,  0.5076,  0.1101, -1.3474,  0.5594,  0.1834],\n",
            "          [-1.9542, -0.7066, -0.2763,  0.6562, -0.0644,  1.2688, -0.9368],\n",
            "          [-0.2404,  0.0539,  1.1548,  0.3328, -0.9681, -1.0897,  1.1995],\n",
            "          [-0.2945, -0.6290,  1.1676, -0.2834,  0.0801,  0.5556,  1.1956]]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "17rOEglH6-gf",
        "colab_type": "code",
        "outputId": "d520ed8c-f7b2-490e-b8c4-4a3e3d86dcfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        }
      },
      "cell_type": "code",
      "source": [
        "x=decimate(s1,m)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index: 0\n",
            "Number of elements in d = 0 (dimension) : 2\n",
            "Step Size: 4\n",
            "tensor([[[[-0.2546, -1.5330,  0.9464,  0.8398, -2.0292,  0.2078, -0.1742],\n",
            "          [-0.9466, -0.3097, -1.5996,  1.0044,  0.1724,  0.1705, -0.7411],\n",
            "          [-1.2677,  0.3842,  1.6150, -0.9137, -1.1277,  1.9705, -0.5900],\n",
            "          [ 1.3535,  0.1026, -1.4232, -0.2712, -0.6568, -2.1320,  1.2154],\n",
            "          [-0.9880, -1.6161, -0.2654,  0.1858,  0.5914,  0.2180, -1.3067],\n",
            "          [ 0.0613, -2.4601, -0.7081, -1.0835, -1.0823,  0.4095, -2.2745],\n",
            "          [ 0.7307,  0.0312, -0.6315, -0.8049, -0.0664,  0.3020,  0.3811]],\n",
            "\n",
            "         [[ 0.0514, -0.9905, -1.2673, -0.3777,  1.1829, -1.0737,  0.6938],\n",
            "          [-0.4404,  0.0302,  1.1418, -0.1971, -0.5233,  0.0451,  0.8625],\n",
            "          [-0.4771, -1.4032,  0.4864, -1.5147, -0.5819,  0.5870, -1.3267],\n",
            "          [ 1.3249,  0.1047,  0.4748,  0.2062, -0.3078,  0.3360,  1.1187],\n",
            "          [ 0.1928, -0.8406, -2.8185, -0.0976,  0.5295, -1.6954, -0.4845],\n",
            "          [-0.9378,  1.2767, -0.9744, -0.3748,  1.0450, -0.9261,  0.5624],\n",
            "          [-1.9278, -0.9398,  0.9314, -1.0151, -0.2800,  0.4686,  2.1334]]]])\n",
            "Index: 2\n",
            "Number of elements in d = 2 (dimension) : 7\n",
            "Step Size: 3\n",
            "tensor([[[[-0.2546, -1.5330,  0.9464,  0.8398, -2.0292,  0.2078, -0.1742],\n",
            "          [ 1.3535,  0.1026, -1.4232, -0.2712, -0.6568, -2.1320,  1.2154],\n",
            "          [ 0.7307,  0.0312, -0.6315, -0.8049, -0.0664,  0.3020,  0.3811]],\n",
            "\n",
            "         [[ 0.0514, -0.9905, -1.2673, -0.3777,  1.1829, -1.0737,  0.6938],\n",
            "          [ 1.3249,  0.1047,  0.4748,  0.2062, -0.3078,  0.3360,  1.1187],\n",
            "          [-1.9278, -0.9398,  0.9314, -1.0151, -0.2800,  0.4686,  2.1334]]]])\n",
            "Index: 3\n",
            "Number of elements in d = 3 (dimension) : 7\n",
            "Step Size: 3\n",
            "tensor([[[[-0.2546,  0.8398, -0.1742],\n",
            "          [ 1.3535, -0.2712,  1.2154],\n",
            "          [ 0.7307, -0.8049,  0.3811]],\n",
            "\n",
            "         [[ 0.0514, -0.3777,  0.6938],\n",
            "          [ 1.3249,  0.2062,  1.1187],\n",
            "          [-1.9278, -1.0151,  2.1334]]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SpenaSkkvRKP",
        "colab_type": "code",
        "outputId": "e9aa9118-e0bd-4ff1-feb4-75089f2c18b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 2, 3, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "metadata": {
        "id": "SqwvSuAhlChM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Create Prior Boxes\n"
      ]
    },
    {
      "metadata": {
        "id": "0ebq32relBsB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_prior_boxes(self):\n",
        "        \"\"\"\n",
        "        Create the 8732 prior (default) boxes for the SSD300, as defined in the paper.\n",
        "\n",
        "        :return: prior boxes in center-size coordinates, a tensor of dimensions (8732, 4)\n",
        "        \"\"\"\n",
        "        fmap_dims = {'conv4_3': 38,\n",
        "                     'conv7': 19,\n",
        "                     'conv8_2': 10,\n",
        "                     'conv9_2': 5,\n",
        "                     'conv10_2': 3,\n",
        "                     'conv11_2': 1}\n",
        "\n",
        "        obj_scales = {'conv4_3': 0.1,\n",
        "                      'conv7': 0.2,\n",
        "                      'conv8_2': 0.375,\n",
        "                      'conv9_2': 0.55,\n",
        "                      'conv10_2': 0.725,\n",
        "                      'conv11_2': 0.9}\n",
        "\n",
        "        aspect_ratios = {'conv4_3': [1., 2., 0.5],\n",
        "                         'conv7': [1., 2., 3., 0.5, .333],\n",
        "                         'conv8_2': [1., 2., 3., 0.5, .333],\n",
        "                         'conv9_2': [1., 2., 3., 0.5, .333],\n",
        "                         'conv10_2': [1., 2., 0.5],\n",
        "                         'conv11_2': [1., 2., 0.5]}\n",
        "\n",
        "        fmaps = list(fmap_dims.keys())\n",
        "\n",
        "        prior_boxes = []\n",
        "\n",
        "        for k, fmap in enumerate(fmaps):\n",
        "            for i in range(fmap_dims[fmap]):\n",
        "                for j in range(fmap_dims[fmap]):\n",
        "                    cx = (j + 0.5) / fmap_dims[fmap]\n",
        "                    cy = (i + 0.5) / fmap_dims[fmap]\n",
        "\n",
        "                    for ratio in aspect_ratios[fmap]:\n",
        "                        prior_boxes.append([cx, cy, obj_scales[fmap] * sqrt(ratio), obj_scales[fmap] / sqrt(ratio)])\n",
        "\n",
        "                        # For an aspect ratio of 1, use an additional prior whose scale is the geometric mean of the\n",
        "                        # scale of the current feature map and the scale of the next feature map\n",
        "                        if ratio == 1.:\n",
        "                            try:\n",
        "                                additional_scale = sqrt(obj_scales[fmap] * obj_scales[fmaps[k + 1]])\n",
        "                            # For the last feature map, there is no \"next\" feature map\n",
        "                            except IndexError:\n",
        "                                additional_scale = 1.\n",
        "                            prior_boxes.append([cx, cy, additional_scale, additional_scale])\n",
        "\n",
        "        prior_boxes = torch.FloatTensor(prior_boxes).to(device)  # (8732, 4)\n",
        "        prior_boxes.clamp_(0, 1)  # (8732, 4)\n",
        "\n",
        "        return prior_boxes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8E0U8uSLlJdv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_prior_boxes():\n",
        "        \"\"\"\n",
        "        Create the 8732 prior (default) boxes for the SSD300, as defined in the paper.\n",
        "\n",
        "        :return: prior boxes in center-size coordinates, a tensor of dimensions (8732, 4)\n",
        "        \"\"\"\n",
        "        fmap_dims = {'conv10_2': 3,\n",
        "                    'conv11_2': 1}\n",
        "\n",
        "        obj_scales = {'conv10_2': 0.725,\n",
        "                     'conv11_2': 0.9}\n",
        "\n",
        "        aspect_ratios = {'conv10_2': [1., 2., 0.5],\n",
        "                        'conv11_2': [1., 2., 0.5]}\n",
        "\n",
        "        fmaps = list(fmap_dims.keys())\n",
        "        prior_boxes = []\n",
        "\n",
        "        for k, fmap in enumerate(fmaps):\n",
        "            print(\"For feature map = {}\".format(fmap))\n",
        "            for i in range(fmap_dims[fmap]):\n",
        "                #print(i)\n",
        "                #print(\"y location on Feature Map(i) = {} and fmap = {}\".format(i,fmap))\n",
        "                for j in range(fmap_dims[fmap]):\n",
        "                    #print(j)\n",
        "                    print(\"x,y location on Feature Map(j,i) = ({},{})\".format(j,i))\n",
        "                    cx = (j + 0.5) / fmap_dims[fmap]\n",
        "                    cy = (i + 0.5) / fmap_dims[fmap]\n",
        "                    print(\"cx = {} and cy = {}\".format(cx,cy))\n",
        "\n",
        "                    for m,ratio in enumerate(aspect_ratios[fmap]):\n",
        "                        prior_boxes.append([cx, cy, obj_scales[fmap] * sqrt(ratio), obj_scales[fmap] / sqrt(ratio)])\n",
        "                        print(\"For aspect ration {}\".format(ratio))\n",
        "                        print(prior_boxes)\n",
        "                        #print(\"Pre\\n Centre of x ={}\\n Centre of y = {}\\n Widht ={}\\n Height {}\".format(prior_boxes[m][0],prior_boxes[m][1],prior_boxes[m][2],prior_boxes[m][3]))\n",
        "                        # For an aspect ratio of 1, use an additional prior whose scale is the geometric mean of the\n",
        "                        # scale of the current feature map and the scale of the next feature map\n",
        "                        if ratio == 1.:\n",
        "                            print(\"Add 1 more prior box\")\n",
        "                            try:\n",
        "                                additional_scale = sqrt(obj_scales[fmap] * obj_scales[fmaps[k + 1]])\n",
        "                                print(\"Additional Scale\",additional_scale)\n",
        "                            # For the last feature map, there is no \"next\" feature map\n",
        "                            except IndexError:\n",
        "                                additional_scale = 1.\n",
        "                            prior_boxes.append([cx, cy, additional_scale, additional_scale])\n",
        "                            print(prior_boxes)\n",
        "                            #print(\" Post \\n Modified Centre of x ={}\\n Centre of y = {}\\n Widht ={}\\n Height {}\".format(prior_boxes[m+1][0],prior_boxes[i][1],prior_boxes[i][2],prior_boxes[i][3]))\n",
        "        prior_boxes = torch.FloatTensor(prior_boxes).to(device)  # (8732, 4)\n",
        "        prior_boxes.clamp_(0, 1)  # (8732, 4)\n",
        "\n",
        "        return prior_boxes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GhwQc4uxlPto",
        "colab_type": "code",
        "outputId": "c4dca510-0e5c-4c7f-c7c5-6504b205b34f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2708
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"After clamping values between 0 and 1\\n\",create_prior_boxes())"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For feature map = conv10_2\n",
            "x,y location on Feature Map(j,i) = (0,0)\n",
            "cx = 0.16666666666666666 and cy = 0.16666666666666666\n",
            "For aspect ration 1.0\n",
            "[[0.16666666666666666, 0.16666666666666666, 0.725, 0.725]]\n",
            "Add 1 more prior box\n",
            "Additional Scale 0.8077747210701756\n",
            "[[0.16666666666666666, 0.16666666666666666, 0.725, 0.725], [0.16666666666666666, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756]]\n",
            "For aspect ration 2.0\n",
            "[[0.16666666666666666, 0.16666666666666666, 0.725, 0.725], [0.16666666666666666, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469]]\n",
            "For aspect ration 0.5\n",
            "[[0.16666666666666666, 0.16666666666666666, 0.725, 0.725], [0.16666666666666666, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939]]\n",
            "x,y location on Feature Map(j,i) = (1,0)\n",
            "cx = 0.5 and cy = 0.16666666666666666\n",
            "For aspect ration 1.0\n",
            "[[0.16666666666666666, 0.16666666666666666, 0.725, 0.725], [0.16666666666666666, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.5, 0.16666666666666666, 0.725, 0.725]]\n",
            "Add 1 more prior box\n",
            "Additional Scale 0.8077747210701756\n",
            "[[0.16666666666666666, 0.16666666666666666, 0.725, 0.725], [0.16666666666666666, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.5, 0.16666666666666666, 0.725, 0.725], [0.5, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756]]\n",
            "For aspect ration 2.0\n",
            "[[0.16666666666666666, 0.16666666666666666, 0.725, 0.725], [0.16666666666666666, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.5, 0.16666666666666666, 0.725, 0.725], [0.5, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.5, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469]]\n",
            "For aspect ration 0.5\n",
            "[[0.16666666666666666, 0.16666666666666666, 0.725, 0.725], [0.16666666666666666, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.5, 0.16666666666666666, 0.725, 0.725], [0.5, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.5, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.5, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939]]\n",
            "x,y location on Feature Map(j,i) = (2,0)\n",
            "cx = 0.8333333333333334 and cy = 0.16666666666666666\n",
            "For aspect ration 1.0\n",
            "[[0.16666666666666666, 0.16666666666666666, 0.725, 0.725], [0.16666666666666666, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.5, 0.16666666666666666, 0.725, 0.725], [0.5, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.5, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.5, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.16666666666666666, 0.725, 0.725]]\n",
            "Add 1 more prior box\n",
            "Additional Scale 0.8077747210701756\n",
            "[[0.16666666666666666, 0.16666666666666666, 0.725, 0.725], [0.16666666666666666, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.5, 0.16666666666666666, 0.725, 0.725], [0.5, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.5, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.5, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.16666666666666666, 0.725, 0.725], [0.8333333333333334, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756]]\n",
            "For aspect ration 2.0\n",
            "[[0.16666666666666666, 0.16666666666666666, 0.725, 0.725], [0.16666666666666666, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.5, 0.16666666666666666, 0.725, 0.725], [0.5, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.5, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.5, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.16666666666666666, 0.725, 0.725], [0.8333333333333334, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469]]\n",
            "For aspect ration 0.5\n",
            "[[0.16666666666666666, 0.16666666666666666, 0.725, 0.725], [0.16666666666666666, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.5, 0.16666666666666666, 0.725, 0.725], [0.5, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.5, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.5, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.16666666666666666, 0.725, 0.725], [0.8333333333333334, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939]]\n",
            "x,y location on Feature Map(j,i) = (0,1)\n",
            "cx = 0.16666666666666666 and cy = 0.5\n",
            "For aspect ration 1.0\n",
            "[[0.16666666666666666, 0.16666666666666666, 0.725, 0.725], [0.16666666666666666, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.5, 0.16666666666666666, 0.725, 0.725], [0.5, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.5, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.5, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.16666666666666666, 0.725, 0.725], [0.8333333333333334, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.5, 0.725, 0.725]]\n",
            "Add 1 more prior box\n",
            "Additional Scale 0.8077747210701756\n",
            "[[0.16666666666666666, 0.16666666666666666, 0.725, 0.725], [0.16666666666666666, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.5, 0.16666666666666666, 0.725, 0.725], [0.5, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.5, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.5, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.16666666666666666, 0.725, 0.725], [0.8333333333333334, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.5, 0.725, 0.725], [0.16666666666666666, 0.5, 0.8077747210701756, 0.8077747210701756]]\n",
            "For aspect ration 2.0\n",
            "[[0.16666666666666666, 0.16666666666666666, 0.725, 0.725], [0.16666666666666666, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.5, 0.16666666666666666, 0.725, 0.725], [0.5, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.5, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.5, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.16666666666666666, 0.725, 0.725], [0.8333333333333334, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.5, 0.725, 0.725], [0.16666666666666666, 0.5, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.5, 1.0253048327204939, 0.5126524163602469]]\n",
            "For aspect ration 0.5\n",
            "[[0.16666666666666666, 0.16666666666666666, 0.725, 0.725], [0.16666666666666666, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.5, 0.16666666666666666, 0.725, 0.725], [0.5, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.5, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.5, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.16666666666666666, 0.725, 0.725], [0.8333333333333334, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.5, 0.725, 0.725], [0.16666666666666666, 0.5, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.5, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.5, 0.5126524163602469, 1.0253048327204939]]\n",
            "x,y location on Feature Map(j,i) = (1,1)\n",
            "cx = 0.5 and cy = 0.5\n",
            "For aspect ration 1.0\n",
            "[[0.16666666666666666, 0.16666666666666666, 0.725, 0.725], [0.16666666666666666, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.5, 0.16666666666666666, 0.725, 0.725], [0.5, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.5, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.5, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.16666666666666666, 0.725, 0.725], [0.8333333333333334, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.5, 0.725, 0.725], [0.16666666666666666, 0.5, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.5, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.5, 0.5126524163602469, 1.0253048327204939], [0.5, 0.5, 0.725, 0.725]]\n",
            "Add 1 more prior box\n",
            "Additional Scale 0.8077747210701756\n",
            "[[0.16666666666666666, 0.16666666666666666, 0.725, 0.725], [0.16666666666666666, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.5, 0.16666666666666666, 0.725, 0.725], [0.5, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.5, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.5, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.16666666666666666, 0.725, 0.725], [0.8333333333333334, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.5, 0.725, 0.725], [0.16666666666666666, 0.5, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.5, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.5, 0.5126524163602469, 1.0253048327204939], [0.5, 0.5, 0.725, 0.725], [0.5, 0.5, 0.8077747210701756, 0.8077747210701756]]\n",
            "For aspect ration 2.0\n",
            "[[0.16666666666666666, 0.16666666666666666, 0.725, 0.725], [0.16666666666666666, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.5, 0.16666666666666666, 0.725, 0.725], [0.5, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.5, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.5, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.16666666666666666, 0.725, 0.725], [0.8333333333333334, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.5, 0.725, 0.725], [0.16666666666666666, 0.5, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.5, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.5, 0.5126524163602469, 1.0253048327204939], [0.5, 0.5, 0.725, 0.725], [0.5, 0.5, 0.8077747210701756, 0.8077747210701756], [0.5, 0.5, 1.0253048327204939, 0.5126524163602469]]\n",
            "For aspect ration 0.5\n",
            "[[0.16666666666666666, 0.16666666666666666, 0.725, 0.725], [0.16666666666666666, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.5, 0.16666666666666666, 0.725, 0.725], [0.5, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.5, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.5, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.16666666666666666, 0.725, 0.725], [0.8333333333333334, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.5, 0.725, 0.725], [0.16666666666666666, 0.5, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.5, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.5, 0.5126524163602469, 1.0253048327204939], [0.5, 0.5, 0.725, 0.725], [0.5, 0.5, 0.8077747210701756, 0.8077747210701756], [0.5, 0.5, 1.0253048327204939, 0.5126524163602469], [0.5, 0.5, 0.5126524163602469, 1.0253048327204939]]\n",
            "x,y location on Feature Map(j,i) = (2,1)\n",
            "cx = 0.8333333333333334 and cy = 0.5\n",
            "For aspect ration 1.0\n",
            "[[0.16666666666666666, 0.16666666666666666, 0.725, 0.725], [0.16666666666666666, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.5, 0.16666666666666666, 0.725, 0.725], [0.5, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.5, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.5, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.16666666666666666, 0.725, 0.725], [0.8333333333333334, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.5, 0.725, 0.725], [0.16666666666666666, 0.5, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.5, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.5, 0.5126524163602469, 1.0253048327204939], [0.5, 0.5, 0.725, 0.725], [0.5, 0.5, 0.8077747210701756, 0.8077747210701756], [0.5, 0.5, 1.0253048327204939, 0.5126524163602469], [0.5, 0.5, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.5, 0.725, 0.725]]\n",
            "Add 1 more prior box\n",
            "Additional Scale 0.8077747210701756\n",
            "[[0.16666666666666666, 0.16666666666666666, 0.725, 0.725], [0.16666666666666666, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.5, 0.16666666666666666, 0.725, 0.725], [0.5, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.5, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.5, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.16666666666666666, 0.725, 0.725], [0.8333333333333334, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.5, 0.725, 0.725], [0.16666666666666666, 0.5, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.5, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.5, 0.5126524163602469, 1.0253048327204939], [0.5, 0.5, 0.725, 0.725], [0.5, 0.5, 0.8077747210701756, 0.8077747210701756], [0.5, 0.5, 1.0253048327204939, 0.5126524163602469], [0.5, 0.5, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.5, 0.725, 0.725], [0.8333333333333334, 0.5, 0.8077747210701756, 0.8077747210701756]]\n",
            "For aspect ration 2.0\n",
            "[[0.16666666666666666, 0.16666666666666666, 0.725, 0.725], [0.16666666666666666, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.5, 0.16666666666666666, 0.725, 0.725], [0.5, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.5, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.5, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.16666666666666666, 0.725, 0.725], [0.8333333333333334, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.5, 0.725, 0.725], [0.16666666666666666, 0.5, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.5, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.5, 0.5126524163602469, 1.0253048327204939], [0.5, 0.5, 0.725, 0.725], [0.5, 0.5, 0.8077747210701756, 0.8077747210701756], [0.5, 0.5, 1.0253048327204939, 0.5126524163602469], [0.5, 0.5, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.5, 0.725, 0.725], [0.8333333333333334, 0.5, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.5, 1.0253048327204939, 0.5126524163602469]]\n",
            "For aspect ration 0.5\n",
            "[[0.16666666666666666, 0.16666666666666666, 0.725, 0.725], [0.16666666666666666, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.5, 0.16666666666666666, 0.725, 0.725], [0.5, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.5, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.5, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.16666666666666666, 0.725, 0.725], [0.8333333333333334, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.5, 0.725, 0.725], [0.16666666666666666, 0.5, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.5, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.5, 0.5126524163602469, 1.0253048327204939], [0.5, 0.5, 0.725, 0.725], [0.5, 0.5, 0.8077747210701756, 0.8077747210701756], [0.5, 0.5, 1.0253048327204939, 0.5126524163602469], [0.5, 0.5, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.5, 0.725, 0.725], [0.8333333333333334, 0.5, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.5, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.5, 0.5126524163602469, 1.0253048327204939]]\n",
            "x,y location on Feature Map(j,i) = (0,2)\n",
            "cx = 0.16666666666666666 and cy = 0.8333333333333334\n",
            "For aspect ration 1.0\n",
            "[[0.16666666666666666, 0.16666666666666666, 0.725, 0.725], [0.16666666666666666, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.5, 0.16666666666666666, 0.725, 0.725], [0.5, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.5, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.5, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.16666666666666666, 0.725, 0.725], [0.8333333333333334, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.5, 0.725, 0.725], [0.16666666666666666, 0.5, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.5, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.5, 0.5126524163602469, 1.0253048327204939], [0.5, 0.5, 0.725, 0.725], [0.5, 0.5, 0.8077747210701756, 0.8077747210701756], [0.5, 0.5, 1.0253048327204939, 0.5126524163602469], [0.5, 0.5, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.5, 0.725, 0.725], [0.8333333333333334, 0.5, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.5, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.5, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.8333333333333334, 0.725, 0.725]]\n",
            "Add 1 more prior box\n",
            "Additional Scale 0.8077747210701756\n",
            "[[0.16666666666666666, 0.16666666666666666, 0.725, 0.725], [0.16666666666666666, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.5, 0.16666666666666666, 0.725, 0.725], [0.5, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.5, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.5, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.16666666666666666, 0.725, 0.725], [0.8333333333333334, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.5, 0.725, 0.725], [0.16666666666666666, 0.5, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.5, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.5, 0.5126524163602469, 1.0253048327204939], [0.5, 0.5, 0.725, 0.725], [0.5, 0.5, 0.8077747210701756, 0.8077747210701756], [0.5, 0.5, 1.0253048327204939, 0.5126524163602469], [0.5, 0.5, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.5, 0.725, 0.725], [0.8333333333333334, 0.5, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.5, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.5, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.8333333333333334, 0.725, 0.725], [0.16666666666666666, 0.8333333333333334, 0.8077747210701756, 0.8077747210701756]]\n",
            "For aspect ration 2.0\n",
            "[[0.16666666666666666, 0.16666666666666666, 0.725, 0.725], [0.16666666666666666, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.5, 0.16666666666666666, 0.725, 0.725], [0.5, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.5, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.5, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.16666666666666666, 0.725, 0.725], [0.8333333333333334, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.5, 0.725, 0.725], [0.16666666666666666, 0.5, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.5, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.5, 0.5126524163602469, 1.0253048327204939], [0.5, 0.5, 0.725, 0.725], [0.5, 0.5, 0.8077747210701756, 0.8077747210701756], [0.5, 0.5, 1.0253048327204939, 0.5126524163602469], [0.5, 0.5, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.5, 0.725, 0.725], [0.8333333333333334, 0.5, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.5, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.5, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.8333333333333334, 0.725, 0.725], [0.16666666666666666, 0.8333333333333334, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.8333333333333334, 1.0253048327204939, 0.5126524163602469]]\n",
            "For aspect ration 0.5\n",
            "[[0.16666666666666666, 0.16666666666666666, 0.725, 0.725], [0.16666666666666666, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.5, 0.16666666666666666, 0.725, 0.725], [0.5, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.5, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.5, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.16666666666666666, 0.725, 0.725], [0.8333333333333334, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.5, 0.725, 0.725], [0.16666666666666666, 0.5, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.5, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.5, 0.5126524163602469, 1.0253048327204939], [0.5, 0.5, 0.725, 0.725], [0.5, 0.5, 0.8077747210701756, 0.8077747210701756], [0.5, 0.5, 1.0253048327204939, 0.5126524163602469], [0.5, 0.5, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.5, 0.725, 0.725], [0.8333333333333334, 0.5, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.5, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.5, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.8333333333333334, 0.725, 0.725], [0.16666666666666666, 0.8333333333333334, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.8333333333333334, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.8333333333333334, 0.5126524163602469, 1.0253048327204939]]\n",
            "x,y location on Feature Map(j,i) = (1,2)\n",
            "cx = 0.5 and cy = 0.8333333333333334\n",
            "For aspect ration 1.0\n",
            "[[0.16666666666666666, 0.16666666666666666, 0.725, 0.725], [0.16666666666666666, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.5, 0.16666666666666666, 0.725, 0.725], [0.5, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.5, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.5, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.16666666666666666, 0.725, 0.725], [0.8333333333333334, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.5, 0.725, 0.725], [0.16666666666666666, 0.5, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.5, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.5, 0.5126524163602469, 1.0253048327204939], [0.5, 0.5, 0.725, 0.725], [0.5, 0.5, 0.8077747210701756, 0.8077747210701756], [0.5, 0.5, 1.0253048327204939, 0.5126524163602469], [0.5, 0.5, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.5, 0.725, 0.725], [0.8333333333333334, 0.5, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.5, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.5, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.8333333333333334, 0.725, 0.725], [0.16666666666666666, 0.8333333333333334, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.8333333333333334, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.8333333333333334, 0.5126524163602469, 1.0253048327204939], [0.5, 0.8333333333333334, 0.725, 0.725]]\n",
            "Add 1 more prior box\n",
            "Additional Scale 0.8077747210701756\n",
            "[[0.16666666666666666, 0.16666666666666666, 0.725, 0.725], [0.16666666666666666, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.5, 0.16666666666666666, 0.725, 0.725], [0.5, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.5, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.5, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.16666666666666666, 0.725, 0.725], [0.8333333333333334, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.5, 0.725, 0.725], [0.16666666666666666, 0.5, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.5, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.5, 0.5126524163602469, 1.0253048327204939], [0.5, 0.5, 0.725, 0.725], [0.5, 0.5, 0.8077747210701756, 0.8077747210701756], [0.5, 0.5, 1.0253048327204939, 0.5126524163602469], [0.5, 0.5, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.5, 0.725, 0.725], [0.8333333333333334, 0.5, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.5, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.5, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.8333333333333334, 0.725, 0.725], [0.16666666666666666, 0.8333333333333334, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.8333333333333334, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.8333333333333334, 0.5126524163602469, 1.0253048327204939], [0.5, 0.8333333333333334, 0.725, 0.725], [0.5, 0.8333333333333334, 0.8077747210701756, 0.8077747210701756]]\n",
            "For aspect ration 2.0\n",
            "[[0.16666666666666666, 0.16666666666666666, 0.725, 0.725], [0.16666666666666666, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.5, 0.16666666666666666, 0.725, 0.725], [0.5, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.5, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.5, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.16666666666666666, 0.725, 0.725], [0.8333333333333334, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.5, 0.725, 0.725], [0.16666666666666666, 0.5, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.5, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.5, 0.5126524163602469, 1.0253048327204939], [0.5, 0.5, 0.725, 0.725], [0.5, 0.5, 0.8077747210701756, 0.8077747210701756], [0.5, 0.5, 1.0253048327204939, 0.5126524163602469], [0.5, 0.5, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.5, 0.725, 0.725], [0.8333333333333334, 0.5, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.5, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.5, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.8333333333333334, 0.725, 0.725], [0.16666666666666666, 0.8333333333333334, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.8333333333333334, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.8333333333333334, 0.5126524163602469, 1.0253048327204939], [0.5, 0.8333333333333334, 0.725, 0.725], [0.5, 0.8333333333333334, 0.8077747210701756, 0.8077747210701756], [0.5, 0.8333333333333334, 1.0253048327204939, 0.5126524163602469]]\n",
            "For aspect ration 0.5\n",
            "[[0.16666666666666666, 0.16666666666666666, 0.725, 0.725], [0.16666666666666666, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.5, 0.16666666666666666, 0.725, 0.725], [0.5, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.5, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.5, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.16666666666666666, 0.725, 0.725], [0.8333333333333334, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.5, 0.725, 0.725], [0.16666666666666666, 0.5, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.5, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.5, 0.5126524163602469, 1.0253048327204939], [0.5, 0.5, 0.725, 0.725], [0.5, 0.5, 0.8077747210701756, 0.8077747210701756], [0.5, 0.5, 1.0253048327204939, 0.5126524163602469], [0.5, 0.5, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.5, 0.725, 0.725], [0.8333333333333334, 0.5, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.5, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.5, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.8333333333333334, 0.725, 0.725], [0.16666666666666666, 0.8333333333333334, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.8333333333333334, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.8333333333333334, 0.5126524163602469, 1.0253048327204939], [0.5, 0.8333333333333334, 0.725, 0.725], [0.5, 0.8333333333333334, 0.8077747210701756, 0.8077747210701756], [0.5, 0.8333333333333334, 1.0253048327204939, 0.5126524163602469], [0.5, 0.8333333333333334, 0.5126524163602469, 1.0253048327204939]]\n",
            "x,y location on Feature Map(j,i) = (2,2)\n",
            "cx = 0.8333333333333334 and cy = 0.8333333333333334\n",
            "For aspect ration 1.0\n",
            "[[0.16666666666666666, 0.16666666666666666, 0.725, 0.725], [0.16666666666666666, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.5, 0.16666666666666666, 0.725, 0.725], [0.5, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.5, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.5, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.16666666666666666, 0.725, 0.725], [0.8333333333333334, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.5, 0.725, 0.725], [0.16666666666666666, 0.5, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.5, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.5, 0.5126524163602469, 1.0253048327204939], [0.5, 0.5, 0.725, 0.725], [0.5, 0.5, 0.8077747210701756, 0.8077747210701756], [0.5, 0.5, 1.0253048327204939, 0.5126524163602469], [0.5, 0.5, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.5, 0.725, 0.725], [0.8333333333333334, 0.5, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.5, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.5, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.8333333333333334, 0.725, 0.725], [0.16666666666666666, 0.8333333333333334, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.8333333333333334, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.8333333333333334, 0.5126524163602469, 1.0253048327204939], [0.5, 0.8333333333333334, 0.725, 0.725], [0.5, 0.8333333333333334, 0.8077747210701756, 0.8077747210701756], [0.5, 0.8333333333333334, 1.0253048327204939, 0.5126524163602469], [0.5, 0.8333333333333334, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.8333333333333334, 0.725, 0.725]]\n",
            "Add 1 more prior box\n",
            "Additional Scale 0.8077747210701756\n",
            "[[0.16666666666666666, 0.16666666666666666, 0.725, 0.725], [0.16666666666666666, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.5, 0.16666666666666666, 0.725, 0.725], [0.5, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.5, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.5, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.16666666666666666, 0.725, 0.725], [0.8333333333333334, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.5, 0.725, 0.725], [0.16666666666666666, 0.5, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.5, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.5, 0.5126524163602469, 1.0253048327204939], [0.5, 0.5, 0.725, 0.725], [0.5, 0.5, 0.8077747210701756, 0.8077747210701756], [0.5, 0.5, 1.0253048327204939, 0.5126524163602469], [0.5, 0.5, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.5, 0.725, 0.725], [0.8333333333333334, 0.5, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.5, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.5, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.8333333333333334, 0.725, 0.725], [0.16666666666666666, 0.8333333333333334, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.8333333333333334, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.8333333333333334, 0.5126524163602469, 1.0253048327204939], [0.5, 0.8333333333333334, 0.725, 0.725], [0.5, 0.8333333333333334, 0.8077747210701756, 0.8077747210701756], [0.5, 0.8333333333333334, 1.0253048327204939, 0.5126524163602469], [0.5, 0.8333333333333334, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.8333333333333334, 0.725, 0.725], [0.8333333333333334, 0.8333333333333334, 0.8077747210701756, 0.8077747210701756]]\n",
            "For aspect ration 2.0\n",
            "[[0.16666666666666666, 0.16666666666666666, 0.725, 0.725], [0.16666666666666666, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.5, 0.16666666666666666, 0.725, 0.725], [0.5, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.5, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.5, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.16666666666666666, 0.725, 0.725], [0.8333333333333334, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.5, 0.725, 0.725], [0.16666666666666666, 0.5, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.5, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.5, 0.5126524163602469, 1.0253048327204939], [0.5, 0.5, 0.725, 0.725], [0.5, 0.5, 0.8077747210701756, 0.8077747210701756], [0.5, 0.5, 1.0253048327204939, 0.5126524163602469], [0.5, 0.5, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.5, 0.725, 0.725], [0.8333333333333334, 0.5, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.5, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.5, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.8333333333333334, 0.725, 0.725], [0.16666666666666666, 0.8333333333333334, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.8333333333333334, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.8333333333333334, 0.5126524163602469, 1.0253048327204939], [0.5, 0.8333333333333334, 0.725, 0.725], [0.5, 0.8333333333333334, 0.8077747210701756, 0.8077747210701756], [0.5, 0.8333333333333334, 1.0253048327204939, 0.5126524163602469], [0.5, 0.8333333333333334, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.8333333333333334, 0.725, 0.725], [0.8333333333333334, 0.8333333333333334, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.8333333333333334, 1.0253048327204939, 0.5126524163602469]]\n",
            "For aspect ration 0.5\n",
            "[[0.16666666666666666, 0.16666666666666666, 0.725, 0.725], [0.16666666666666666, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.5, 0.16666666666666666, 0.725, 0.725], [0.5, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.5, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.5, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.16666666666666666, 0.725, 0.725], [0.8333333333333334, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.5, 0.725, 0.725], [0.16666666666666666, 0.5, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.5, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.5, 0.5126524163602469, 1.0253048327204939], [0.5, 0.5, 0.725, 0.725], [0.5, 0.5, 0.8077747210701756, 0.8077747210701756], [0.5, 0.5, 1.0253048327204939, 0.5126524163602469], [0.5, 0.5, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.5, 0.725, 0.725], [0.8333333333333334, 0.5, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.5, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.5, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.8333333333333334, 0.725, 0.725], [0.16666666666666666, 0.8333333333333334, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.8333333333333334, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.8333333333333334, 0.5126524163602469, 1.0253048327204939], [0.5, 0.8333333333333334, 0.725, 0.725], [0.5, 0.8333333333333334, 0.8077747210701756, 0.8077747210701756], [0.5, 0.8333333333333334, 1.0253048327204939, 0.5126524163602469], [0.5, 0.8333333333333334, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.8333333333333334, 0.725, 0.725], [0.8333333333333334, 0.8333333333333334, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.8333333333333334, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.8333333333333334, 0.5126524163602469, 1.0253048327204939]]\n",
            "For feature map = conv11_2\n",
            "x,y location on Feature Map(j,i) = (0,0)\n",
            "cx = 0.5 and cy = 0.5\n",
            "For aspect ration 1.0\n",
            "[[0.16666666666666666, 0.16666666666666666, 0.725, 0.725], [0.16666666666666666, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.5, 0.16666666666666666, 0.725, 0.725], [0.5, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.5, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.5, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.16666666666666666, 0.725, 0.725], [0.8333333333333334, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.5, 0.725, 0.725], [0.16666666666666666, 0.5, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.5, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.5, 0.5126524163602469, 1.0253048327204939], [0.5, 0.5, 0.725, 0.725], [0.5, 0.5, 0.8077747210701756, 0.8077747210701756], [0.5, 0.5, 1.0253048327204939, 0.5126524163602469], [0.5, 0.5, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.5, 0.725, 0.725], [0.8333333333333334, 0.5, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.5, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.5, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.8333333333333334, 0.725, 0.725], [0.16666666666666666, 0.8333333333333334, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.8333333333333334, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.8333333333333334, 0.5126524163602469, 1.0253048327204939], [0.5, 0.8333333333333334, 0.725, 0.725], [0.5, 0.8333333333333334, 0.8077747210701756, 0.8077747210701756], [0.5, 0.8333333333333334, 1.0253048327204939, 0.5126524163602469], [0.5, 0.8333333333333334, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.8333333333333334, 0.725, 0.725], [0.8333333333333334, 0.8333333333333334, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.8333333333333334, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.8333333333333334, 0.5126524163602469, 1.0253048327204939], [0.5, 0.5, 0.9, 0.9]]\n",
            "Add 1 more prior box\n",
            "[[0.16666666666666666, 0.16666666666666666, 0.725, 0.725], [0.16666666666666666, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.5, 0.16666666666666666, 0.725, 0.725], [0.5, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.5, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.5, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.16666666666666666, 0.725, 0.725], [0.8333333333333334, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.5, 0.725, 0.725], [0.16666666666666666, 0.5, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.5, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.5, 0.5126524163602469, 1.0253048327204939], [0.5, 0.5, 0.725, 0.725], [0.5, 0.5, 0.8077747210701756, 0.8077747210701756], [0.5, 0.5, 1.0253048327204939, 0.5126524163602469], [0.5, 0.5, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.5, 0.725, 0.725], [0.8333333333333334, 0.5, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.5, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.5, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.8333333333333334, 0.725, 0.725], [0.16666666666666666, 0.8333333333333334, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.8333333333333334, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.8333333333333334, 0.5126524163602469, 1.0253048327204939], [0.5, 0.8333333333333334, 0.725, 0.725], [0.5, 0.8333333333333334, 0.8077747210701756, 0.8077747210701756], [0.5, 0.8333333333333334, 1.0253048327204939, 0.5126524163602469], [0.5, 0.8333333333333334, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.8333333333333334, 0.725, 0.725], [0.8333333333333334, 0.8333333333333334, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.8333333333333334, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.8333333333333334, 0.5126524163602469, 1.0253048327204939], [0.5, 0.5, 0.9, 0.9], [0.5, 0.5, 1.0, 1.0]]\n",
            "For aspect ration 2.0\n",
            "[[0.16666666666666666, 0.16666666666666666, 0.725, 0.725], [0.16666666666666666, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.5, 0.16666666666666666, 0.725, 0.725], [0.5, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.5, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.5, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.16666666666666666, 0.725, 0.725], [0.8333333333333334, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.5, 0.725, 0.725], [0.16666666666666666, 0.5, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.5, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.5, 0.5126524163602469, 1.0253048327204939], [0.5, 0.5, 0.725, 0.725], [0.5, 0.5, 0.8077747210701756, 0.8077747210701756], [0.5, 0.5, 1.0253048327204939, 0.5126524163602469], [0.5, 0.5, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.5, 0.725, 0.725], [0.8333333333333334, 0.5, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.5, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.5, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.8333333333333334, 0.725, 0.725], [0.16666666666666666, 0.8333333333333334, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.8333333333333334, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.8333333333333334, 0.5126524163602469, 1.0253048327204939], [0.5, 0.8333333333333334, 0.725, 0.725], [0.5, 0.8333333333333334, 0.8077747210701756, 0.8077747210701756], [0.5, 0.8333333333333334, 1.0253048327204939, 0.5126524163602469], [0.5, 0.8333333333333334, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.8333333333333334, 0.725, 0.725], [0.8333333333333334, 0.8333333333333334, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.8333333333333334, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.8333333333333334, 0.5126524163602469, 1.0253048327204939], [0.5, 0.5, 0.9, 0.9], [0.5, 0.5, 1.0, 1.0], [0.5, 0.5, 1.2727922061357857, 0.6363961030678927]]\n",
            "For aspect ration 0.5\n",
            "[[0.16666666666666666, 0.16666666666666666, 0.725, 0.725], [0.16666666666666666, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.5, 0.16666666666666666, 0.725, 0.725], [0.5, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.5, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.5, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.16666666666666666, 0.725, 0.725], [0.8333333333333334, 0.16666666666666666, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.16666666666666666, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.16666666666666666, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.5, 0.725, 0.725], [0.16666666666666666, 0.5, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.5, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.5, 0.5126524163602469, 1.0253048327204939], [0.5, 0.5, 0.725, 0.725], [0.5, 0.5, 0.8077747210701756, 0.8077747210701756], [0.5, 0.5, 1.0253048327204939, 0.5126524163602469], [0.5, 0.5, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.5, 0.725, 0.725], [0.8333333333333334, 0.5, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.5, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.5, 0.5126524163602469, 1.0253048327204939], [0.16666666666666666, 0.8333333333333334, 0.725, 0.725], [0.16666666666666666, 0.8333333333333334, 0.8077747210701756, 0.8077747210701756], [0.16666666666666666, 0.8333333333333334, 1.0253048327204939, 0.5126524163602469], [0.16666666666666666, 0.8333333333333334, 0.5126524163602469, 1.0253048327204939], [0.5, 0.8333333333333334, 0.725, 0.725], [0.5, 0.8333333333333334, 0.8077747210701756, 0.8077747210701756], [0.5, 0.8333333333333334, 1.0253048327204939, 0.5126524163602469], [0.5, 0.8333333333333334, 0.5126524163602469, 1.0253048327204939], [0.8333333333333334, 0.8333333333333334, 0.725, 0.725], [0.8333333333333334, 0.8333333333333334, 0.8077747210701756, 0.8077747210701756], [0.8333333333333334, 0.8333333333333334, 1.0253048327204939, 0.5126524163602469], [0.8333333333333334, 0.8333333333333334, 0.5126524163602469, 1.0253048327204939], [0.5, 0.5, 0.9, 0.9], [0.5, 0.5, 1.0, 1.0], [0.5, 0.5, 1.2727922061357857, 0.6363961030678927], [0.5, 0.5, 0.6363961030678928, 1.2727922061357855]]\n",
            "After clamping values between 0 and 1\n",
            " tensor([[0.1667, 0.1667, 0.7250, 0.7250],\n",
            "        [0.1667, 0.1667, 0.8078, 0.8078],\n",
            "        [0.1667, 0.1667, 1.0000, 0.5127],\n",
            "        [0.1667, 0.1667, 0.5127, 1.0000],\n",
            "        [0.5000, 0.1667, 0.7250, 0.7250],\n",
            "        [0.5000, 0.1667, 0.8078, 0.8078],\n",
            "        [0.5000, 0.1667, 1.0000, 0.5127],\n",
            "        [0.5000, 0.1667, 0.5127, 1.0000],\n",
            "        [0.8333, 0.1667, 0.7250, 0.7250],\n",
            "        [0.8333, 0.1667, 0.8078, 0.8078],\n",
            "        [0.8333, 0.1667, 1.0000, 0.5127],\n",
            "        [0.8333, 0.1667, 0.5127, 1.0000],\n",
            "        [0.1667, 0.5000, 0.7250, 0.7250],\n",
            "        [0.1667, 0.5000, 0.8078, 0.8078],\n",
            "        [0.1667, 0.5000, 1.0000, 0.5127],\n",
            "        [0.1667, 0.5000, 0.5127, 1.0000],\n",
            "        [0.5000, 0.5000, 0.7250, 0.7250],\n",
            "        [0.5000, 0.5000, 0.8078, 0.8078],\n",
            "        [0.5000, 0.5000, 1.0000, 0.5127],\n",
            "        [0.5000, 0.5000, 0.5127, 1.0000],\n",
            "        [0.8333, 0.5000, 0.7250, 0.7250],\n",
            "        [0.8333, 0.5000, 0.8078, 0.8078],\n",
            "        [0.8333, 0.5000, 1.0000, 0.5127],\n",
            "        [0.8333, 0.5000, 0.5127, 1.0000],\n",
            "        [0.1667, 0.8333, 0.7250, 0.7250],\n",
            "        [0.1667, 0.8333, 0.8078, 0.8078],\n",
            "        [0.1667, 0.8333, 1.0000, 0.5127],\n",
            "        [0.1667, 0.8333, 0.5127, 1.0000],\n",
            "        [0.5000, 0.8333, 0.7250, 0.7250],\n",
            "        [0.5000, 0.8333, 0.8078, 0.8078],\n",
            "        [0.5000, 0.8333, 1.0000, 0.5127],\n",
            "        [0.5000, 0.8333, 0.5127, 1.0000],\n",
            "        [0.8333, 0.8333, 0.7250, 0.7250],\n",
            "        [0.8333, 0.8333, 0.8078, 0.8078],\n",
            "        [0.8333, 0.8333, 1.0000, 0.5127],\n",
            "        [0.8333, 0.8333, 0.5127, 1.0000],\n",
            "        [0.5000, 0.5000, 0.9000, 0.9000],\n",
            "        [0.5000, 0.5000, 1.0000, 1.0000],\n",
            "        [0.5000, 0.5000, 1.0000, 0.6364],\n",
            "        [0.5000, 0.5000, 0.6364, 1.0000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8Zp8P5Gv7riV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MultiLoss\n",
        "\n",
        "What we have:\n",
        "1. Two  Bounding Boxes corresponding to two objects\n",
        "2. 3 anchor boxes \n",
        "3. True Labels for each bounding boxes\n",
        "\n",
        "What we require:\n",
        "1. Labels for each prior boxes \n",
        "\n",
        "Steps:\n",
        "1. Assign true labels to anchor boxes\n",
        "<br>\n",
        "        For each bounding box :\n",
        "         a. Calculate the overlap with the anchor boxes -Jaccard Index\n",
        "         b. Identify the anchor box with the highest overlap.\n",
        "         c.  Assign the anchor box with the true lable of the bounding box.\n",
        "2. Calculate the Localization Loss(Done only for positive priors)\n",
        "<br>\n",
        "       Use the mask tensor to calculate loss over the relevant anchor boxes offsets.\n",
        "3. Hard Negative Mining\n",
        "4. Calculate the Confidence Loss\n"
      ]
    },
    {
      "metadata": {
        "id": "vQ22PSQ37qqo",
        "colab_type": "code",
        "outputId": "1b3270e8-ba35-4c01-ea16-597f863a10bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        }
      },
      "cell_type": "code",
      "source": [
        "boxes=[[0,0,3,4],[0,0,3,6]]\n",
        "boxes=torch.tensor(boxes,dtype=torch.float)\n",
        "priors=[[0,0,5,4],[0,2.8,3,6],[0,0,4,7],[2.8,2.8,3,6]]\n",
        "priors=torch.tensor(priors,dtype=torch.float)\n",
        "#find_jaccard_overlap(set1,set2)\n",
        "print(\"2 Boundin boxes\\n\",boxes)\n",
        "print(\" 3 Anchor Boxes\\n\",priors)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2 Boundin boxes\n",
            " tensor([[0., 0., 3., 4.],\n",
            "        [0., 0., 3., 6.]])\n",
            " 3 Anchor Boxes\n",
            " tensor([[0.0000, 0.0000, 5.0000, 4.0000],\n",
            "        [0.0000, 2.8000, 3.0000, 6.0000],\n",
            "        [0.0000, 0.0000, 4.0000, 7.0000],\n",
            "        [2.8000, 2.8000, 3.0000, 6.0000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PsExCWRIDf_5",
        "colab_type": "code",
        "outputId": "c03d7908-10ee-4f8d-a2c9-87f8401afe5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "priors_cxcy=xy_to_cxcy(priors)\n",
        "print(priors_cxcy)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2.5000, 2.0000, 5.0000, 4.0000],\n",
            "        [1.5000, 4.4000, 3.0000, 3.2000],\n",
            "        [2.0000, 3.5000, 4.0000, 7.0000],\n",
            "        [2.9000, 4.4000, 0.2000, 3.2000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ilq_4RBX8zMT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step1:\n",
        "1. Assign true labels to anchor boxes\n",
        "<br>\n",
        "        For each bounding box :\n",
        "         a. Calculate the overlap with the anchor boxes -Jaccard Index\n",
        "         b. Identify the anchor box with the highest overlap by making it 1 and the remaining to 0(masking)  if overlap is less tha 0.5 .\n",
        "         c.  Assign the anchor box with the true lable of the bounding box.\n"
      ]
    },
    {
      "metadata": {
        "id": "ZK_saRD27L5r",
        "colab_type": "code",
        "outputId": "edd40c32-6a2a-4953-abe7-e28d6eaf7706",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "#Bounding box = 2\n",
        "labels=torch.tensor([[2],[3]])\n",
        "n_objects=boxes.size(0)\n",
        "overlap=find_jaccard_overlap(boxes,priors)\n",
        "overlap   #2 x 4\n",
        "#Row is the object\n",
        "#COlumn is the priors\n",
        "print(\"Overlap between Bounding Box and Anchor Boxes\\n\",overlap)\n",
        "#Desired Outcome -1. Assign lable of 1st Bounding box to 1st anchor box\n",
        "                  #2. Assign label of 2nd Bounding box to 3rd anchor box"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overlap between Bounding Box and Anchor Boxes\n",
            " tensor([[0.6000, 0.2000, 0.4286, 0.0194],\n",
            "        [0.4615, 0.5333, 0.6429, 0.0356]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Zr9nLATI8-28",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For each prior, find the object that has the maximum overlap"
      ]
    },
    {
      "metadata": {
        "id": "Jk_MFlHg7P2a",
        "colab_type": "code",
        "outputId": "56eb1b62-75e1-48c0-ecdc-32e101e129ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "overlap_for_each_prior, object_for_each_prior=overlap.max(dim=0)\n",
        "print(overlap.max(dim=0))   #4"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([0.6000, 0.5333, 0.6429, 0.0356]), tensor([0, 1, 1, 1]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "He8mCGXO9fFe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For each object.find the prior that has the maximum overlap "
      ]
    },
    {
      "metadata": {
        "id": "ccZBR-oS9Lq_",
        "colab_type": "code",
        "outputId": "caeb813f-2b3b-4b45-aba3-1b5437185137",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "_, prior_for_each_object = overlap.max(dim=1)\n",
        "print(overlap.max(dim=1))  #2"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([0.6000, 0.6429]), tensor([0, 2]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_GlJn43T91ps",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For each priors, assign each object to the corresponding maximum-overlap-prior. (This fixes 1.)\n",
        "            "
      ]
    },
    {
      "metadata": {
        "id": "rLYrcttz9047",
        "colab_type": "code",
        "outputId": "27d0e6a9-4298-4808-878d-2c3d94e6b476",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "object_for_each_prior[prior_for_each_object] = torch.LongTensor(range(n_objects)).to(device)\n",
        "print(\"Identified object for each prior\",object_for_each_prior)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Identified object for each prior tensor([0, 1, 1, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UA6KyrpO-cRq",
        "colab_type": "code",
        "outputId": "9cfa196b-13b6-4462-a9f5-82819a9bd3fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "overlap_for_each_prior[prior_for_each_object] = 1.\n",
        "print(\"Overlap of Identified object for each prior\", overlap_for_each_prior)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overlap of Identified object for each prior tensor([1.0000, 0.5333, 1.0000, 0.0356])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EDCFrDbKC5RT",
        "colab_type": "code",
        "outputId": "97f5ed89-e8bb-4c6c-a00a-7bcceec34890",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "# Encode center-size object coordinates into the form we regressed predicted boxes to\n",
        "true_locs = cxcy_to_gcxgcy(xy_to_cxcy(set1[object_for_each_prior]), priors_cxcy)  # (8732, 4)\n",
        "print(true_locs)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ -2.0000,   0.0000,  -2.5541,   0.0000],\n",
            "        [  0.0000,  -7.5000,   0.0000,   1.1157],\n",
            "        [ -1.2500,  -2.1429,  -1.4384,  -2.7981],\n",
            "        [-70.0000,  -7.5000,  13.5402,   1.1157]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-xeZR5nXC3Bw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "threshold=0.5\n",
        "# Labels for each prior\n",
        "label_for_each_prior = labels[object_for_each_prior]  # (3)\n",
        "# Set priors whose overlaps with objects are less than the threshold to be background (no object)\n",
        "label_for_each_prior[overlap_for_each_prior < threshold] = 0  # (8732)\n",
        "\n",
        "# Store\n",
        "true_classes = label_for_each_prior"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RXkptD_HGR33",
        "colab_type": "code",
        "outputId": "b6a48f25-5c55-4217-a638-a2cd0dd4ed91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "label_for_each_prior"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2],\n",
              "        [3],\n",
              "        [3],\n",
              "        [0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "metadata": {
        "id": "Wl0RiuB6LYeD",
        "colab_type": "code",
        "outputId": "aff29083-dfcc-43f5-d1e0-da61eddc876a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "positive_priors = true_classes != 0  # (N, 8732)\n",
        "print(\"Mask tensor\",positive_priors)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mask tensor tensor([[1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0]], dtype=torch.uint8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6nhRQCujTsNP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Step 3: Hard Negative Mining\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "xRRpZ4CcRPYo",
        "colab_type": "code",
        "outputId": "588433e2-1c8c-4a76-e501-9c6e97f9f8bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "positive_priors.sum(dim=1)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "metadata": {
        "id": "3yZvqRX0Q1Ap",
        "colab_type": "code",
        "outputId": "bee1f422-a066-41dc-d5c5-149492489a50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "neg_pos_ratio=3\n",
        "n_positives = positive_priors.sum(dim=0)  # (N)\n",
        "n_hard_negatives = neg_pos_ratio * n_positives  # (N)\n",
        "print(n_positives,n_hard_negatives)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([3]) tensor([9])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}