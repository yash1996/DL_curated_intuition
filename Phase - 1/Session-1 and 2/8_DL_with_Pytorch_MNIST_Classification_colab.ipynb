{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1a991e7f539673da033393d34767c7335318ab9a",
    "colab_type": "text",
    "id": "9Vvp6QLz4C9y"
   },
   "source": [
    "**Agenda:**\n",
    "<br>\n",
    "For this tutorial in  Deep Learning(DL) with Pytorch, we are going to explore Multi Layered Perceptron architecture and learn Pytorch by implementing  algorithms under a certain usecase.We will cover the following:\n",
    "1. Deep Learning basics with Pytorch\n",
    "2. Multilayered Perceptron (MLP) implemention on  MNIST\n",
    "<br>\n",
    "\n",
    "Lets get started !!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8f02da80b362a4233b75cb0f9e9656525e37befa",
    "colab_type": "text",
    "id": "L45gM0dy4C9z"
   },
   "source": [
    "![](images/mlp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6145a827010b47e713d5bcdb6f89d8042040d75f",
    "colab_type": "text",
    "id": "FtyNV4e_4C91"
   },
   "source": [
    "# **1. Deep Learning basics with Pytorch**\n",
    "<br>\n",
    "In this part we will cover the following:\n",
    "\n",
    "1. Learn to play with tensors on numpy and pytorch \n",
    "2. Learn to build a simple feed forward network from scratch with random data \n",
    "3. Learn to build an end to end MLP for MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vDr4q0SY4C93"
   },
   "source": [
    "##  Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-29T06:23:59.969638Z",
     "start_time": "2019-06-29T06:22:56.981582Z"
    },
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FqzxX9Xy4C94",
    "outputId": "6495dd77-e8e8-4c1d-ce2a-57baf1f2a631"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Version: 1.1.0\n"
     ]
    }
   ],
   "source": [
    "#!pip3 install torch torchvision\n",
    "\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "#print(\"List of files\",os.listdir(\"../input\"))\n",
    "import torch\n",
    "import numpy as np\n",
    "print(\"Torch Version:\",torch.__version__)\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1e8017c3ed94f083df4e2bf071f7f5f422c40ca1",
    "colab_type": "text",
    "id": "XZ1sqauc4C98"
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_uuid": "8f08b918b1e2513ad7c1f382cfba39b0205aba6e",
    "colab": {},
    "colab_type": "code",
    "id": "m4BiKJI74C99"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def test_network(net, trainloader):\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "    dataiter = iter(trainloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    # Create Variables for the inputs and targets\n",
    "    inputs = Variable(images)\n",
    "    targets = Variable(images)\n",
    "\n",
    "    # Clear the gradients from all Variables\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass, then backward pass, then update weights\n",
    "    output = net.forward(inputs)\n",
    "    loss = criterion(output, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def imshow(image, ax=None, title=None, normalize=True):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "\n",
    "    if normalize:\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        image = std * image + mean\n",
    "        image = np.clip(image, 0, 1)\n",
    "\n",
    "    ax.imshow(image)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.tick_params(axis='both', length=0)\n",
    "    ax.set_xticklabels('')\n",
    "    ax.set_yticklabels('')\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def view_recon(img, recon):\n",
    "    ''' Function for displaying an image (as a PyTorch Tensor) and its\n",
    "        reconstruction also a PyTorch Tensor\n",
    "    '''\n",
    "\n",
    "    fig, axes = plt.subplots(ncols=2, sharex=True, sharey=True)\n",
    "    axes[0].imshow(img.numpy().squeeze())\n",
    "    axes[1].imshow(recon.data.numpy().squeeze())\n",
    "    for ax in axes:\n",
    "        ax.axis('off')\n",
    "        ax.set_adjustable('box-forced')\n",
    "\n",
    "def view_classify(img, ps, version=\"MNIST\"):\n",
    "    ''' Function for viewing an image and it's predicted classes.\n",
    "    '''\n",
    "    ps = ps.data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(np.arange(10), ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    if version == \"MNIST\":\n",
    "        ax2.set_yticklabels(np.arange(10))\n",
    "    elif version == \"Fashion\":\n",
    "        ax2.set_yticklabels(['T-shirt/top',\n",
    "                            'Trouser',\n",
    "                            'Pullover',\n",
    "                            'Dress',\n",
    "                            'Coat',\n",
    "                            'Sandal',\n",
    "                            'Shirt',\n",
    "                            'Sneaker',\n",
    "                            'Bag',\n",
    "                            'Ankle Boot'], size='small');\n",
    "    ax2.set_title('Class Probability')\n",
    "    ax2.set_xlim(0, 1.1)\n",
    "\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cc2337505994f4530913183436b9f4bf8a118599",
    "colab_type": "text",
    "id": "YAYW22Rh4C-B"
   },
   "source": [
    "## Tensors\n",
    "It turns out neural network computations are just a bunch of linear algebra operations on *tensors*, a generalization of matrices. A vector is a 1-dimensional tensor, a matrix is a 2-dimensional tensor, an array with three indices is a 3-dimensional tensor (RGB color images for example). The fundamental data structure for neural networks are tensors and PyTorch (as well as pretty much every other deep learning framework) is built around tensors.\n",
    "\n",
    "Tensors are similar to NumPyâ€™s ndarrays, with the addition being that Tensors can also be used on a GPU to accelerate computing.\n",
    "\n",
    "<img src=\"images/tensor_examples.svg\" width=600px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iB71Npbp4C-C"
   },
   "source": [
    "### Construct a randomly initialized 5x3 matrix:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T11:21:36.971841Z",
     "start_time": "2019-02-04T11:21:36.623384Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "oLdA8qkA4C-D",
    "outputId": "7e405385-94ae-4b9d-a760-669b19cb18ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9768, 0.4626, 0.4697],\n",
      "        [0.6264, 0.5623, 0.8074],\n",
      "        [0.2413, 0.3968, 0.8782],\n",
      "        [0.5647, 0.7554, 0.1240],\n",
      "        [0.1027, 0.4617, 0.4611]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FdMjupDY4C-H"
   },
   "source": [
    "### Construct a tensor directly from data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T11:22:21.040158Z",
     "start_time": "2019-02-04T11:22:21.033606Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7KjxFCsl4C-I",
    "outputId": "85148122-bdea-4f76-988a-7f49c90ff044"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1afe587702c9d925968dc34d4e7f515b700d9089",
    "colab_type": "text",
    "id": "N2_NMiwy4C-M"
   },
   "source": [
    "### Numpy to Torch and back\n",
    "\n",
    "PyTorch has a great feature for converting between Numpy arrays and Torch tensors. Let us see how easy it is to switch between the two\n",
    "\n",
    "### Ceate a tensor using numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "35d8b903e1564ee833e2d0ed2ea00d40b61aa16e",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "lfm27TeL4C-M",
    "outputId": "08e2244b-2f09-40c9-bbcd-82082c3b1c3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Numpy array:\n",
      " [[-0.02647265  0.10582354  0.13038732]\n",
      " [-1.34244932  0.35982855  0.70407106]\n",
      " [ 1.52964114 -0.29781545 -0.62033849]\n",
      " [ 0.96108999 -1.24624232  1.94094033]\n",
      " [-0.51059626  0.36401938 -0.5627018 ]]\n"
     ]
    }
   ],
   "source": [
    "np_array=np.random.randn(5,3)\n",
    "print(f' Numpy array:\\n {np_array}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1d82db999b723fa737510352cf47d96a62b8d63b",
    "colab_type": "text",
    "id": "Nq9cmqeH4C-S"
   },
   "source": [
    "### Convert to torch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "1cbd6fd48cf54645f924d354fc9fb5856bf1ddc1",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "yTcHR5qk4C-U",
    "outputId": "580311f0-8eba-4075-937d-a7736423efed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch tensor:\n",
      " tensor([[-0.0265,  0.1058,  0.1304],\n",
      "        [-1.3424,  0.3598,  0.7041],\n",
      "        [ 1.5296, -0.2978, -0.6203],\n",
      "        [ 0.9611, -1.2462,  1.9409],\n",
      "        [-0.5106,  0.3640, -0.5627]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "torch_tensor=torch.from_numpy(np_array)\n",
    "print(f'Torch tensor:\\n {torch_tensor}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "31fe8979751ba061cc81055bbc5079bed1cb0124",
    "colab_type": "text",
    "id": "13IACWyu4C-Y"
   },
   "source": [
    "### Convert back to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "e72bac0d8c4870f97b1d1724c0bce3fd84b50450",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "403oY_8S4C-Z",
    "outputId": "f31fec4e-9cdc-42ce-8a01-8bf46bd40cb0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02647265,  0.10582354,  0.13038732],\n",
       "       [-1.34244932,  0.35982855,  0.70407106],\n",
       "       [ 1.52964114, -0.29781545, -0.62033849],\n",
       "       [ 0.96108999, -1.24624232,  1.94094033],\n",
       "       [-0.51059626,  0.36401938, -0.5627018 ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_tensor.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "532f4e612d823389740276fdb2f1d0c9d69cb78d",
    "colab_type": "text",
    "id": "9JtXENQc4C-c"
   },
   "source": [
    "***An important thing to note here is memory is shared between the Numpy array and Torch tensor, so if you change the values in-place of one object, the other will change as well.*       \n",
    "Let see what does it mean**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "7a08bc968bbb69b18d7d376748f7a5333f931efe",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "OK9LEQa-4C-d",
    "outputId": "fc9e7eda-846e-4974-e0ae-d014acffe44d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.9735, 2.1058, 2.1304],\n",
       "        [0.6576, 2.3598, 2.7041],\n",
       "        [3.5296, 1.7022, 1.3797],\n",
       "        [2.9611, 0.7538, 3.9409],\n",
       "        [1.4894, 2.3640, 1.4373]], dtype=torch.float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add 2 to PyTorch Tensor, in place\n",
    "torch_tensor.add_(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "15c233bd4f3539d1cf8c07878d01802607a6ab89",
    "colab_type": "text",
    "id": "a8gtGecL4C-h"
   },
   "source": [
    "###  Numpy array matches new values from Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "3d4047f95de1ca8055e276de3246da2c6a01ccee",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "H9FKs6dC4C-j",
    "outputId": "0a1e9c2f-6a72-40a4-865f-2084fd583c6d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.97352735, 2.10582354, 2.13038732],\n",
       "       [0.65755068, 2.35982855, 2.70407106],\n",
       "       [3.52964114, 1.70218455, 1.37966151],\n",
       "       [2.96108999, 0.75375768, 3.94094033],\n",
       "       [1.48940374, 2.36401938, 1.4372982 ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b183396c1d82a600e1c3b1848e94e3ce5a6fbe28",
    "colab_type": "text",
    "id": "MlIiUgFz4C-o"
   },
   "source": [
    " ## Simple Neural Network using Pytorch \n",
    " Let us see how we can use PyTorch to build a simple neural network.\n",
    "![](images/simple_neuron.PNG)\n",
    "\n",
    "Mathematically this looks like: \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "y &= f(w_1 x_1 + w_2 x_2 + b) \\\\\n",
    "y &= f\\left(\\sum_i w_i x_i +b \\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "With vectors this is the dot/inner product of two vectors:\n",
    "\n",
    "$$\n",
    "h = \\begin{bmatrix}\n",
    "x_1 \\, x_2 \\cdots  x_n\n",
    "\\end{bmatrix}\n",
    "\\cdot \n",
    "\\begin{bmatrix}\n",
    "           w_1 \\\\\n",
    "           w_2 \\\\\n",
    "           \\vdots \\\\\n",
    "           w_n\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "496c485f3e7f43a27bdce042df78fa11eb296631",
    "colab_type": "text",
    "id": "-YeLMTFM4C-p"
   },
   "source": [
    "With the basics covered, it's time to explore how we can use PyTorch to build a simple neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "93562b119ff2797b3660bb0968bc6c31e890b7e5",
    "colab_type": "text",
    "id": "08TbB9Sm4C-q"
   },
   "source": [
    "###  Generate some random data \n",
    " We will create a tensor with shape (1, 5), one row and five columns, that contains values randomly distributed according to the normal distribution with a mean of zero and standard deviation of one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "fd1ee538877f19c8a2cfac8ea123ecbdb2f4a94d",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "NWB4MQuu4C-r",
    "outputId": "6403240d-eeb5-468a-a3ff-d6a66e138eee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Inout features:3\n"
     ]
    }
   ],
   "source": [
    "features=torch.randn(1,3)\n",
    "print(f'Number of Inout features:{features.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b0673d28508dd5eed49da6731c4cc1408f1efd5c",
    "colab_type": "text",
    "id": "oABNl_OM4C-x"
   },
   "source": [
    "### Initialize Weights and Biases "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7f39730f8dbaff0834b223744d0bab6bfc516e2c",
    "colab_type": "text",
    "id": "rBChM5NH4C-y"
   },
   "source": [
    "Weights = torch.randn_like(features) creates another tensor with the same shape as features, again containing values from a normal distribution.\n",
    "\n",
    "Finally, bias = torch.randn((1, 1)) creates a single value from a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_uuid": "3d2b5d527e0650f3d3c1942a5ee1da56bbbac7de",
    "colab": {},
    "colab_type": "code",
    "id": "i92IlQIC4C-z"
   },
   "outputs": [],
   "source": [
    "n_input=features.shape[1]   #3 input neuron\n",
    "n_hidden=2     #two hidden neuron\n",
    "n_output=1     #one output neuron\n",
    "#Weights for input to hidden layer\n",
    "W1=torch.randn(n_input,n_hidden)\n",
    "W2=torch.randn(n_hidden,n_output)\n",
    "#Bias term for hidden and output layer\n",
    "B1=torch.randn(n_hidden)\n",
    "B2=torch.randn(n_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_uuid": "cd62c805fb7363693b56ec9dbcd00a8c404adcba",
    "colab": {},
    "colab_type": "code",
    "id": "hjlSRWiu4C-3"
   },
   "outputs": [],
   "source": [
    "#Using a Sigmoid Activation Function\n",
    "def activation(x):\n",
    "    return(1/1+torch.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fbfeec62cfa4a35cb829897b71a4450b70ec8392",
    "colab_type": "text",
    "id": "DrWzkrnk4C-7"
   },
   "source": [
    "### Calculate Weight and Biases\n",
    "We will calculate the output for this multi-layer network using the weights `W1` & `W2`, and the biases, `B1` & `B2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "bd98acc8aa8bb1d2fe06cb77ffd4a5054c07a40b",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "zC2QQjr24C-8",
    "outputId": "a0442f80-59e9-4eb2-bc96-9df1f949d29f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer activations:tensor([[2.9791, 1.2008]])\n",
      "Output of the network:tensor([[1.1576]])\n"
     ]
    }
   ],
   "source": [
    "h1=activation(torch.matmul(features,W1)+B1)\n",
    "print(f'Hidden Layer activations:{h1}')\n",
    "out=activation(torch.matmul(h1,W2)+B2)\n",
    "print(f'Output of the network:{out}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "21b8946d94159fc86b191a82bbbb4e34d2289f53",
    "colab_type": "text",
    "id": "xe4vu51K4C_I"
   },
   "source": [
    "## Building our Network\n",
    "Now we're going to build a larger network that can solve a (formerly) difficult problem, identifying text in an image using MNIST data\n",
    "For now our goal will be to build a neural network that can take one of these images and predict the digit in the image.First, let's try to build this network for this dataset using weight matrices and matrix multiplications. Then, we'll see how to do it using PyTorch's `nn` module which provides a much more convenient and powerful method for defining network architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c4c2229e3f3534db73e8d22ba73485022765f3af",
    "colab_type": "text",
    "id": "rsLM8Yc14C_J"
   },
   "source": [
    "![](images/mnist.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_uuid": "d2974386321060bd66905127f3a48b9f1b177310",
    "colab": {},
    "colab_type": "code",
    "id": "uoGmSr6P4C_K"
   },
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import helper\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "237092ef839e8201ecc710f53ed7154e0f865b2e",
    "colab_type": "text",
    "id": "jMGNnSoA4C_O"
   },
   "source": [
    "### Load Dataset \n",
    "First up, we need to get our dataset.Right now we will be using MNIST dataset which is already in`torchvision` package. The code below will download the MNIST dataset, then create training and test datasets for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T11:27:05.872957Z",
     "start_time": "2019-02-04T11:26:45.305539Z"
    },
    "_uuid": "45cde9b49e2c0e1802ff640ebab0d766233e6abe",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "Gt1AQ86c4C_P",
    "outputId": "20fe4e7d-01a7-47ea-d509-b9f71d90eafe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9920512it [00:00, 27181756.88it/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32768it [00:00, 447175.53it/s]\n",
      "  1%|          | 16384/1648877 [00:00<00:11, 145553.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1654784it [00:00, 7246505.93it/s]                            \n",
      "8192it [00:00, 180111.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jExiHh8b4C_T"
   },
   "source": [
    "#### what is dataset ?\n",
    "Dataset contains two data methods `__getitem__` and `__len__` so using these methods. we can directly call a single data with index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T11:31:37.364338Z",
     "start_time": "2019-02-04T11:31:37.283418Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "_vzZQG7M4C_U",
    "outputId": "97e9db3e-ac54-4529-fd1e-ab5ac3154da7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
       "           0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
       "           0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
       "           0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
       "           0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
       "           0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
       "           0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
       "           0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
       "           0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
       "           0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
       "           0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
       "           0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
       "           0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
       "           0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]), 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# like this way\n",
    "trainset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fx2u1ci_4C_X"
   },
   "source": [
    "#### what is dataloader?\n",
    "\n",
    "It simply uses the generator to provide data giving single- or multi-process iterators over the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "00ab24a0af33038559ec91ea83458558e4d574bf",
    "colab_type": "text",
    "id": "YKA5zpwB4C_X"
   },
   "source": [
    "We have the training data loaded into trainloader \n",
    "\n",
    "With dataloaded we make  an iterator with iter(trainloader). Later, we'll use this to loop through the dataset for training, like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T11:38:04.781132Z",
     "start_time": "2019-02-04T11:38:04.633040Z"
    },
    "_uuid": "9808e8dab8f56248ae40759f20b1e59dad3ede7b",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "kjMIXE_t4C_Y",
    "outputId": "42381cd6-0d57-4116-f017-43e77abecefc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "#Printing the size of one image\n",
    "print(images[1].numpy().squeeze().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "f544046855f3efd0eb1d88fb11f0e4e27318d5eb",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "FIto5Wet4C_b",
    "outputId": "db3b46e1-76b0-4889-e7a7-c740d75ce642"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      },
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Look at the image\n",
    "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T11:38:08.273406Z",
     "start_time": "2019-02-04T11:38:08.264208Z"
    },
    "_uuid": "b11c0c543d20cfb96cbb0635eea5f93e37c58cb0",
    "colab": {},
    "colab_type": "code",
    "id": "UDqvWprf4C_d"
   },
   "outputs": [],
   "source": [
    "#Sigmoid Activation Function\n",
    "def activation(x):\n",
    "    return (1/(1+torch.exp(-x)))\n",
    "\n",
    "#Input 64x784\n",
    "inputs=images.view(images.shape[0],-1)\n",
    "#Number of input features-784\n",
    "n_input=inputs.shape[1]\n",
    "#Number of neurons in hidden layer-256\n",
    "n_hidden=256\n",
    "#Number of output neuron-10\n",
    "n_out=10\n",
    "#Weight at hidden neuron-784x256\n",
    "W1=torch.randn(n_input,n_hidden)\n",
    "#Bias at hidden neuron-256\n",
    "B1=torch.randn(n_hidden)\n",
    "#Weight at output neuron-256x10\n",
    "W2=torch.randn(n_hidden,n_out)\n",
    "#Bias at output neuron-10\n",
    "B2=torch.randn(n_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T11:38:13.520858Z",
     "start_time": "2019-02-04T11:38:13.510149Z"
    },
    "_uuid": "e494abcbcf8bf4e1210b1acdc0790ca77f826e21",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "q0RLuvzt4C_h",
    "outputId": "e0a380f7-f121-46f3-feeb-51af844510e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of a batch of an image: torch.Size([64, 1, 28, 28])\n",
      "Shape of the input to the network: torch.Size([64, 784])\n",
      "Shape of the input features: 784\n",
      "Shape of the Weight matrix of neurons in the hidden layer torch.Size([784, 256])\n",
      "Shape of the Bias vector of neurons in the hidden layer torch.Size([256])\n",
      "Shape of the Weight matrix of neurons in the output layer torch.Size([256, 10])\n",
      "Shape of the Bias vector of neurons in the output layer torch.Size([256, 10])\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of a batch of an image:\",images.shape)\n",
    "print(\"Shape of the input to the network:\",inputs.shape)\n",
    "print(\"Shape of the input features:\",n_input)\n",
    "print(\"Shape of the Weight matrix of neurons in the hidden layer\",W1.shape)\n",
    "print(\"Shape of the Bias vector of neurons in the hidden layer\",B1.shape)\n",
    "print(\"Shape of the Weight matrix of neurons in the output layer\",W2.shape)\n",
    "print(\"Shape of the Bias vector of neurons in the output layer\",W2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T11:38:23.336380Z",
     "start_time": "2019-02-04T11:38:22.958331Z"
    },
    "_uuid": "e751026ecf95253bf33db0462ce8bc250c082bb7",
    "colab": {},
    "colab_type": "code",
    "id": "lFz3MRF04C_l"
   },
   "outputs": [],
   "source": [
    "#Hidden layer activations\n",
    "h1=activation(torch.mm(inputs,W1)+B1)\n",
    "#Output layer activations\n",
    "out=activation(torch.mm(h1,W2)+B2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T11:38:26.658141Z",
     "start_time": "2019-02-04T11:38:26.649686Z"
    },
    "_uuid": "2cb2a0f4a6d9852da5d4811e89734c8906bbb878",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "jkUmaAhH4C_o",
    "outputId": "f9c1e1a8-9268-4538-8a4b-d4e2c5303463"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the Hidden activation of the networktorch.Size([64, 256])\n",
      "Shape of the Output of the networktorch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of the Hidden activation of the network{h1.shape}')\n",
    "print(f'Shape of the Output of the network{out.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T11:38:38.560819Z",
     "start_time": "2019-02-04T11:38:38.553507Z"
    },
    "_uuid": "66671445031ee39d4142f84c832b2ab097f6d14a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "VPibe5io4C_r",
    "outputId": "db305839-0697-4db5-c013-91fd70be9594"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9.2154e-01, 4.1177e-05, 1.0000e+00, 9.9978e-01, 7.6175e-01, 1.3460e-03,\n",
       "        1.0000e+00, 1.4779e-06, 6.7857e-04, 1.0000e+00])"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let us see the network output to one of the feeded input image\n",
    "out[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8c7ab4cad2d8a2d619e0b376780e0d5b2dfa7be3",
    "colab_type": "text",
    "id": "XPPcsO9m4C_u"
   },
   "source": [
    "Now we have 10 outputs for our network. This raw output is usually called **logits or scores**.\n",
    "<br>\n",
    "However,We want to pass in an image to our network and get out a probability distribution over the classes that tells us the likely class(es) the image belongs to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1903f5520e57c8ca69b4252ed7a7c4d5e5beb51a",
    "colab_type": "text",
    "id": "DjJ4RkZZ4C_u"
   },
   "source": [
    "\n",
    "### Probability Distribution using Softmax\n",
    "To calculate this probability distribution, we often use the [softmax function](https://en.wikipedia.org/wiki/Softmax_function)\n",
    "$$\n",
    "\\Large \\sigma(x_i) = \\cfrac{e^{x_i}}{\\sum_k^K{e^{x_k}}}\n",
    "$$\n",
    "What this does is squish each input $x_i$ between 0 and 1 and normalizes the values to give you a proper probability distribution where the probabilites sum up to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T11:40:41.701155Z",
     "start_time": "2019-02-04T11:40:41.697492Z"
    },
    "_uuid": "f4d7ba5cc02acf1610fa113490099e51e84978aa",
    "colab": {},
    "colab_type": "code",
    "id": "S188ENAT4C_v"
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return(torch.exp(x)/torch.sum(torch.exp(x),dim=1).view(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bdf3ab4229b26432555148c0d1b67f6e857055e6",
    "colab_type": "text",
    "id": "3a7zi3F-4C_x"
   },
   "source": [
    "Let us understand what we are doing above by an example\n",
    "<br>\n",
    "Step 1:Calculating the numerator of the softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T11:40:42.976206Z",
     "start_time": "2019-02-04T11:40:42.970484Z"
    },
    "_uuid": "d06ddfc05e73456929293906a0ee9672cf2f45a6",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "eStL6dvV4C_y",
    "outputId": "e7377417-7d80-41e4-d313-ec5a7747d512"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.5132, 1.0000, 2.7183, 2.7177, 2.1420, 1.0013, 2.7183, 1.0000, 1.0007,\n",
       "         2.7183],\n",
       "        [2.7082, 1.0000, 2.7157, 2.7183, 1.0645, 1.0001, 2.7183, 1.0054, 1.0000,\n",
       "         2.7181]])"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(out[1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0fd149046af107a72d73208528b3a5cf1a6eb13e",
    "colab_type": "text",
    "id": "01A27TNB4C_1"
   },
   "source": [
    "Step 2:For every predicted image output, calculate the sum over the predicted values over all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T11:40:45.248689Z",
     "start_time": "2019-02-04T11:40:45.236760Z"
    },
    "_uuid": "2277f07ce4566f91bf8ad70e3969f2c4790e676d",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "52l7XpZ64C_2",
    "outputId": "4f3d8491-2261-413b-bf61-3eccfcac40ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([19.5298, 18.6485])"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(torch.sum(torch.exp(out[1:3])))\n",
    "#Dim=1 says, we want to take the sum across all columns\n",
    "torch.sum(torch.exp(out[1:3]),dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e247c285cf5dfdd02702bc79ddc8e49383bc17c1",
    "colab_type": "text",
    "id": "SRB2MTph4C_6"
   },
   "source": [
    "Step3:Rearrange the sums in an order for broadcasting to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T11:40:47.116271Z",
     "start_time": "2019-02-04T11:40:47.106860Z"
    },
    "_uuid": "8c226fe7a4a2e9f31f63ddca18ed71959d9a139d",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "CGMlnjDl4C_6",
    "outputId": "e80a3d3c-980b-4527-98f6-19125a487c92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19.5298],\n",
       "        [18.6485]])"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.exp(out[1:3]),dim=1).view(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ecbcd104b966f3ae051d09048e7d708f992f1a41",
    "colab_type": "text",
    "id": "rM6w5dmi4C_9"
   },
   "source": [
    "Step 3:For every predicted image output, divide the predictions of each class with the sum over all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T11:41:41.871814Z",
     "start_time": "2019-02-04T11:41:41.808608Z"
    },
    "_uuid": "fce3f0e89d812e35f44a46ee5eab0fc85bf05406",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "aDOCWoIb4C__",
    "outputId": "c1f2c861-e946-480d-aeb7-59611908f1a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1287, 0.0512, 0.1392, 0.1392, 0.1097, 0.0513, 0.1392, 0.0512, 0.0512,\n",
      "         0.1392],\n",
      "        [0.1452, 0.0536, 0.1456, 0.1458, 0.0571, 0.0536, 0.1458, 0.0539, 0.0536,\n",
      "         0.1458]])\n"
     ]
    }
   ],
   "source": [
    "#print(torch.exp(out[1:3])/torch.sum(torch.exp(out[1:3]),dim=1))\n",
    "temp=torch.exp(out[1:3])/torch.sum(torch.exp(out[1:3]),dim=1).view(-1,1)\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0973f2a30eacf6d699df25a24ce00f9487f35559",
    "colab_type": "text",
    "id": "6l9keIdD4DAB"
   },
   "source": [
    "Voila!! We got the softmax output .One last thing to do is check whether the sum across all classes sum to 1 for understanding the predicted class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "5f899daaaf970fbb7b821a9cf4f70af1b00a9773",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "nalYGtoG4DAC",
    "outputId": "652ae82c-823a-41d1-ffa8-3682f6c45e0a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1.])"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "da2f00d033b1ef41cf3941998ef34e24167a08cc",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "QaVOzTEm4DAF",
    "outputId": "4ffeb7aa-2f9e-4c76-ef09-9c6cf1ed066e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "probabilities = softmax(out)\n",
    "# Does it have the right shape? Should be (64, 10)\n",
    "print(probabilities.shape)\n",
    "# Does it sum to 1?\n",
    "#print(probabilities.sum(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f9cd86feb1156d1a7ba69037197aabf876735be6",
    "colab_type": "text",
    "id": "Ecm_JHVC4DAL"
   },
   "source": [
    "## Building our Network with Pytorch\n",
    "\n",
    "![](images/mlp_mnist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6b0737a96ecaa7d4bcd0f6bc4592961e5ffc8e42",
    "colab_type": "text",
    "id": "dWd6P2hG4DAM"
   },
   "source": [
    "PyTorch provides a module `nn` that makes building networks much simpler. Here I'll show you how to build the same one as above with 784 inputs, 256 hidden units, 10 output units and a softmax output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_uuid": "e82cac77674746147dc9dd5d9367b21c1e02d40c",
    "colab": {},
    "colab_type": "code",
    "id": "DVkq49YW4DAN"
   },
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_uuid": "72a3786079aa4a387146ff066176d5af56b11b4b",
    "colab": {},
    "colab_type": "code",
    "id": "Tsob_Rb54DAR"
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden=nn.Linear(784,256)\n",
    "        self.output=nn.Linear(256,10)\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "        self.softmax=nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.hidden(x)\n",
    "        x=self.sigmoid(x)\n",
    "        x=self.output(x)\n",
    "        x=self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b1546fd3ac7e6ab35a81dfee3e704817627a5618",
    "colab_type": "text",
    "id": "NmsMC3m_4DAY"
   },
   "source": [
    "Let's go through this bit by bit.\n",
    "\n",
    "```python\n",
    "class Network(nn.Module):\n",
    "```\n",
    "\n",
    "Here we're inheriting from `nn.Module`. Combined with `super().__init__()` this creates a class that tracks the architecture and provides a lot of useful methods and attributes. It is mandatory to inherit from `nn.Module` when you're creating a class for your network. The name of the class itself can be anything.\n",
    "\n",
    "```python\n",
    "self.hidden = nn.Linear(784, 256)\n",
    "```\n",
    "\n",
    "This line creates a module for a linear transformation, $x\\mathbf{W} + b$, with 784 inputs and 256 outputs and assigns it to `self.hidden`. The module automatically creates the weight and bias tensors which we'll use in the `forward` method. You can access the weight and bias tensors once the network once it's create at `net.hidden.weight` and `net.hidden.bias`.\n",
    "\n",
    "```python\n",
    "self.output = nn.Linear(256, 10)\n",
    "```\n",
    "\n",
    "Similarly, this creates another linear transformation with 256 inputs and 10 outputs.\n",
    "\n",
    "```python\n",
    "self.sigmoid = nn.Sigmoid()\n",
    "self.softmax = nn.Softmax(dim=1)\n",
    "```\n",
    "\n",
    "Here I defined operations for the sigmoid activation and softmax output. Setting `dim=1` in `nn.Softmax(dim=1)` calculates softmax across the columns.\n",
    "\n",
    "```python\n",
    "def forward(self, x):\n",
    "```\n",
    "\n",
    "PyTorch networks created with `nn.Module` must have a `forward` method defined. It takes in a tensor `x` and passes it through the operations you defined in the `__init__` method.\n",
    "\n",
    "```python\n",
    "x = self.hidden(x)\n",
    "x = self.sigmoid(x)\n",
    "x = self.output(x)\n",
    "x = self.softmax(x)\n",
    "```\n",
    "\n",
    "Here the input tensor `x` is passed through each operation a reassigned to `x`. We can see that the input tensor goes through the hidden layer, then a sigmoid function, then the output layer, and finally the softmax function. It doesn't matter what you name the variables here, as long as the inputs and outputs of the operations match the network architecture you want to build. The order in which you define things in the `__init__` method doesn't matter, but you'll need to sequence the operations correctly in the `forward` method.\n",
    "\n",
    "Now we can create a `Network` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "36bc9a286ffafd0a0b1ac7890906092965f5fee0",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "5mUYbFw94DAZ",
    "outputId": "1902590e-2502-4e52-ac86-a199f16872df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "aae8f6f5e7c42a3df7d79b6e3a20293f3a673b0a",
    "colab_type": "text",
    "id": "xvFaVwHN4DAf"
   },
   "source": [
    "We can define the network somewhat more concisely and clearly using the `torch.nn.functional` module. This is the most common way you'll see networks defined as many operations are simple element-wise functions. We normally import this module as `F`, `import torch.nn.functional as F`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_uuid": "1ebea291b4d96d74d435885e60bc2a792c4abd12",
    "colab": {},
    "colab_type": "code",
    "id": "y1CX1qWJ4DAg"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_uuid": "41e688fd7486e6ac4ea420cdc23e464a4e2c3432",
    "colab": {},
    "colab_type": "code",
    "id": "KJU1PQUE4DAi"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Inputs to hidden layer linear transformation\n",
    "        self.hidden = nn.Linear(784, 128)\n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.output = nn.Linear(128, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Hidden layer with sigmoid activation\n",
    "        x = F.sigmoid(self.hidden(x))\n",
    "        # Output layer with softmax activation\n",
    "        x = F.softmax(self.output(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_uuid": "30f4a6c129eb490f265d2570e16f86dc96534952",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "zaUQd7194DAj",
    "outputId": "05c6eb79-11d0-4094-e6af-b8684f110965"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (hidden): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8c3820bb60313a368c0a3d8322b21b7d8adeafeb",
    "colab_type": "text",
    "id": "lqLdKq2v4DAq"
   },
   "source": [
    "### Initializing weights and biases\n",
    "\n",
    "The weights and bias are automatically initialized for you, but it's possible to customize how they are initialized. The weights and biases are tensors attached to the layer you defined, you can get them with `model.fc1.weight` for instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_uuid": "d148d7e2446d76d5ca6a8948d23ec513f103cdba",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 650
    },
    "colab_type": "code",
    "id": "BIEIlmhV4DAv",
    "outputId": "7287b601-3963-4231-a792-df95bdcb5b3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0197, -0.0116,  0.0058,  ...,  0.0302,  0.0299, -0.0343],\n",
      "        [ 0.0206,  0.0135,  0.0345,  ...,  0.0247, -0.0280,  0.0309],\n",
      "        [ 0.0328,  0.0228,  0.0160,  ..., -0.0250, -0.0251,  0.0253],\n",
      "        ...,\n",
      "        [ 0.0225,  0.0256,  0.0272,  ...,  0.0159,  0.0133,  0.0227],\n",
      "        [ 0.0063,  0.0204,  0.0154,  ...,  0.0120,  0.0228,  0.0085],\n",
      "        [ 0.0172, -0.0254, -0.0014,  ..., -0.0239, -0.0123, -0.0082]],\n",
      "       requires_grad=True) torch.Size([128, 784])\n",
      "Parameter containing:\n",
      "tensor([-3.4129e-02, -3.5023e-02, -2.4994e-02,  6.9522e-03,  2.4256e-02,\n",
      "        -3.0995e-02,  1.8428e-02,  1.7995e-04,  3.5690e-02,  1.1080e-02,\n",
      "        -2.5361e-02, -1.9550e-02, -4.1704e-03, -3.0963e-02, -2.3094e-03,\n",
      "         2.3683e-02, -8.2089e-03,  3.5467e-02,  6.6356e-03,  9.0419e-04,\n",
      "         9.8338e-03, -1.3634e-02, -2.2661e-02, -9.3643e-03,  2.4917e-02,\n",
      "         3.0572e-02, -6.5517e-03,  3.5520e-02,  3.5385e-02, -3.1636e-02,\n",
      "         1.2763e-02, -2.5896e-02, -1.5290e-02,  7.1542e-03,  2.3027e-02,\n",
      "         3.5029e-02, -3.1634e-03,  2.5170e-02,  1.0522e-02,  2.0760e-02,\n",
      "        -1.7747e-02, -9.3821e-03,  1.6665e-02, -1.5528e-02,  3.5188e-02,\n",
      "         2.0664e-02, -3.6067e-03,  1.4825e-02, -3.5022e-03,  3.2112e-02,\n",
      "        -9.9952e-03,  1.8579e-02,  1.9001e-02,  2.7324e-02, -1.8744e-02,\n",
      "        -3.1447e-02,  2.7373e-02,  1.2326e-02, -3.1618e-02,  3.5516e-02,\n",
      "         1.8448e-02, -2.7804e-02,  3.4334e-02,  2.3076e-03,  1.8247e-02,\n",
      "        -2.7856e-02, -1.1554e-02,  6.2440e-03, -5.8380e-04,  2.4348e-02,\n",
      "         3.0930e-02, -2.4141e-02,  3.0912e-02,  1.2217e-02,  3.9276e-03,\n",
      "        -2.8238e-02,  4.9517e-03,  8.7882e-04, -1.6903e-02,  1.7382e-02,\n",
      "         4.3225e-03, -2.3541e-02, -1.6702e-03,  3.1075e-02, -1.7210e-02,\n",
      "         3.4483e-02,  1.8049e-04, -1.4049e-02,  1.4035e-02,  2.5542e-03,\n",
      "         3.3312e-02, -1.0237e-02, -1.8189e-02, -9.2125e-03, -2.2061e-02,\n",
      "         1.0555e-02,  2.4672e-02, -2.9224e-02, -2.6461e-02, -1.1879e-02,\n",
      "         1.2724e-02,  1.0099e-02,  3.4147e-03, -1.5321e-02,  2.0307e-03,\n",
      "         1.0033e-02, -2.2252e-02,  3.1660e-02,  2.3012e-02,  1.4720e-02,\n",
      "         3.4967e-02, -2.4062e-02,  8.7397e-03, -3.2874e-02,  2.1446e-05,\n",
      "         3.5473e-02,  1.5873e-02, -2.6940e-02, -1.2387e-02,  2.6201e-02,\n",
      "        -3.1600e-02,  3.4718e-03, -8.8702e-03, -2.5180e-02,  2.0655e-02,\n",
      "         1.7065e-03,  2.7802e-02,  2.8921e-02], requires_grad=True) torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "print(model.hidden.weight,model.hidden.weight.shape)\n",
    "print(model.hidden.bias,model.hidden.bias.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1a1989c40df55dd4324cad2736e72481c148299d",
    "colab_type": "text",
    "id": "j3iwfmdl4DA2"
   },
   "source": [
    "For custom initialization, we can these tensors in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_uuid": "dc98f7292fe8d6f40b1ea58b681acf522f500bb2",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "Gut8xqfG4DA4",
    "outputId": "14ddc64f-c906-4841-8603-73f11ce15399"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set biases to all zeros\n",
    "model.hidden.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_uuid": "354f3f9fbcf8b0c6808394ea97e794b9f43ffe60",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "id": "mP1_5vXd4DBA",
    "outputId": "af52a474-54f5-415f-cab6-7bbadf1b9981"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2083e-02,  1.3362e-02, -4.7883e-04,  ..., -1.9470e-02,\n",
       "         -7.9714e-05, -2.3377e-02],\n",
       "        [ 1.9217e-03, -7.4535e-03,  1.4575e-03,  ..., -3.4555e-03,\n",
       "          5.4716e-03, -2.1791e-03],\n",
       "        [-2.0988e-03,  9.7672e-03, -3.6484e-03,  ..., -6.3477e-03,\n",
       "         -1.8276e-02,  9.4072e-03],\n",
       "        ...,\n",
       "        [ 3.9926e-03,  1.2083e-02, -5.4276e-03,  ..., -7.9789e-03,\n",
       "          1.0731e-03,  3.9884e-03],\n",
       "        [-2.4229e-03, -3.3990e-03,  6.5320e-03,  ...,  9.5462e-04,\n",
       "          6.1829e-03, -1.6516e-02],\n",
       "        [-2.5104e-03, -9.3102e-03,  5.5190e-03,  ..., -1.0905e-02,\n",
       "         -1.3265e-02, -5.5200e-03]])"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample from random normal with standard dev = 0.01\n",
    "model.hidden.weight.data.normal_(std=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_uuid": "e3b948402fbcd6e8529fe5ebcd00347f1db63a1c",
    "colab": {},
    "colab_type": "code",
    "id": "0c1xeOjL4DBE"
   },
   "outputs": [],
   "source": [
    "netowrk=Network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1eb03d730d47d46308e593ff4debbd6899280bbe",
    "colab_type": "text",
    "id": "e5Ked5Lw4DBJ"
   },
   "source": [
    "### Forward pass\n",
    "\n",
    "Now that we have a network, let's see what happens when we pass in an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "_uuid": "59df5bda3337698adad159777311294b7f8cfce4",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "colab_type": "code",
    "id": "hvty_zDW4DBK",
    "outputId": "09d8e2a7-1abc-4775-e849-50f2e78a57d5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAHECAYAAAAOFHoWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAABghOAAAAAwQnAACAAf8f1YPt3qT6OLcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 226,
       "width": 423
      },
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Grab some data \n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Resize images into a 1D vector, new shape is (batch size, color channels, image pixels) \n",
    "images.resize_(images.shape[0], 1, 784)\n",
    "\n",
    "# Forward pass through the network\n",
    "img_idx = 0\n",
    "ps = model.forward(images[img_idx,:])\n",
    "\n",
    "img = images[img_idx]\n",
    "view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2103e632ea834fcbd4741de8b9ee7edace23ba6b",
    "colab_type": "text",
    "id": "mBnOZK-84DBN"
   },
   "source": [
    "As you can see above, our network has basically no idea what this digit is. It's because we haven't trained it yet, , all the weights are random!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6d611ac89023080d6ee0e42b9369376ed261a777",
    "colab_type": "text",
    "id": "Tlbgk3-D4DBN"
   },
   "source": [
    "## Add-on: People from the keras would love this!!!\n",
    "PyTorch provides a convenient way to build networks like this where a tensor is passed sequentially through operations, `nn.Sequential`.\n",
    "Lets try to build the above network using this method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_uuid": "e6f5405fe980380825786437c0aa8e94cb8cb92e",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "colab_type": "code",
    "id": "hzQD5uAK4DBN",
    "outputId": "840e243c-1450-4204-df0f-fccbe5e10dce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Softmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters for our network\n",
    "input_size = 784\n",
    "hidden_sizes = [128]\n",
    "output_size = 10\n",
    "\n",
    "model=nn.Sequential(nn.Linear(input_size,hidden_sizes[0]),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(hidden_sizes[0],output_size),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Softmax(dim=1))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_uuid": "d461b698ae5973918405c9120db6e94194347a27",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "colab_type": "code",
    "id": "YTGl3o4q4DBQ",
    "outputId": "d5c5c113-ef48-4c80-f231-c3faf20e78be"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAHECAYAAAAOFHoWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+afJpVviAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 226,
       "width": 423
      },
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Forward pass through the network and display output\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(images.shape[0], 1, 784)\n",
    "ps = model.forward(images[0,:])\n",
    "view_classify(images[0].view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d137ebac2a3367c41e6c001f2edf2a37b0b22211",
    "colab_type": "text",
    "id": "jjHQZNqX4DBS"
   },
   "source": [
    "### Access Layers of the network\n",
    "We can access layers  by integer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "_uuid": "0cf54881f8e022928a962d1d83fd5614a97a039e",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "id": "Lm58z7bx4DBS",
    "outputId": "53e8b256-325f-4f73-8497-fcdfd503ab42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=128, bias=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0193,  0.0175, -0.0097,  ..., -0.0264,  0.0135,  0.0245],\n",
       "        [ 0.0010, -0.0323, -0.0246,  ...,  0.0255, -0.0211, -0.0345],\n",
       "        [ 0.0170, -0.0030, -0.0328,  ...,  0.0156, -0.0089, -0.0116],\n",
       "        ...,\n",
       "        [ 0.0051, -0.0267, -0.0117,  ..., -0.0142,  0.0277,  0.0269],\n",
       "        [-0.0048,  0.0291, -0.0253,  ...,  0.0246,  0.0038,  0.0083],\n",
       "        [-0.0341, -0.0225, -0.0207,  ..., -0.0338,  0.0086,  0.0154]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model[0])\n",
    "model[0].weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0499ff7a787fc1885f5998f81f2395fc6bcc4108",
    "colab_type": "text",
    "id": "2csfs3nj4DBU"
   },
   "source": [
    "### Ordered Dict- Better way to create a network\n",
    "We can also pass in an `OrderedDict` to name the individual layers and operations, instead of using incremental integers. Note that dictionary keys must be unique, so _each operation must have a different name_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "_uuid": "ca7567562b0610e6ec4ec7d98f03032bbe32c061",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "Fh7-9VfL4DBV",
    "outputId": "225f0c75-d213-43b9-8ca5-7ab77fd8ed3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (hidden): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (softmax): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "model = nn.Sequential(OrderedDict([\n",
    "                      ('hidden', nn.Linear(input_size, hidden_sizes[0])),\n",
    "                      ('relu1', nn.ReLU()),\n",
    "                      ('output', nn.Linear(hidden_sizes[0], output_size)),\n",
    "                      ('softmax', nn.Softmax(dim=1))]))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c67ffda9a2ace0093371017d9abf4bc02a8656dc",
    "colab_type": "text",
    "id": "fMg2ZNxD4DBX"
   },
   "source": [
    "### Access Layers using integer or name \n",
    "Now we can access layers  either by integer or name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "_uuid": "6da7947d84c734eea2bf19acc3127bdf87ccce1c",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "colab_type": "code",
    "id": "ypn65-Ep4DBY",
    "outputId": "89e79723-bfa0-44ed-eb24-ff48c2cb7f63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=128, bias=True)\n",
      "Linear(in_features=784, out_features=128, bias=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0213,  0.0055,  0.0044,  ...,  0.0216,  0.0212,  0.0184],\n",
      "        [-0.0282,  0.0110, -0.0335,  ..., -0.0296, -0.0002, -0.0258],\n",
      "        [-0.0075,  0.0346,  0.0275,  ...,  0.0115,  0.0269, -0.0081],\n",
      "        ...,\n",
      "        [-0.0204,  0.0250, -0.0245,  ...,  0.0287,  0.0189,  0.0337],\n",
      "        [-0.0119,  0.0049, -0.0011,  ..., -0.0234, -0.0316,  0.0198],\n",
      "        [ 0.0213, -0.0012, -0.0262,  ...,  0.0164,  0.0224,  0.0268]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model[0])\n",
    "print(model.hidden)\n",
    "print(model.hidden.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "df59c9d06c7e7d2ec2b6582c6bb0934e2d49c58f",
    "colab_type": "text",
    "id": "6e3jVOgM4DBa"
   },
   "source": [
    "### Recollect everything \n",
    "Before we go ahead and train a neural network to accuractly predict the numbers appearing in the MNIST images,let us recollect the important modules that is necessary for any model training exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f0df7ddfb84bf00cee50f9b916a9c61f1a65aaa9",
    "colab_type": "text",
    "id": "f_Hs4w9J4DBb"
   },
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T13:03:17.978997Z",
     "start_time": "2019-02-04T13:03:17.973595Z"
    },
    "_uuid": "ff53d2bd4296f89b134eb961832043cce0e43e4d",
    "colab": {},
    "colab_type": "code",
    "id": "rekP8JB34DBb"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets,transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7a1f47e2928ea88a7c9b45edb08ea75016b6fca6",
    "colab_type": "text",
    "id": "fogM8L7P4DBg"
   },
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T13:07:13.687456Z",
     "start_time": "2019-02-04T13:06:40.910295Z"
    },
    "_uuid": "c2c9d59a82c6bce28a611e1f409ced8b4f8fdc39",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "llRMkr-v4DBg",
    "outputId": "bd256cc2-8a0b-4d9f-a74d-b5e3397d92a6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 16384/9912422 [00:00<01:11, 138201.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9920512it [00:00, 31253957.04it/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /root/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32768it [00:00, 445049.83it/s]\n",
      "  1%|          | 16384/1648877 [00:00<00:11, 140432.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting /root/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1654784it [00:00, 6967617.90it/s]                           \n",
      "8192it [00:00, 160376.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /root/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting /root/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "transform=transforms.Compose([transforms.ToTensor()])\n",
    "trainset=datasets.MNIST('~/.pytorch/MNIST_data/',train=True,transform=transform,download=True)\n",
    "testset=datasets.MNIST('~/.pytorch/MNIST_data/',train=False,transform=transform,download=True)\n",
    "\n",
    "trainloader=torch.utils.data.DataLoader(trainset,batch_size=64,shuffle=True,num_workers=0)\n",
    "#will explain later\n",
    "testloader=torch.utils.data.DataLoader(testset,batch_size=64,shuffle=True,num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c7161f89857d013b0f837c620c0ed24657bed1b2",
    "colab_type": "text",
    "id": "OY4Xho394DBk"
   },
   "source": [
    "#### Build a feedforward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T13:03:47.741595Z",
     "start_time": "2019-02-04T13:03:47.735142Z"
    },
    "_uuid": "0e73fc284a626e4d7bbca629f817585aeb06fdd6",
    "colab": {},
    "colab_type": "code",
    "id": "qzKD0j684DBk"
   },
   "outputs": [],
   "source": [
    "# TODO: Build a feed-forward network in one of the three ways mentioned above:\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dfdb486a01347095c7c8d75de1d5b74443bbfd4f",
    "colab_type": "text",
    "id": "XNVJKWay4DBo"
   },
   "source": [
    "#### Lets run one image through the network to check our work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T13:03:49.422306Z",
     "start_time": "2019-02-04T13:03:49.121144Z"
    },
    "_uuid": "0864af9a75655db17435ef4940945a7d9532c671",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "50EvUnF34DBo",
    "outputId": "e9d2f2e7-87e0-4802-9d4d-4e97b0bd2b94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "# Get our data\n",
    "images, labels = next(iter(trainloader))\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our logits\n",
    "logits = model(images)\n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0d9976b19b6ca3910a3a4855754bdc1e3de1f52f",
    "colab_type": "text",
    "id": "kOqfHHNJ4DBs"
   },
   "source": [
    "#### Define a loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T13:03:52.643210Z",
     "start_time": "2019-02-04T13:03:52.638129Z"
    },
    "_uuid": "22466cb3a58aad481e903428de2642ff67e9bc1f",
    "colab": {},
    "colab_type": "code",
    "id": "k7KhsCL94DBt"
   },
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T13:03:55.680366Z",
     "start_time": "2019-02-04T13:03:55.547651Z"
    },
    "_uuid": "2e3bda9d30daf829a8e19537715860ff7c678329",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "inh-tLMV4DBu",
    "outputId": "e8d550c3-9934-46eb-82f4-f234bee2572c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3049, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the loss with the logits and the labels\n",
    "loss=criterion(logits,labels)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8a7dd6c45e94460f48dd048b35229f74a399a988",
    "colab_type": "text",
    "id": "xlkpF1m_4DBw"
   },
   "source": [
    "## Autograd\n",
    "\n",
    "Now that we know how to calculate a loss, how do we use it to perform backpropagation? Torch provides a module, `autograd`, for automatically calculating the gradients of tensors. We can use it to calculate the gradients of all our parameters with respect to the loss. Autograd works by keeping track of operations performed on tensors, then going backwards through those operations, calculating gradients along the way.\n",
    "\n",
    "PyTorch keeps track of operations on a tensor and calculates the gradients, you need to set `requires_grad = True` on a tensor. You can do this at creation with the `requires_grad` keyword, or at any time with `x.requires_grad_(True)`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d3361f46b9d9dbf06bc4a6b257f472129c2b01e1",
    "colab_type": "text",
    "id": "P6CQP81X4DBw"
   },
   "source": [
    "Let's see an example to understand it better.Then again we will head back to our modelling task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "_uuid": "5ab21186791f7e319778106ca1ffb327d0847e16",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "colab_type": "code",
    "id": "0ZYgrLYf4DBx",
    "outputId": "a22e2c03-6e10-4813-805d-1f0ea82329fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[ 0.5090, -0.1186],\n",
      "        [-0.6671, -0.0789]], requires_grad=True)\n",
      "y: tensor([[0.2591, 0.0141],\n",
      "        [0.4450, 0.0062]], grad_fn=<PowBackward0>)\n",
      "y.grad_fn: <PowBackward0 object at 0x7f3d1d46e6a0>\n",
      "z: tensor(0.1811, grad_fn=<MeanBackward0>)\n",
      "x.grad: None\n",
      "x.grad: tensor([[ 0.2545, -0.0593],\n",
      "        [-0.3335, -0.0394]])\n",
      "x/2: tensor([[ 0.2545, -0.0593],\n",
      "        [-0.3335, -0.0394]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,2, requires_grad=True)\n",
    "print(\"x:\",x)\n",
    "y = x**2\n",
    "print(\"y:\",y)\n",
    "## grad_fn shows the function that generated this variable\n",
    "print(\"y.grad_fn:\",y.grad_fn)\n",
    "z = y.mean()\n",
    "print(\"z:\",z)\n",
    "print(\"x.grad:\",x.grad)\n",
    "z.backward()\n",
    "print(\"x.grad:\",x.grad)\n",
    "print(\"x/2:\",x/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "94d46a1835ad4987ff28365b28ee304d366336dc",
    "colab_type": "text",
    "id": "mdd4kzZa4DBy"
   },
   "source": [
    "## Loss and Autograd together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T13:04:00.684688Z",
     "start_time": "2019-02-04T13:04:00.535643Z"
    },
    "_uuid": "b0c5e229539704b93a5991c27849bd7b41abae80",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "id": "x2Bp2C_14DBz",
    "outputId": "d5b04102-2af4-4b25-b16e-cde6230f562e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " None\n",
      "After backward pass: \n",
      " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "logits = model(images)\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "\n",
    "print('Before backward pass: \\n', model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('After backward pass: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d184b346f9ed4194de74a29675da09076e52e0c4",
    "colab_type": "text",
    "id": "iHu0ac6Z4DB1"
   },
   "source": [
    "## Defining the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T13:04:04.271653Z",
     "start_time": "2019-02-04T13:04:04.266694Z"
    },
    "_uuid": "efadf9e312ec51f9f36d25f043d011c27f4f8fe2",
    "colab": {},
    "colab_type": "code",
    "id": "uclj7uN44DB2"
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "91c0777ba686873bd972d96e384c090c9baae3d8",
    "colab_type": "text",
    "id": "YMzGLiTq4DB3"
   },
   "source": [
    "## Training for real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T13:05:20.593146Z",
     "start_time": "2019-02-04T13:04:05.998666Z"
    },
    "_uuid": "6b6ac5071aad8b3232596ed1d4807d73aab09df3",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "SG_yue954DB3",
    "outputId": "50a52f08-a800-4e7a-bcb6-ee9cb11f2995"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 Training loss: 1.1391830668767293\n",
      "Epoch:1 Training loss: 1.2300454666773477\n",
      "Epoch:2 Training loss: 1.4402017743428548\n",
      "Epoch:3 Training loss: 1.687267345937093\n",
      "Epoch:4 Training loss: 1.6394379685719809\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        optimizer.zero_grad()\n",
    "        output=model.forward(images)\n",
    "        # TODO: Training pass\n",
    "        \n",
    "        loss = criterion(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()*images.shape[0]\n",
    "    else:\n",
    "        print(f\"Epoch:{e} Training loss: {running_loss/len(trainloader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T13:06:05.063846Z",
     "start_time": "2019-02-04T13:06:04.983101Z"
    },
    "_uuid": "6d837662f725dc7196ba3d24130aa23090dc1616",
    "colab": {},
    "colab_type": "code",
    "id": "nAsqu-lu4DB6"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#import helper\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logits = model.forward(img)\n",
    "\n",
    "# Output of the network are logits, need to take softmax for probabilities\n",
    "ps = F.softmax(logits, dim=1)\n",
    "#helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "37a44994683bfe1fee884125d2e58ed08b62720b",
    "colab_type": "text",
    "id": "g4hUTb6u4DB9"
   },
   "source": [
    "## Inference and Validation\n",
    "\n",
    "The goal of validation is to measure the model's performance on data that isn't part of the training set. Typically this is just accuracy, the percentage of classes the network predicted correctly. Other options are precision and recall and top-5 error rate. We'll focus on accuracy here. First I'll do a forward pass with one batch from the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e94326ca7cdc742c2c575294d260c257a97cab87",
    "colab_type": "text",
    "id": "KjLRoPhS4DB-"
   },
   "source": [
    "### Inference on a batch of images\n",
    "Let us try to do this for a batch of images.Before that we will make some changes in our architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T13:08:55.536357Z",
     "start_time": "2019-02-04T13:08:55.509217Z"
    },
    "_uuid": "e4ec78de08b2f24f5032ba181ec7a7d79428261a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JmXSm5P64DB-",
    "outputId": "d77d894c-a3d8-4c26-bc4b-be538ee69df5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 1, 28, 28]), torch.Size([64]))"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images, labels = next(iter(testloader))\n",
    "images.shape,labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T13:09:03.958533Z",
     "start_time": "2019-02-04T13:09:03.928394Z"
    },
    "_uuid": "3f2244405b587c87c9347abd1ed4ab150f8d80aa",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "g85IuZKD4DCC",
    "outputId": "bed95d0b-1dc1-44d8-cc97-c9eca7287809"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(testloader))\n",
    "img = images.view(images.shape[0], 784)\n",
    "# Get the class probabilities\n",
    "ps = torch.exp(model(img))\n",
    "# Make sure the shape is appropriate, we should get 10 class probabilities for 64 examples\n",
    "print(ps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T13:09:06.432988Z",
     "start_time": "2019-02-04T13:09:06.341035Z"
    },
    "_uuid": "72a2ebdd77e3380b972e24e1565bc7744beedd27",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YLRbwojf4DCH",
    "outputId": "0f4bc9ae-a938-4233-dc1e-73ceb7b043b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 1]), torch.Size([64, 1]))"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_prob,top_class=ps.topk(1,dim=1)\n",
    "top_prob.shape,top_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T13:10:21.313112Z",
     "start_time": "2019-02-04T13:10:21.305216Z"
    },
    "_uuid": "9f6368720bf311e1ee9977f0f2562a02b1afc12f",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "BJ4d8SbF4DCO",
    "outputId": "41fe7554-c4ec-45fe-bec9-bb919e4ef633"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 1, 3, 6, 3, 6, 6, 6, 6, 6, 6, 3, 6, 3, 6, 6, 6, 6, 6, 6, 6, 3, 6, 3,\n",
       "        6, 1, 6, 6, 3, 6, 6, 3, 1, 6, 3, 3, 3, 6, 6, 6, 3, 6, 6, 6, 6, 1, 6, 3,\n",
       "        6, 3, 6, 1, 6, 6, 6, 6, 3, 0, 3, 3, 6, 6, 6, 3])"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_class.view(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "_uuid": "a9a05d7571a12641d0da644ae00b1608346faf6a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "sScTfQeQ4DCR",
    "outputId": "ac69ec43-4c4f-4c6b-dc55-bf5ee0ba391e",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Predicted  Actual\n",
       "0           6       2\n",
       "1           1       1\n",
       "2           3       5\n",
       "3           6       1\n",
       "4           3       9\n",
       "5           6       6\n",
       "6           6       5\n",
       "7           6       0\n",
       "8           6       8\n",
       "9           6       0\n",
       "10          6       7\n",
       "11          3       8\n",
       "12          6       3\n",
       "13          3       9\n",
       "14          6       6\n",
       "15          6       6\n",
       "16          6       6\n",
       "17          6       2\n",
       "18          6       7\n",
       "19          6       7\n",
       "20          6       8\n",
       "21          3       1\n",
       "22          6       8\n",
       "23          3       5\n",
       "24          6       7\n",
       "25          1       1\n",
       "26          6       7\n",
       "27          6       9\n",
       "28          3       4\n",
       "29          6       0\n",
       "..        ...     ...\n",
       "34          3       8\n",
       "35          3       5\n",
       "36          3       5\n",
       "37          6       6\n",
       "38          6       2\n",
       "39          6       7\n",
       "40          3       3\n",
       "41          6       2\n",
       "42          6       9\n",
       "43          6       4\n",
       "44          6       8\n",
       "45          1       1\n",
       "46          6       2\n",
       "47          3       5\n",
       "48          6       2\n",
       "49          3       3\n",
       "50          6       6\n",
       "51          1       1\n",
       "52          6       7\n",
       "53          6       5\n",
       "54          6       6\n",
       "55          6       4\n",
       "56          3       3\n",
       "57          0       0\n",
       "58          3       8\n",
       "59          3       5\n",
       "60          6       7\n",
       "61          6       4\n",
       "62          6       6\n",
       "63          3       4\n",
       "\n",
       "[64 rows x 2 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame({\"Predicted\":top_class.view(top_class.shape[0]),\"Actual\":labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "_uuid": "3f958e5da0aed9b404c743c8798b64e0d4341fdd",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QPgumHuE4DCV",
    "outputId": "bb3999a7-5b1c-4310-e142-9fc32f11be03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.265625"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equals=top_class == labels.view(*top_class.shape)\n",
    "accuracy=torch.mean(equals.type(torch.FloatTensor))\n",
    "accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T13:27:29.556056Z",
     "start_time": "2019-02-04T13:27:29.541115Z"
    },
    "_uuid": "352673a9d93a8f6b52165952364a7793ff43b8f0",
    "colab": {},
    "colab_type": "code",
    "id": "QecOZ7Bt4DCZ"
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "        # Dropout module with 0.2 drop probability\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # make sure input tensor is flattened\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        # Now with dropout\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "\n",
    "        # output so no dropout here\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "\n",
    "        return x\n",
    "        \n",
    "model=Network()\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.01)\n",
    "criterion=nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T13:29:20.825396Z",
     "start_time": "2019-02-04T13:27:30.220213Z"
    },
    "_uuid": "d7ef3898265ce167202ee321100129a95e3b748e",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "ZJvxs4ib4DCa",
    "outputId": "d8d7eb58-15ee-4c46-ebab-cbd24bb46d36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5..  Training Loss: 0.402..  Test Loss: 0.204..  Test Accuracy: 0.947\n",
      "Epoch: 2/5..  Training Loss: 0.300..  Test Loss: 0.193..  Test Accuracy: 0.952\n",
      "Epoch: 3/5..  Training Loss: 0.319..  Test Loss: 0.197..  Test Accuracy: 0.955\n",
      "Epoch: 4/5..  Training Loss: 0.276..  Test Loss: 0.190..  Test Accuracy: 0.954\n",
      "Epoch: 5/5..  Training Loss: 0.279..  Test Loss: 0.190..  Test Accuracy: 0.960\n"
     ]
    }
   ],
   "source": [
    "epochs=5\n",
    "train_losses,test_losses=[],[]\n",
    "for e in range(epochs):\n",
    "    running_loss=0\n",
    "    for images,labels in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        #images=images.view(images.shape[0],-1)\n",
    "        log_ps=model(images)\n",
    "        loss=criterion(log_ps,labels) # a single value for ex 2.33\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * images.shape[0] ## (2.33*64 + 2.22*64 + 2.12*33) / 138 \n",
    "        \n",
    "    else:\n",
    "        test_loss=0\n",
    "        accuracy=0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for images,labels in testloader:\n",
    "                log_ps=model(images)\n",
    "                test_loss+=criterion(log_ps,labels) *images.shape[0]\n",
    "                ps=torch.exp(log_ps)\n",
    "                top_p,top_class=ps.topk(1,dim=1)\n",
    "                equals=top_class==labels.view(*top_class.shape)\n",
    "                accuracy+=torch.sum(equals).item()\n",
    "        model.train()\n",
    "        train_losses.append(running_loss/len(trainloader.dataset))\n",
    "        test_losses.append(test_loss.item()/len(testloader.dataset))\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader.dataset)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader.dataset)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader.dataset)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T13:24:46.424543Z",
     "start_time": "2019-02-04T13:24:46.420315Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sDXM694d4DCc",
    "outputId": "b53b8261-bc54-4e85-8814-1ad95da33689"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16732.30222570896"
      ]
     },
     "execution_count": 69,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "_uuid": "086d29056a5322e8c76820fcdc87ddc5424539ff",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "n_iWSBVm4DCe",
    "outputId": "928ff11f-a9d1-4968-dce8-02f35cb708a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f3d1d5c3fd0>"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvgAAAH0CAYAAABICFkFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJEklYsCXJEmSSsSAL0mSJJXI/wd75Hy9/+4tgQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 380
      },
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(test_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5612d928a89de850888b2caa3251617ff1ebc9fc",
    "colab_type": "text",
    "id": "BybjWD-B4DCg"
   },
   "source": [
    "## Inference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "_uuid": "e908e92d92cf3f2634fa665acbca4012bacdb3bf",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "l--FFj6x4DCg",
    "outputId": "57dbd226-9bf3-4268-9ced-8ac5c1d32784"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, tensor(8))"
      ]
     },
     "execution_count": 72,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "img = images[0]\n",
    "# Convert 2D image to 1D vector\n",
    "img = img.view(1, 784)\n",
    "\n",
    "# Calculate the class probabilities (softmax) for img\n",
    "with torch.no_grad():\n",
    "    output = model.forward(img)\n",
    "\n",
    "ps = torch.exp(output)\n",
    "top_prob,top_class=ps.topk(1,dim=1)\n",
    "top_class.item(),labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "086a197d3e597422ee8b592832f811444577b876",
    "colab_type": "text",
    "id": "HLqWHCBM4DCh"
   },
   "source": [
    "The parameters for PyTorch networks are stored in a model's state_dict\n",
    " Optimizer objects (torch.optim) also have a state_dict, which contains information about the optimizerâ€™s state, as well as the hyperparameters used.\n",
    "\n",
    "Because state_dict objects are Python dictionaries, they can be easily saved, updated, altered, and restored, adding a great deal of modularity to PyTorch models and optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "_uuid": "2dbde41ca47a505766ec29ad2c89443f9a4d8d7a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "colab_type": "code",
    "id": "ZtBvFdei4DCi",
    "outputId": "cf437a7b-2c5e-438a-86f8-90eed4369a2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "fc1.weight \t torch.Size([256, 784])\n",
      "fc1.bias \t torch.Size([256])\n",
      "fc2.weight \t torch.Size([128, 256])\n",
      "fc2.bias \t torch.Size([128])\n",
      "fc3.weight \t torch.Size([64, 128])\n",
      "fc3.bias \t torch.Size([64])\n",
      "fc4.weight \t torch.Size([10, 64])\n",
      "fc4.bias \t torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "_uuid": "67e383a0385379d68f1c4f0d38143504b098a8d5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "FjWuuhJq4DCj",
    "outputId": "3d8f7fba-4e0d-47df-b333-42c3b4b879b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer's state_dict:\n",
      "state \t {139900461526256: {'step': 4690, 'exp_avg': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'exp_avg_sq': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}, 139900461526328: {'step': 4690, 'exp_avg': tensor([ 5.6052e-45, -9.0633e-05, -2.0838e-18,  5.6052e-45,  5.6052e-45,\n",
      "        -2.1870e-05, -1.6081e-04, -1.2594e-03, -1.9198e-04,  3.1295e-38,\n",
      "        -4.9848e-04,  2.1075e-03, -1.6403e-23, -4.4465e-04,  2.8305e-04,\n",
      "        -6.0509e-41,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.7103e-04, -4.9331e-04, -1.4567e-03,  5.6052e-45, -9.3776e-07,\n",
      "         4.8159e-04, -1.2833e-03,  2.9540e-11, -1.3162e-04,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45, -1.6582e-04, -1.9093e-04,\n",
      "        -2.7883e-03, -6.7744e-04,  5.6052e-45, -3.7190e-04,  5.6052e-45,\n",
      "        -9.4714e-05,  5.6052e-45,  5.6052e-45,  5.1016e-26,  5.6052e-45,\n",
      "        -1.4458e-03, -7.5890e-06, -3.3384e-07,  5.6052e-45, -4.6484e-04,\n",
      "        -3.9815e-24,  5.0237e-07,  1.0383e-04, -1.4806e-04, -1.3148e-03,\n",
      "        -5.6060e-06,  1.4278e-03,  5.6052e-45,  5.6052e-45, -1.8632e-06,\n",
      "         5.6052e-45,  5.6052e-45, -1.8906e-04,  1.6491e-04,  5.6052e-45,\n",
      "        -6.2496e-05, -3.7904e-05,  5.6052e-45,  1.0470e-03,  5.6052e-45,\n",
      "         5.5002e-04,  5.6052e-45,  5.6052e-45,  5.6052e-45, -3.3427e-04,\n",
      "        -7.0477e-05,  5.6052e-45,  5.6052e-45, -1.1798e-03, -1.4826e-04,\n",
      "         2.2910e-34, -2.2005e-04,  1.5249e-03, -4.2334e-10,  5.0154e-04,\n",
      "        -6.2739e-04,  5.6052e-45, -1.9690e-03, -5.6052e-45, -4.7854e-04,\n",
      "         5.6052e-45,  5.6052e-45, -3.1894e-04,  2.7461e-03, -5.2178e-04,\n",
      "        -2.8835e-04, -3.6933e-04, -1.4136e-07,  1.8333e-05,  1.9115e-04,\n",
      "        -9.9939e-05,  5.6052e-45,  5.6052e-45,  5.6052e-45,  3.3981e-04,\n",
      "        -1.8277e-04,  7.2033e-04,  5.6052e-45,  3.9305e-17,  5.6052e-45,\n",
      "        -7.5574e-33,  1.9815e-04,  5.6052e-45,  3.8151e-04,  1.2540e-04,\n",
      "         5.6052e-45,  8.0551e-04,  1.3884e-03, -2.5297e-04, -1.6292e-04,\n",
      "         5.6052e-45,  5.1199e-04,  9.6204e-07,  5.6052e-45,  5.6052e-45,\n",
      "        -6.0065e-04, -1.3282e-03,  4.7743e-19, -7.5781e-08,  6.1700e-04,\n",
      "         5.4625e-04, -2.2623e-06, -2.2372e-06,  3.6068e-04, -2.5489e-04,\n",
      "         1.1144e-05,  5.6052e-45,  5.6052e-45,  5.1736e-04,  5.6052e-45,\n",
      "         5.6052e-45, -5.1086e-05,  5.6052e-45, -1.2228e-03, -8.9460e-16,\n",
      "        -2.4032e-07,  5.6052e-45,  5.6052e-45, -3.8343e-07,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -4.0377e-04, -1.6527e-04, -7.4107e-04,\n",
      "        -2.5274e-04,  1.3999e-03,  5.6052e-45,  5.6052e-45,  2.2554e-04,\n",
      "         5.6052e-45,  5.6052e-45, -2.1454e-18,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  4.8885e-11, -1.1367e-04,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45, -2.6906e-04,  3.3655e-04,\n",
      "         6.2474e-04,  2.1049e-04,  5.6052e-45,  6.8644e-04, -5.0611e-04,\n",
      "        -4.8471e-04, -1.3922e-03,  5.6052e-45, -5.0407e-04,  6.8073e-04,\n",
      "         5.6052e-45,  4.0440e-05,  5.6052e-45,  5.6052e-45,  4.1358e-04,\n",
      "         3.2968e-04, -4.0805e-04,  4.0927e-05,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  4.3170e-28, -3.0520e-04,  5.6052e-45,  1.7056e-03,\n",
      "         5.6052e-45,  8.5415e-07,  5.6052e-45,  1.4115e-03,  7.3234e-04,\n",
      "         5.6052e-45, -3.1110e-05,  5.6052e-45,  5.6052e-45, -5.0643e-05,\n",
      "         5.6052e-45,  4.6739e-06, -3.0619e-12,  5.6052e-45, -5.6052e-45,\n",
      "         3.9847e-04,  5.6052e-45,  5.6052e-45,  1.2318e-03, -2.2216e-03,\n",
      "         5.6052e-45, -4.9994e-04, -1.0524e-08,  5.6052e-45,  1.1751e-04,\n",
      "        -7.9131e-04, -2.4598e-04, -1.5322e-04, -8.4084e-07, -4.0460e-04,\n",
      "         5.6052e-45,  5.6052e-45,  1.2803e-16,  5.6052e-45, -1.1575e-03,\n",
      "        -2.4894e-04, -1.0898e-12,  1.1172e-03, -7.2015e-06, -7.3483e-05,\n",
      "        -1.4377e-04,  5.6052e-45, -2.0602e-05,  1.1014e-17,  5.6052e-45,\n",
      "        -2.6173e-05,  3.4547e-04, -8.5269e-04,  2.3448e-24, -1.7872e-05,\n",
      "         6.9672e-05,  5.6052e-45, -9.6096e-04,  3.7348e-04, -2.4987e-04,\n",
      "         1.5859e-03]), 'exp_avg_sq': tensor([2.0160e-11, 2.1008e-06, 1.2720e-07, 8.1500e-12, 7.7864e-11, 6.0178e-06,\n",
      "        2.5515e-06, 3.0802e-05, 7.8533e-06, 6.0529e-08, 1.0237e-05, 2.6508e-05,\n",
      "        5.3380e-08, 1.1060e-05, 2.3833e-05, 2.8277e-08, 2.1225e-12, 6.3951e-12,\n",
      "        1.9235e-11, 1.2461e-10, 1.9305e-05, 9.7068e-06, 2.0388e-05, 7.6511e-13,\n",
      "        1.2754e-06, 7.6364e-06, 1.4660e-05, 8.6858e-08, 1.3502e-05, 4.6380e-12,\n",
      "        1.3879e-11, 1.5353e-09, 1.8678e-11, 6.9552e-07, 9.7127e-06, 3.0020e-05,\n",
      "        5.7284e-06, 4.3043e-11, 1.4089e-05, 6.8081e-12, 1.0286e-06, 7.7298e-14,\n",
      "        5.0995e-08, 7.3316e-07, 2.8563e-11, 2.0212e-05, 3.1870e-06, 1.9183e-06,\n",
      "        8.6649e-12, 1.1835e-05, 1.6193e-07, 1.6386e-05, 2.3852e-05, 1.3492e-06,\n",
      "        1.9181e-05, 4.1632e-06, 2.3369e-05, 7.9263e-13, 1.5977e-11, 1.3816e-06,\n",
      "        5.0661e-12, 6.0988e-12, 1.1294e-05, 1.5424e-05, 1.0193e-12, 4.2645e-06,\n",
      "        1.9336e-05, 6.4664e-12, 1.1046e-05, 8.1666e-11, 1.2267e-05, 1.2778e-10,\n",
      "        3.8073e-08, 1.8938e-13, 6.6783e-06, 2.7694e-05, 1.9329e-12, 2.1069e-07,\n",
      "        6.5967e-06, 2.3123e-05, 1.1079e-07, 2.0135e-05, 1.1243e-05, 9.4523e-08,\n",
      "        4.4590e-06, 7.9489e-06, 1.0393e-11, 2.7172e-05, 6.8948e-08, 8.8119e-06,\n",
      "        1.0062e-10, 5.3416e-10, 5.1183e-06, 1.9165e-05, 1.1489e-05, 1.2823e-05,\n",
      "        2.1543e-05, 3.0763e-06, 1.5846e-05, 3.0736e-05, 2.7274e-05, 1.1226e-11,\n",
      "        8.0351e-12, 1.6604e-11, 1.7078e-05, 1.1072e-05, 1.0692e-05, 3.9794e-08,\n",
      "        1.0354e-08, 2.2004e-08, 1.5030e-08, 1.6517e-06, 3.4152e-12, 3.4401e-05,\n",
      "        1.1921e-05, 2.5089e-11, 2.3087e-05, 1.1648e-05, 1.4296e-05, 2.0518e-06,\n",
      "        2.1707e-07, 1.5897e-05, 1.3711e-05, 6.6077e-12, 4.2163e-12, 1.3388e-05,\n",
      "        1.1029e-05, 6.3954e-07, 4.5353e-06, 2.8117e-05, 2.0157e-05, 3.5936e-06,\n",
      "        5.7601e-06, 2.5753e-05, 2.8817e-05, 1.0194e-05, 7.6028e-12, 8.0913e-11,\n",
      "        1.0208e-05, 6.8632e-12, 3.5391e-12, 6.2860e-06, 7.1457e-11, 6.1707e-06,\n",
      "        3.5247e-08, 5.4233e-06, 1.7449e-11, 3.3822e-07, 6.5717e-06, 7.5350e-12,\n",
      "        9.1023e-09, 1.5383e-08, 3.3088e-05, 8.6880e-07, 7.1587e-06, 1.0490e-05,\n",
      "        2.2026e-05, 8.9084e-12, 3.1643e-11, 1.0487e-05, 3.5097e-09, 2.2138e-11,\n",
      "        1.0931e-06, 1.1192e-09, 5.8274e-11, 3.3750e-12, 7.1008e-12, 7.5826e-12,\n",
      "        1.7436e-06, 1.6265e-05, 3.0266e-12, 3.2127e-12, 2.2556e-08, 1.2205e-05,\n",
      "        1.2238e-05, 7.5882e-06, 2.7635e-05, 5.8003e-11, 2.2000e-05, 1.8573e-05,\n",
      "        6.4704e-06, 2.3237e-05, 4.5839e-09, 1.2010e-05, 3.1836e-05, 6.4275e-12,\n",
      "        9.3727e-06, 1.5362e-15, 5.8506e-08, 1.4453e-05, 2.0889e-05, 1.3129e-05,\n",
      "        3.2019e-06, 1.4059e-11, 2.8743e-11, 3.5082e-10, 5.6549e-08, 7.5633e-06,\n",
      "        2.9774e-11, 2.7921e-05, 5.1786e-12, 6.7535e-07, 1.0596e-11, 1.5241e-05,\n",
      "        5.0772e-06, 4.5000e-12, 4.4615e-06, 6.0049e-11, 2.2792e-10, 1.7014e-05,\n",
      "        6.7951e-08, 9.5301e-07, 2.1374e-07, 5.7570e-12, 6.9692e-09, 8.8905e-06,\n",
      "        1.4452e-11, 3.7032e-08, 1.4276e-05, 2.1252e-05, 3.8762e-12, 7.0415e-06,\n",
      "        3.4788e-07, 1.0391e-11, 1.6392e-06, 2.1311e-05, 1.4133e-05, 1.7716e-06,\n",
      "        1.8970e-05, 1.2725e-05, 1.2128e-11, 1.9355e-11, 3.7479e-12, 3.6879e-08,\n",
      "        1.5979e-05, 5.8590e-06, 5.7794e-08, 1.0580e-05, 8.3609e-06, 1.1806e-05,\n",
      "        6.4650e-06, 5.5602e-08, 1.2513e-06, 4.5440e-08, 1.5930e-11, 7.5485e-06,\n",
      "        1.5942e-05, 1.0589e-05, 4.1900e-07, 1.9761e-05, 2.1407e-05, 2.5238e-11,\n",
      "        2.2480e-05, 7.5331e-06, 1.8760e-05, 1.4502e-05])}, 139900461525392: {'step': 4690, 'exp_avg': tensor([[ 5.6052e-45,  5.9859e-10, -5.6052e-45,  ..., -7.5535e-23,\n",
      "         -8.2570e-22, -1.4431e-24],\n",
      "        [-5.6052e-45,  5.6052e-45,  5.6052e-45,  ..., -9.4061e-06,\n",
      "         -6.5321e-04, -1.9733e-03],\n",
      "        [-5.6052e-45,  4.9055e-07, -5.6052e-45,  ...,  5.4969e-06,\n",
      "         -4.9657e-05, -5.3686e-06],\n",
      "        ...,\n",
      "        [ 5.6052e-45, -5.6052e-45, -5.6052e-45,  ...,  8.9802e-07,\n",
      "          1.7440e-05,  3.9829e-05],\n",
      "        [-5.6052e-45,  8.4629e-07,  5.6052e-45,  ...,  3.0286e-21,\n",
      "         -1.1601e-07, -1.0881e-09],\n",
      "        [-5.6052e-45,  5.6052e-45, -5.6052e-45,  ...,  5.6052e-45,\n",
      "          6.1732e-06,  7.2658e-05]]), 'exp_avg_sq': tensor([[3.3201e-13, 5.3940e-07, 3.7244e-08,  ..., 2.8396e-08, 2.9961e-06,\n",
      "         6.8652e-07],\n",
      "        [6.6013e-12, 4.0142e-08, 2.2513e-08,  ..., 2.0858e-06, 9.8170e-05,\n",
      "         4.5702e-05],\n",
      "        [1.3497e-12, 1.2152e-06, 1.1506e-08,  ..., 6.8172e-08, 2.0846e-05,\n",
      "         3.8204e-05],\n",
      "        ...,\n",
      "        [1.8454e-12, 4.7357e-10, 7.1464e-08,  ..., 4.1053e-08, 1.8037e-06,\n",
      "         1.4767e-06],\n",
      "        [1.3383e-13, 3.9913e-09, 4.3661e-08,  ..., 1.3015e-08, 1.8022e-06,\n",
      "         7.7080e-07],\n",
      "        [8.0929e-13, 1.0355e-07, 6.2716e-08,  ..., 3.7291e-09, 1.6681e-06,\n",
      "         2.5748e-06]])}, 139900461526112: {'step': 4690, 'exp_avg': tensor([-1.2909e-04,  2.4660e-04,  1.5988e-04,  7.3528e-05,  1.8472e-06,\n",
      "        -1.9826e-05, -2.0145e-04, -3.3048e-05, -5.6509e-04, -1.9983e-04,\n",
      "        -1.5285e-04, -4.6748e-05,  8.3083e-04, -4.4042e-06,  8.9194e-06,\n",
      "         4.8256e-04, -1.1667e-04, -1.1729e-04, -1.4312e-04,  5.7649e-04,\n",
      "         1.0127e-04, -1.6241e-06, -3.4087e-04,  2.3752e-04, -3.0360e-05,\n",
      "         3.3750e-07, -5.4022e-04, -1.5422e-05,  5.6052e-45,  3.6990e-04,\n",
      "         3.6851e-04, -4.8492e-04, -3.4300e-05, -1.4492e-05, -5.2315e-04,\n",
      "        -1.7087e-07, -1.8778e-04, -1.1772e-04,  7.2602e-04,  8.2353e-05,\n",
      "         1.1801e-04, -7.6495e-05, -6.1823e-04, -1.9737e-10, -1.3041e-04,\n",
      "        -1.8452e-03, -6.7736e-06, -5.3150e-05, -2.4154e-04,  1.1406e-04,\n",
      "         3.3539e-04, -4.8865e-04, -2.3958e-05, -4.2819e-05, -3.1120e-04,\n",
      "        -1.2215e-05, -1.8287e-04,  1.6531e-04,  9.1417e-05, -4.5539e-04,\n",
      "         1.3994e-04,  4.5136e-05,  9.5200e-06,  3.8422e-05, -1.9843e-04,\n",
      "         1.8433e-04, -9.6962e-04, -1.0862e-04,  5.6458e-04,  2.3610e-04,\n",
      "        -3.7210e-04, -6.0189e-05,  1.0946e-03, -1.0759e-05,  6.2165e-04,\n",
      "        -3.3889e-04, -1.6923e-03,  5.9440e-05,  1.8638e-05,  1.1267e-04,\n",
      "         2.4674e-04,  9.2008e-07,  1.2399e-04,  2.5901e-04, -2.0639e-04,\n",
      "        -6.7167e-04,  5.2466e-04, -2.4921e-04,  2.1985e-04,  4.2930e-04,\n",
      "        -5.4526e-05, -7.0575e-06, -1.0473e-05,  4.1598e-05,  5.5857e-05,\n",
      "        -3.4982e-05,  2.9785e-05,  1.0195e-05, -8.1172e-05, -9.5797e-05,\n",
      "         1.7819e-04,  5.3293e-04,  1.6696e-04,  3.5086e-05,  4.0574e-04,\n",
      "         4.1801e-04,  1.4045e-05,  1.3502e-04,  3.3930e-04,  5.3970e-04,\n",
      "         4.8366e-06, -2.2800e-05,  1.7637e-04, -1.3367e-04,  6.6134e-07,\n",
      "        -7.6568e-05,  2.6509e-05, -1.7254e-04,  5.7555e-04, -4.1443e-05,\n",
      "         8.4460e-05,  7.0156e-04, -2.0258e-05, -6.5623e-04, -9.8701e-05,\n",
      "        -8.1752e-05,  4.7091e-06, -1.0151e-06]), 'exp_avg_sq': tensor([7.6907e-07, 5.6437e-06, 3.1294e-06, 4.6518e-06, 6.0130e-06, 1.5373e-06,\n",
      "        1.0934e-06, 6.7901e-06, 4.5485e-06, 1.8672e-06, 5.1357e-06, 3.7233e-06,\n",
      "        1.5402e-06, 1.8828e-06, 9.2130e-07, 4.2199e-06, 5.5776e-06, 1.1961e-06,\n",
      "        6.4486e-06, 5.2119e-06, 5.0504e-06, 6.1551e-07, 5.6928e-06, 4.0122e-06,\n",
      "        3.5543e-06, 2.7474e-06, 6.1314e-06, 1.0417e-06, 9.0383e-11, 3.3043e-06,\n",
      "        5.8399e-06, 3.6004e-06, 5.0794e-07, 2.6088e-06, 4.9966e-06, 5.0437e-07,\n",
      "        4.2044e-06, 3.0332e-06, 8.4421e-06, 8.7030e-07, 4.9481e-06, 3.1368e-08,\n",
      "        5.8931e-06, 4.3666e-09, 5.1971e-06, 9.2423e-06, 6.4350e-07, 2.8997e-06,\n",
      "        2.5190e-06, 3.8955e-07, 2.1700e-06, 4.1142e-06, 3.0168e-07, 3.9488e-06,\n",
      "        1.2919e-06, 6.6820e-07, 2.9851e-06, 1.9923e-06, 1.5860e-06, 5.5307e-06,\n",
      "        5.0241e-07, 7.1609e-06, 1.2631e-06, 3.4589e-06, 3.9030e-06, 1.2609e-06,\n",
      "        6.8581e-06, 1.1345e-06, 5.5086e-06, 5.2100e-07, 3.1832e-06, 3.3962e-06,\n",
      "        3.9177e-06, 6.0988e-07, 4.0214e-06, 3.9222e-06, 4.3557e-06, 1.6606e-06,\n",
      "        9.7263e-07, 8.2460e-06, 3.2286e-06, 5.8069e-07, 2.3252e-06, 5.9235e-06,\n",
      "        4.2597e-07, 6.0506e-06, 5.4456e-06, 5.8790e-06, 2.0797e-06, 4.8118e-06,\n",
      "        6.4540e-07, 5.6915e-07, 1.6480e-07, 4.4769e-06, 1.2334e-07, 6.0121e-07,\n",
      "        1.1480e-06, 9.6727e-07, 2.4759e-06, 1.1378e-05, 2.1714e-06, 7.4186e-07,\n",
      "        4.1942e-06, 1.1270e-06, 9.1601e-07, 6.8907e-06, 4.8703e-07, 1.9495e-06,\n",
      "        2.0869e-06, 5.0826e-06, 7.2962e-07, 2.1816e-07, 4.7466e-06, 4.6380e-06,\n",
      "        1.2959e-06, 2.4143e-06, 1.1162e-06, 1.8269e-06, 4.9407e-06, 1.3954e-06,\n",
      "        7.0093e-06, 6.1579e-06, 1.3861e-06, 6.8897e-06, 1.0757e-06, 1.7799e-06,\n",
      "        3.2545e-07, 8.2589e-07])}, 139900461526040: {'step': 4690, 'exp_avg': tensor([[-3.0439e-08, -1.2409e-08,  3.4250e-04,  ..., -5.5884e-12,\n",
      "         -8.4041e-07, -5.6052e-45],\n",
      "        [ 4.3944e-40,  3.4023e-05, -1.9848e-04,  ...,  1.1912e-06,\n",
      "          3.4964e-08,  4.7000e-07],\n",
      "        [ 1.1539e-38, -4.2105e-08,  1.0535e-03,  ..., -2.6653e-07,\n",
      "         -5.0220e-07, -3.4162e-05],\n",
      "        ...,\n",
      "        [ 5.6052e-45, -3.8936e-33,  1.7960e-03,  ...,  3.6836e-08,\n",
      "          3.6358e-10, -1.0499e-06],\n",
      "        [-6.7221e-37,  5.6052e-45, -6.8850e-07,  ..., -4.7001e-26,\n",
      "          5.6052e-45, -1.4941e-31],\n",
      "        [-1.3073e-19,  3.9909e-16, -3.0864e-06,  ...,  4.5565e-09,\n",
      "         -1.1513e-06, -3.4462e-05]]), 'exp_avg_sq': tensor([[5.5368e-06, 1.3295e-06, 3.6648e-05,  ..., 4.4462e-07, 4.1638e-06,\n",
      "         3.2714e-06],\n",
      "        [1.6893e-08, 3.1863e-07, 1.0157e-04,  ..., 2.0351e-06, 9.8976e-06,\n",
      "         8.9255e-06],\n",
      "        [2.3075e-07, 7.5221e-06, 1.1583e-04,  ..., 1.7064e-06, 4.6344e-06,\n",
      "         9.6035e-06],\n",
      "        ...,\n",
      "        [8.4200e-08, 1.6446e-06, 6.8540e-05,  ..., 1.3699e-06, 8.0277e-07,\n",
      "         1.1968e-06],\n",
      "        [2.1728e-10, 3.1512e-08, 1.0583e-05,  ..., 1.3092e-06, 1.2653e-08,\n",
      "         1.5370e-09],\n",
      "        [1.7704e-06, 6.0989e-07, 1.3985e-05,  ..., 1.5147e-07, 4.0570e-07,\n",
      "         1.7411e-06]])}, 139900461525248: {'step': 4690, 'exp_avg': tensor([-2.2409e-04, -1.0514e-04, -2.2531e-05,  1.1361e-04,  2.1007e-05,\n",
      "        -7.5251e-05, -1.6207e-04, -2.6700e-05, -5.5658e-04, -3.2277e-04,\n",
      "        -4.9651e-16, -3.2694e-04,  2.3576e-04,  2.2112e-04, -6.9036e-04,\n",
      "        -3.5538e-06, -1.1465e-04,  1.7443e-04,  4.8515e-04, -6.5063e-04,\n",
      "        -3.7166e-04,  1.1352e-11,  2.0714e-07, -4.5680e-05, -5.8665e-04,\n",
      "        -1.0959e-06,  1.3370e-03, -7.2549e-04,  5.1173e-05,  5.9709e-04,\n",
      "        -9.6832e-04,  6.1406e-04, -4.4309e-04, -6.8583e-06, -6.7363e-04,\n",
      "         1.0745e-39,  6.8978e-05, -2.8864e-04, -6.5218e-07, -4.4942e-05,\n",
      "        -8.8874e-05, -2.6537e-04,  2.1660e-08, -3.9327e-04,  4.3083e-18,\n",
      "        -6.9570e-05,  1.8185e-04,  6.1726e-05,  8.5478e-10,  4.1923e-07,\n",
      "         2.6255e-04,  7.3841e-06,  1.7282e-05,  1.2687e-08,  1.2880e-04,\n",
      "        -3.3075e-05, -9.1281e-04,  7.3394e-04,  1.1153e-10,  4.5372e-04,\n",
      "         1.5997e-03,  4.6362e-04, -1.8101e-05, -8.4351e-04]), 'exp_avg_sq': tensor([4.0402e-06, 3.5730e-06, 6.8574e-06, 7.6486e-07, 1.6507e-06, 3.3100e-06,\n",
      "        6.2310e-06, 5.0227e-06, 8.1812e-06, 3.7582e-06, 2.7292e-07, 3.3632e-06,\n",
      "        3.7643e-06, 1.1877e-06, 6.9635e-06, 5.0682e-06, 2.3374e-06, 5.3952e-06,\n",
      "        1.2488e-06, 9.0824e-06, 3.4307e-06, 2.0671e-07, 6.5342e-07, 4.5825e-06,\n",
      "        3.4935e-06, 2.0613e-07, 8.4145e-06, 6.0097e-06, 2.6297e-06, 7.9023e-06,\n",
      "        1.1026e-05, 5.2180e-06, 3.0439e-06, 1.0718e-06, 4.8543e-06, 3.6846e-09,\n",
      "        4.3594e-06, 7.5386e-06, 4.8594e-07, 4.6684e-06, 6.2848e-07, 7.2960e-06,\n",
      "        5.4032e-07, 3.3385e-06, 4.4825e-07, 3.0315e-06, 6.7744e-06, 4.7726e-07,\n",
      "        6.9378e-07, 8.7345e-08, 2.4895e-06, 1.3262e-06, 1.1211e-06, 4.1199e-07,\n",
      "        3.7932e-06, 3.8700e-06, 6.2931e-06, 4.7584e-06, 1.1123e-07, 5.7224e-06,\n",
      "        7.9200e-06, 4.3516e-06, 7.1062e-07, 4.8290e-06])}, 139900461525680: {'step': 4690, 'exp_avg': tensor([[ 6.0655e-05, -1.2791e-02, -9.2147e-04,  2.1673e-05, -4.1058e-04,\n",
      "          2.2092e-04,  9.3630e-04, -8.4244e-04,  1.1652e-03, -2.9285e-02,\n",
      "          3.1146e-20,  2.5363e-05, -2.6613e-03,  7.2318e-05,  4.5017e-04,\n",
      "         -4.3325e-04,  4.0996e-07, -2.2132e-03,  6.3804e-05,  3.9406e-03,\n",
      "         -8.2670e-03,  7.2933e-12,  1.5404e-10, -4.9675e-03,  3.6926e-04,\n",
      "          2.1772e-08, -2.3323e-03,  3.3699e-04,  1.5331e-05,  1.0594e-03,\n",
      "          2.3482e-03, -2.7367e-03,  3.2953e-04,  1.3379e-06,  2.6193e-04,\n",
      "          6.3114e-42,  1.3882e-04,  9.2218e-04,  8.5543e-09,  1.8975e-03,\n",
      "          3.7938e-05, -1.7319e-03,  4.5561e-07, -3.8550e-03,  2.8505e-20,\n",
      "          6.2950e-02, -9.5540e-05,  9.2063e-06,  4.8318e-12,  2.0646e-09,\n",
      "          3.6704e-04, -1.2727e-03,  1.1521e-10,  2.3292e-08, -8.8260e-03,\n",
      "         -6.6115e-05,  4.3013e-04, -4.1527e-03,  1.2339e-20, -1.0495e-02,\n",
      "          7.0002e-04, -3.3688e-03,  2.8396e-06,  1.6550e-04],\n",
      "        [ 6.4342e-04, -7.0615e-04, -1.7810e-03,  3.9195e-05,  1.8642e-04,\n",
      "          3.3421e-04,  2.8177e-04, -1.4400e-02,  3.6164e-05,  1.5856e-04,\n",
      "          2.2252e-21,  2.1819e-04,  3.7965e-04,  1.6275e-03,  8.4986e-04,\n",
      "          3.5819e-03, -4.8866e-04,  2.3106e-03,  3.1386e-05,  1.4170e-03,\n",
      "         -4.9496e-04,  9.1555e-13,  3.0923e-09,  1.5971e-03, -1.3562e-02,\n",
      "          2.4855e-08,  1.0632e-02,  8.3045e-04, -2.3467e-04,  1.0786e-03,\n",
      "          2.4902e-03,  6.2346e-04,  4.5365e-04,  1.3266e-06,  3.2794e-04,\n",
      "          6.1097e-42, -2.6325e-03,  1.1108e-03,  2.8952e-08,  1.4671e-02,\n",
      "          2.4318e-05, -2.0775e-04,  1.5423e-06,  2.2969e-04,  4.5046e-21,\n",
      "          2.8734e-04, -9.6467e-03,  7.2479e-05,  6.7430e-11,  2.7392e-06,\n",
      "          4.4603e-02,  3.7826e-05,  9.4647e-10,  5.6905e-12, -3.3269e-03,\n",
      "          3.9343e-03,  2.8985e-03, -5.2099e-03,  6.3759e-11, -3.5141e-03,\n",
      "          1.1085e-03, -2.1191e-03,  8.5595e-06, -6.2178e-03],\n",
      "        [-1.1279e-03,  1.0543e-04,  1.6612e-03,  3.4101e-05,  2.0064e-05,\n",
      "          3.1949e-03,  1.2260e-03,  3.9997e-03,  2.9635e-03,  4.1801e-03,\n",
      "          3.0246e-18,  6.1391e-04,  1.8425e-04,  9.9576e-06, -9.1689e-04,\n",
      "          7.2249e-05,  1.9875e-05,  1.2135e-03,  1.2557e-04,  4.0164e-03,\n",
      "          5.7576e-03, -6.3479e-10, -9.9287e-07, -1.8478e-03,  1.7606e-03,\n",
      "          4.1317e-07, -1.0264e-02,  3.6387e-03, -1.1257e-02,  2.7415e-04,\n",
      "         -2.1603e-03,  1.0014e-02,  3.1992e-04,  2.4815e-06, -7.5049e-04,\n",
      "          5.8587e-41,  7.6634e-04,  4.6535e-04,  5.2662e-08,  2.2997e-03,\n",
      "          2.3940e-05,  1.5604e-03,  2.8048e-06,  2.3474e-03,  3.3118e-20,\n",
      "         -7.3655e-02,  1.3692e-03,  1.2989e-05,  7.3255e-12, -7.9618e-06,\n",
      "          2.5449e-04, -3.6612e-04,  6.9422e-10,  1.9942e-10,  7.1586e-04,\n",
      "          1.0598e-02,  2.2502e-02, -3.0736e-03,  5.1294e-11,  8.0015e-04,\n",
      "          3.7301e-03,  3.4588e-04,  4.6960e-05,  5.2406e-03],\n",
      "        [ 9.7803e-04, -5.7591e-03,  2.8518e-03, -7.3398e-05,  2.5469e-05,\n",
      "          1.7901e-03,  2.4835e-03,  3.5200e-04,  3.3197e-03, -1.0286e-03,\n",
      "          5.8132e-20,  1.9056e-04,  1.8554e-04,  3.3539e-05,  3.4421e-03,\n",
      "         -1.6499e-02,  4.6298e-05,  3.6397e-03,  2.0179e-05, -2.4890e-03,\n",
      "          2.0947e-04,  7.2090e-12,  1.2930e-08,  4.4958e-03,  2.3325e-04,\n",
      "          7.2660e-07, -5.8211e-03,  7.4462e-04,  3.0254e-02, -1.2488e-03,\n",
      "          3.8391e-03,  1.3244e-04,  1.8818e-03,  6.5810e-06,  5.2162e-04,\n",
      "          2.2190e-41, -1.9189e-03,  3.3726e-03,  1.9136e-07,  1.9461e-03,\n",
      "          5.6933e-06,  3.4045e-04,  1.0193e-05,  9.9102e-04,  2.0472e-20,\n",
      "         -1.7063e-04,  6.7598e-03,  9.5516e-05, -2.4221e-09,  4.9838e-06,\n",
      "         -4.8239e-04, -1.6009e-03,  2.7525e-10,  1.0924e-10,  3.1977e-04,\n",
      "         -1.6310e-02, -3.8442e-02,  3.0997e-02,  1.2784e-10,  6.0948e-03,\n",
      "          1.9830e-03, -1.9069e-03,  2.3035e-05,  7.5605e-04],\n",
      "        [-4.5912e-05,  4.8757e-04,  1.2643e-04,  5.5841e-05,  1.1495e-05,\n",
      "          1.3659e-04, -4.0086e-03,  1.6297e-03,  5.6420e-04,  8.8125e-04,\n",
      "          3.0042e-16,  1.9286e-04, -1.4206e-02,  3.5235e-03,  4.1370e-02,\n",
      "          2.1637e-03,  8.2001e-05,  2.1773e-03,  3.8327e-03,  6.3733e-03,\n",
      "         -1.8607e-03,  2.4579e-13,  3.5993e-08,  3.1144e-04, -1.2892e-02,\n",
      "          1.5482e-07, -9.1971e-04,  2.5765e-02,  1.8947e-05,  3.6488e-04,\n",
      "          2.5485e-02,  8.4330e-04,  1.3146e-03, -2.0034e-05, -6.5345e-03,\n",
      "          2.3262e-41,  3.1501e-03, -2.3027e-02, -7.7443e-07,  6.3521e-04,\n",
      "         -4.2126e-04, -1.5364e-02, -4.2412e-05, -1.6689e-03, -1.2324e-17,\n",
      "          3.5199e-04,  3.9292e-02, -6.4763e-04,  1.5920e-10,  1.0208e-07,\n",
      "         -2.6229e-03,  2.8661e-05,  1.1051e-08,  5.4056e-12, -1.3071e-02,\n",
      "         -3.2830e-04,  6.1126e-03,  4.1686e-04,  1.8591e-10,  4.6347e-04,\n",
      "          1.2427e-02,  1.2250e-04,  3.1720e-06,  7.9513e-03],\n",
      "        [ 8.6165e-04,  1.1891e-02, -5.9651e-03,  6.7274e-05, -1.2139e-04,\n",
      "          5.6340e-04, -1.7675e-02,  1.5725e-03, -1.5175e-02,  2.0766e-02,\n",
      "          4.0862e-14,  1.1383e-04, -8.0797e-03,  1.2325e-05,  6.3148e-03,\n",
      "          3.5843e-03,  4.1690e-06,  8.0564e-04, -3.6879e-03,  8.4207e-03,\n",
      "          2.3316e-04,  1.0453e-13,  1.6824e-09,  5.8055e-04,  1.8235e-03,\n",
      "         -7.2947e-06, -6.8145e-04, -5.1994e-03, -1.8644e-02, -4.0514e-03,\n",
      "         -1.8055e-04,  1.0952e-03, -1.9157e-04,  2.1720e-06,  6.6323e-04,\n",
      "          4.0198e-41,  5.6886e-04, -6.1873e-03,  6.8599e-08,  1.6068e-03,\n",
      "          1.8089e-05,  3.1182e-04,  3.8937e-06,  1.5155e-03,  2.0718e-20,\n",
      "          1.2753e-02, -1.5339e-02,  6.1533e-05,  2.4695e-09,  4.0058e-09,\n",
      "          5.7953e-04,  1.7506e-03, -2.6567e-05, -2.5048e-08,  3.4162e-03,\n",
      "          5.8968e-04,  6.1135e-04, -2.0262e-02,  3.2702e-15, -9.9731e-05,\n",
      "          1.3353e-03,  6.3181e-03,  4.5248e-06,  3.0445e-04],\n",
      "        [ 8.3590e-05,  1.5211e-03,  8.4773e-04,  1.7138e-05,  6.4443e-04,\n",
      "         -9.4895e-03,  7.9392e-03,  2.7951e-03,  3.9809e-03,  5.4222e-03,\n",
      "          2.7446e-20,  2.6707e-05,  2.2772e-02,  1.2406e-06,  1.4238e-04,\n",
      "          2.3956e-03,  2.8610e-07,  7.5274e-04,  4.0841e-05,  9.5999e-04,\n",
      "          3.0001e-03,  3.2045e-14,  1.5596e-11,  1.4300e-04,  1.6838e-02,\n",
      "          1.4031e-07, -2.4844e-03,  5.2618e-04,  9.2018e-07, -1.6985e-04,\n",
      "          8.8030e-04, -1.3556e-03, -5.0838e-03,  6.1005e-08,  5.1764e-03,\n",
      "          3.7975e-43,  2.9285e-05,  1.1486e-04,  2.3927e-10, -1.8018e-02,\n",
      "          5.3103e-06,  1.8788e-02,  9.3153e-07, -1.5259e-03,  7.4597e-25,\n",
      "         -5.0114e-03,  4.8150e-04,  1.1210e-06, -2.8871e-10,  3.5563e-09,\n",
      "         -4.3094e-02,  7.8910e-05,  2.6555e-05,  1.5047e-10,  1.9773e-02,\n",
      "          2.1260e-04,  2.6984e-04,  2.5723e-04,  3.0052e-22,  9.8502e-05,\n",
      "         -9.6666e-04,  4.8448e-05,  3.6815e-07,  6.8641e-05],\n",
      "        [-3.0544e-03,  3.7554e-04,  1.9600e-04, -2.3234e-04,  5.2573e-07,\n",
      "          2.4601e-04,  3.1509e-05,  1.3949e-03,  3.9377e-04, -6.7361e-03,\n",
      "          2.6346e-21, -1.2944e-03,  9.5232e-05,  9.0406e-06,  7.2170e-03,\n",
      "          2.8510e-03, -2.4961e-04,  1.4493e-03,  5.4571e-05,  7.2805e-03,\n",
      "          3.2949e-04,  6.1733e-10,  4.8037e-07,  1.5017e-02,  4.9188e-03,\n",
      "          5.0866e-07, -9.1993e-03,  4.7141e-03, -2.8186e-04,  3.5682e-04,\n",
      "          4.1818e-03, -9.4393e-03,  1.5570e-04, -2.0763e-06,  5.3853e-04,\n",
      "         -2.0982e-40,  5.1340e-05,  2.8537e-03,  6.5580e-08,  3.8495e-03,\n",
      "          9.7204e-05,  2.1208e-04,  3.4928e-06,  2.7584e-04,  1.1974e-17,\n",
      "          4.2425e-04, -4.9946e-03,  1.0017e-04,  1.4705e-12,  1.2567e-07,\n",
      "         -1.2158e-04,  6.3444e-04,  3.7228e-11,  4.3327e-10,  2.6831e-04,\n",
      "          5.1502e-04,  2.3114e-03,  9.1195e-04, -7.4339e-10,  1.1900e-03,\n",
      "          9.0714e-03,  1.3563e-04, -1.1799e-04, -1.1163e-02],\n",
      "        [ 4.6634e-04,  1.6397e-03,  1.1240e-03,  2.6158e-05, -3.5681e-04,\n",
      "          2.5724e-03,  6.3749e-03,  1.5753e-03,  1.5058e-03,  2.0195e-03,\n",
      "          1.0866e-20,  4.2717e-05,  2.6325e-04,  2.5235e-04,  1.4457e-03,\n",
      "          1.9416e-03,  9.8937e-07,  9.1179e-04,  9.9483e-05, -2.5729e-04,\n",
      "          9.2125e-04,  2.8425e-13,  1.1911e-09,  6.8082e-04,  1.3983e-03,\n",
      "          1.7459e-07,  2.3272e-02,  1.2354e-03,  4.7895e-05,  5.0578e-03,\n",
      "          1.6723e-03, -7.3700e-04,  4.8377e-04,  1.2666e-06, -2.8294e-04,\n",
      "          2.3780e-42, -2.1041e-04,  9.5778e-04,  3.1583e-08, -6.5431e-03,\n",
      "          1.9087e-05, -4.9716e-03,  1.6822e-06,  2.4183e-03,  1.0229e-22,\n",
      "          1.7014e-03,  1.1845e-03,  8.0721e-05,  8.8632e-11,  1.0727e-09,\n",
      "          7.4483e-04,  3.1628e-04, -3.2164e-10,  3.9585e-10,  3.1032e-04,\n",
      "          5.6509e-04,  1.5096e-03,  3.7662e-04,  2.1429e-17,  2.6395e-04,\n",
      "          2.1676e-03,  2.2728e-04,  2.4134e-05,  7.8617e-04],\n",
      "        [ 1.1345e-03,  3.2359e-03,  1.8605e-03,  4.4360e-05,  3.6574e-07,\n",
      "          4.3105e-04,  2.4107e-03,  1.9232e-03,  1.2456e-03,  3.6221e-03,\n",
      "          2.1307e-21, -1.2978e-04,  1.0668e-03, -5.5418e-03, -6.0315e-02,\n",
      "          3.4172e-04,  5.8420e-04, -1.1047e-02, -5.8058e-04, -2.9662e-02,\n",
      "          1.7160e-04,  1.3778e-12,  4.5743e-07, -1.6010e-02, -8.8802e-04,\n",
      "          5.1299e-06, -2.2019e-03, -3.2592e-02,  7.9672e-05, -2.7215e-03,\n",
      "         -3.8556e-02,  1.5604e-03,  3.3649e-04,  6.8843e-06,  7.8335e-05,\n",
      "          5.0396e-41,  5.7114e-05,  1.9418e-02,  3.2690e-07, -2.3451e-03,\n",
      "          1.8968e-04,  1.0626e-03,  1.7417e-05, -7.2778e-04,  2.4169e-19,\n",
      "          3.6981e-04, -1.9011e-02,  2.1390e-04,  9.0513e-11,  3.2138e-10,\n",
      "         -2.2816e-04,  3.9303e-04,  1.0763e-11,  4.5653e-10,  4.2132e-04,\n",
      "          2.8941e-04,  1.7965e-03, -2.6072e-04,  3.2005e-10,  5.1979e-03,\n",
      "         -3.1556e-02,  1.9705e-04,  4.4002e-06,  2.1080e-03]]), 'exp_avg_sq': tensor([[2.4164e-05, 1.5559e-04, 4.9004e-04, 4.2817e-03, 4.2696e-03, 5.6991e-05,\n",
      "         7.0878e-04, 2.2812e-03, 4.1725e-04, 1.0499e-02, 1.2936e-05, 8.0487e-04,\n",
      "         1.0903e-02, 5.0636e-06, 6.3305e-05, 7.6545e-04, 6.0395e-05, 3.6449e-04,\n",
      "         1.1528e-05, 4.7764e-04, 1.1837e-02, 4.2758e-06, 2.2903e-06, 1.3890e-04,\n",
      "         3.8392e-04, 1.6142e-06, 6.0205e-04, 2.6468e-05, 7.2946e-06, 3.0632e-04,\n",
      "         2.9315e-04, 2.2921e-04, 9.0373e-04, 3.9224e-05, 2.0212e-04, 2.8421e-10,\n",
      "         1.9488e-04, 1.4723e-04, 1.0936e-04, 8.0113e-05, 2.1675e-05, 1.5725e-03,\n",
      "         1.4320e-04, 7.7003e-03, 5.7100e-06, 1.0897e-02, 9.5812e-05, 2.5235e-05,\n",
      "         1.6631e-05, 1.4318e-06, 9.2698e-05, 2.4159e-04, 1.5199e-05, 2.6125e-06,\n",
      "         8.6782e-04, 3.5281e-04, 6.5236e-05, 1.3798e-03, 9.2791e-08, 1.5916e-04,\n",
      "         9.3519e-05, 9.0455e-05, 1.1131e-05, 1.2766e-03],\n",
      "        [3.8587e-04, 1.4561e-04, 1.3880e-04, 1.7641e-05, 1.3557e-04, 6.7983e-03,\n",
      "         8.5566e-03, 3.0924e-04, 2.6288e-04, 2.4972e-05, 5.4221e-06, 1.4623e-04,\n",
      "         2.8628e-05, 1.6132e-04, 9.1792e-05, 2.5228e-03, 6.9330e-03, 5.2217e-04,\n",
      "         2.0897e-05, 3.0695e-04, 4.2437e-05, 6.0857e-06, 8.2916e-06, 5.9907e-04,\n",
      "         2.1935e-04, 5.2916e-07, 7.7861e-03, 1.3107e-04, 4.8548e-05, 6.3602e-04,\n",
      "         3.9591e-04, 5.4950e-04, 8.4956e-05, 5.5988e-06, 1.6118e-04, 1.4550e-11,\n",
      "         3.7867e-03, 9.7725e-05, 4.9165e-07, 7.7912e-03, 2.6635e-06, 5.5492e-04,\n",
      "         6.8113e-05, 2.1415e-04, 4.1019e-07, 1.1067e-04, 8.8134e-03, 1.5215e-04,\n",
      "         8.7193e-06, 1.1796e-06, 7.8883e-03, 9.6584e-06, 5.7494e-05, 1.5763e-05,\n",
      "         1.4339e-04, 3.8076e-03, 4.4477e-03, 1.6352e-04, 3.9365e-07, 5.3115e-04,\n",
      "         3.2113e-04, 1.9658e-04, 5.0106e-06, 2.9971e-03],\n",
      "        [8.7349e-04, 2.3135e-04, 2.6037e-04, 8.6410e-06, 7.6225e-04, 7.8016e-04,\n",
      "         8.6167e-04, 1.2492e-03, 3.8084e-04, 5.5150e-04, 7.7308e-06, 3.1419e-04,\n",
      "         1.8014e-03, 5.4168e-06, 3.2804e-05, 1.5210e-02, 1.8171e-04, 1.1814e-02,\n",
      "         7.8643e-05, 6.6446e-04, 6.4680e-04, 9.3659e-05, 5.1863e-04, 1.1150e-02,\n",
      "         6.9256e-04, 2.6569e-05, 1.5326e-02, 6.4267e-04, 3.4477e-04, 2.5281e-03,\n",
      "         4.6229e-04, 3.1563e-03, 5.0051e-05, 1.5863e-04, 2.2743e-03, 9.8059e-07,\n",
      "         1.2086e-02, 8.6680e-05, 3.5019e-05, 4.5565e-04, 9.2292e-05, 1.5800e-03,\n",
      "         2.9017e-05, 1.3727e-03, 6.8679e-06, 6.3272e-03, 7.8440e-04, 3.1849e-05,\n",
      "         3.4480e-05, 1.5630e-05, 3.4464e-04, 4.5204e-05, 3.0621e-03, 1.6238e-06,\n",
      "         3.5814e-03, 7.5220e-03, 2.9363e-03, 1.3859e-03, 4.6726e-06, 8.8095e-04,\n",
      "         2.9528e-03, 1.9689e-03, 1.8962e-04, 6.4042e-04],\n",
      "        [1.6313e-03, 5.7322e-03, 1.2792e-02, 1.2909e-05, 7.4644e-05, 2.7810e-04,\n",
      "         2.1825e-03, 6.4218e-05, 3.1835e-03, 1.1975e-03, 7.9596e-06, 2.0242e-04,\n",
      "         2.0739e-04, 1.0373e-06, 1.3368e-03, 2.7470e-03, 3.8988e-04, 4.6680e-03,\n",
      "         3.8751e-05, 4.5940e-03, 1.4962e-04, 1.6152e-04, 2.2023e-04, 5.1635e-03,\n",
      "         6.4286e-05, 9.9271e-06, 5.5220e-03, 9.1891e-05, 2.0917e-03, 5.1408e-03,\n",
      "         1.1389e-03, 5.9105e-04, 2.6039e-03, 1.1157e-04, 1.7617e-04, 1.6455e-11,\n",
      "         5.1003e-03, 6.9596e-04, 3.7354e-05, 1.6628e-04, 7.4673e-05, 5.3079e-04,\n",
      "         1.8227e-05, 2.0775e-04, 1.0798e-06, 2.2224e-03, 4.2448e-04, 3.2899e-05,\n",
      "         2.2465e-06, 4.6429e-06, 1.2599e-04, 6.5327e-04, 4.7178e-06, 1.5826e-05,\n",
      "         1.0118e-03, 1.8432e-03, 1.2135e-02, 4.9859e-03, 5.5584e-06, 1.5345e-02,\n",
      "         6.4265e-03, 5.6669e-03, 4.7562e-05, 4.9257e-04],\n",
      "        [3.3014e-04, 4.8402e-05, 4.1317e-05, 6.2709e-06, 9.0085e-04, 2.3317e-04,\n",
      "         1.1321e-03, 4.9914e-03, 1.4513e-04, 4.8733e-05, 1.4850e-05, 3.6200e-03,\n",
      "         1.9137e-03, 1.8203e-05, 3.6546e-03, 4.3683e-04, 1.3802e-04, 6.5039e-04,\n",
      "         6.0821e-04, 1.5325e-03, 2.4236e-04, 7.1910e-06, 2.1294e-04, 3.5259e-04,\n",
      "         4.8553e-03, 3.2577e-05, 3.2449e-04, 7.9946e-03, 6.4820e-07, 1.8158e-04,\n",
      "         9.2142e-03, 2.2787e-04, 8.3153e-05, 9.6754e-05, 7.4774e-03, 9.8169e-07,\n",
      "         3.5174e-04, 8.7753e-03, 3.8230e-05, 5.7265e-03, 3.4879e-05, 5.3198e-03,\n",
      "         4.6136e-04, 5.1934e-03, 4.3138e-06, 2.3609e-04, 1.5536e-02, 2.5896e-05,\n",
      "         1.3583e-03, 3.5339e-07, 3.6742e-04, 7.7368e-06, 3.8906e-05, 9.8683e-06,\n",
      "         1.9202e-03, 1.8554e-04, 2.8577e-04, 1.0176e-04, 9.7532e-07, 1.7562e-05,\n",
      "         1.1038e-03, 7.7931e-06, 1.3094e-05, 7.2228e-04],\n",
      "        [3.1145e-04, 7.3497e-03, 1.5531e-02, 4.4441e-03, 3.8136e-03, 4.9348e-04,\n",
      "         1.8772e-02, 2.0943e-03, 1.2333e-02, 1.1015e-02, 7.4249e-06, 3.2444e-04,\n",
      "         2.4073e-03, 2.9479e-07, 1.8238e-03, 3.6008e-04, 1.9831e-04, 1.9424e-04,\n",
      "         5.2191e-05, 4.7311e-03, 2.9817e-03, 1.9319e-06, 5.5457e-06, 6.3013e-04,\n",
      "         2.3417e-04, 1.7613e-06, 6.3445e-04, 1.6621e-04, 9.7612e-04, 1.3269e-03,\n",
      "         5.1305e-04, 2.3724e-04, 8.8587e-03, 1.1898e-04, 8.9317e-04, 2.6590e-09,\n",
      "         1.3051e-04, 2.7351e-04, 7.1842e-06, 5.0460e-04, 4.7999e-06, 6.8255e-03,\n",
      "         5.3463e-04, 3.9659e-04, 3.3184e-07, 8.5956e-04, 4.3205e-04, 3.6133e-05,\n",
      "         1.8923e-04, 4.9614e-06, 3.3949e-04, 1.0495e-03, 2.0700e-04, 1.1520e-05,\n",
      "         2.8843e-03, 1.8133e-04, 5.6089e-03, 1.8066e-03, 2.0722e-06, 1.1993e-02,\n",
      "         7.4974e-04, 2.7766e-03, 4.6744e-05, 1.6356e-04],\n",
      "        [2.6879e-05, 6.1430e-04, 8.0586e-04, 6.8625e-06, 6.3279e-03, 4.8947e-04,\n",
      "         1.9013e-02, 1.2145e-02, 1.2341e-03, 1.8458e-03, 5.7258e-05, 1.1582e-04,\n",
      "         1.4309e-02, 6.4429e-07, 4.7125e-05, 7.6980e-03, 3.2862e-05, 2.4731e-04,\n",
      "         4.6082e-05, 3.2475e-04, 1.9050e-03, 4.7876e-06, 2.5992e-06, 2.3457e-05,\n",
      "         1.0385e-03, 4.0828e-06, 4.9824e-04, 4.5297e-04, 1.2199e-05, 1.3741e-04,\n",
      "         1.2760e-04, 1.6559e-04, 2.2031e-03, 2.0861e-06, 2.2734e-03, 7.5066e-11,\n",
      "         8.8238e-04, 2.3420e-05, 6.7687e-06, 9.3732e-04, 5.4162e-06, 1.5915e-02,\n",
      "         1.3420e-03, 2.3563e-03, 6.8302e-07, 2.2981e-03, 1.7282e-04, 8.3618e-05,\n",
      "         1.2795e-03, 4.1999e-06, 1.7416e-03, 3.0051e-04, 3.3097e-03, 1.2884e-06,\n",
      "         8.1157e-03, 1.3881e-04, 2.3500e-05, 1.7407e-04, 2.2427e-07, 1.6615e-05,\n",
      "         6.9270e-06, 5.4169e-06, 1.9349e-05, 4.5128e-06],\n",
      "        [5.0843e-03, 1.2056e-05, 7.7608e-05, 4.4238e-07, 3.6010e-05, 7.6961e-04,\n",
      "         4.6192e-04, 1.4441e-04, 7.4425e-05, 1.9038e-03, 5.2849e-06, 4.1401e-03,\n",
      "         3.4912e-04, 6.1149e-06, 1.7145e-03, 1.4852e-03, 1.3541e-03, 8.4019e-03,\n",
      "         9.8086e-05, 1.4835e-02, 1.6850e-03, 1.6450e-04, 6.5570e-04, 1.1556e-02,\n",
      "         9.1652e-04, 1.3033e-05, 1.5697e-03, 1.3320e-03, 2.8942e-04, 8.6521e-05,\n",
      "         2.2637e-03, 7.3743e-04, 2.0854e-04, 1.0903e-03, 5.9329e-04, 3.3587e-09,\n",
      "         1.1817e-03, 2.2900e-03, 8.7853e-05, 1.0963e-03, 3.2603e-04, 3.6227e-05,\n",
      "         1.8476e-04, 9.6693e-04, 6.4800e-06, 2.8987e-04, 3.5510e-03, 4.4714e-05,\n",
      "         2.1768e-06, 1.2286e-05, 3.2108e-03, 1.9310e-04, 4.4242e-05, 2.5936e-06,\n",
      "         3.5847e-05, 2.5237e-03, 1.4915e-03, 1.8955e-04, 1.6115e-05, 4.8602e-04,\n",
      "         1.1438e-02, 1.4020e-04, 2.5649e-04, 6.1717e-03],\n",
      "        [1.0891e-04, 7.6459e-04, 1.2062e-03, 2.6042e-06, 5.1874e-04, 5.0040e-03,\n",
      "         3.8758e-03, 1.7160e-03, 1.0466e-02, 1.2049e-03, 1.4538e-05, 8.4335e-05,\n",
      "         5.5011e-04, 1.5327e-04, 5.6150e-04, 8.3712e-04, 5.7238e-03, 3.1252e-04,\n",
      "         1.4978e-05, 7.8303e-04, 6.0714e-04, 1.3621e-05, 4.1742e-06, 2.5527e-04,\n",
      "         1.1156e-04, 4.3493e-07, 8.8517e-03, 1.2171e-04, 5.6126e-04, 6.3933e-03,\n",
      "         5.8039e-03, 4.5366e-03, 2.9123e-03, 2.5333e-06, 2.8578e-04, 4.6301e-10,\n",
      "         3.8033e-04, 6.2766e-04, 2.9803e-06, 1.1533e-03, 5.8022e-07, 6.4181e-03,\n",
      "         6.5587e-05, 5.5509e-04, 8.7293e-07, 1.4502e-03, 1.2992e-03, 1.5177e-04,\n",
      "         3.4890e-06, 3.8776e-06, 1.9870e-03, 1.1059e-04, 3.4291e-05, 2.2495e-07,\n",
      "         4.5465e-04, 4.1793e-04, 8.5964e-04, 1.3323e-03, 3.5328e-07, 4.8181e-04,\n",
      "         4.1762e-04, 2.4789e-04, 1.1756e-05, 1.2546e-04],\n",
      "        [2.2024e-03, 2.9902e-04, 1.9882e-03, 1.8885e-05, 9.8413e-06, 3.6813e-04,\n",
      "         6.4192e-04, 5.0374e-04, 7.0906e-04, 2.1616e-03, 8.7569e-06, 1.1760e-03,\n",
      "         1.1912e-03, 3.7721e-05, 8.6972e-03, 1.7531e-05, 2.6118e-04, 6.7387e-04,\n",
      "         4.6890e-04, 1.5202e-02, 5.4383e-03, 6.6620e-06, 1.9690e-04, 1.8621e-03,\n",
      "         1.6581e-03, 1.1339e-05, 2.8631e-04, 7.0603e-03, 1.3334e-05, 1.0759e-03,\n",
      "         1.5021e-02, 3.3081e-04, 6.6050e-04, 6.8880e-04, 2.8214e-03, 4.5196e-10,\n",
      "         4.2421e-05, 1.2701e-02, 4.4204e-05, 7.8267e-04, 9.9904e-05, 3.1756e-04,\n",
      "         1.0566e-04, 3.2786e-03, 6.5071e-06, 2.0823e-03, 1.2363e-02, 2.8420e-06,\n",
      "         6.0493e-06, 1.4831e-06, 2.7018e-04, 4.4944e-05, 3.4502e-05, 2.0980e-05,\n",
      "         1.6774e-04, 3.1850e-05, 1.8613e-03, 1.0287e-03, 6.3262e-06, 1.1435e-03,\n",
      "         4.6527e-03, 2.1994e-04, 1.7640e-05, 6.2338e-03]])}, 139900461525608: {'step': 4690, 'exp_avg': tensor([-1.3817e-03, -1.5057e-03,  5.2111e-03,  1.2903e-03,  4.3707e-03,\n",
      "        -8.3946e-05, -1.6424e-03, -1.2887e-03,  5.8877e-04, -5.5585e-03]), 'exp_avg_sq': tensor([1.1082e-04, 9.8747e-05, 2.1626e-04, 2.3502e-04, 1.9139e-04, 2.0084e-04,\n",
      "        1.3883e-04, 1.6299e-04, 2.7077e-04, 2.8351e-04])}}\n",
      "param_groups \t [{'lr': 0.01, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [139900461526256, 139900461526328, 139900461525392, 139900461526112, 139900461526040, 139900461525248, 139900461525680, 139900461525608]}]\n"
     ]
    }
   ],
   "source": [
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gjnCMjxF5_R8"
   },
   "source": [
    "#  Try Running the below codes on  Kaggle Kernel\n",
    "\n",
    "[Check for reference](https://www.kaggle.com/u6yuvi/digit-recognizer-pytorch/output?scriptVersionId=16485375)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "98bee7eaf09d225730006f2b24ca5662d28cfb65",
    "colab_type": "text",
    "id": "BSWPI5_K4DCk"
   },
   "source": [
    "# Kaggle- Multilayered Perceptron (MLP) implemention on MNIST dataset\n",
    "Untill now we were using the MNIST dataset that is available in torchvision.dataset.Let us now load the dataset from Kaggle repo and train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_uuid": "4e83a9e422c10eb07cbfb779be01803d2b8a5334",
    "colab": {},
    "colab_type": "code",
    "id": "DtAM0yxR4DCl"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset ,DataLoader\n",
    "from torch import nn,optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "PATH=Path(\"../input/digit-recognizer\")\n",
    "print(os.listdir(\"../input/digit-recognizer\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "661e23266c2c882d34cdae4c9074d26c0d2ac040",
    "colab_type": "text",
    "id": "Gj48dSJg4DCm"
   },
   "source": [
    "## Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_uuid": "72b61aac15c29fc295d77130b07d1110c9cb1825",
    "colab": {},
    "colab_type": "code",
    "id": "mdn255g54DCm"
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv(PATH/'train.csv')\n",
    "test=pd.read_csv(PATH/'test.csv')\n",
    "train.shape,test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6d5eb02dbfc5e385ffd113560494e0b2275e5f66",
    "colab_type": "text",
    "id": "Hf9bGVDH4DCn"
   },
   "source": [
    "## Extracting Input and Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_uuid": "858a074c0e1dea92562d0f1bd93ff5302f861643",
    "colab": {},
    "colab_type": "code",
    "id": "XF2vEl_t4DCo"
   },
   "outputs": [],
   "source": [
    "x=train.drop(\"label\",axis=1)\n",
    "y=np.array(train['label'])\n",
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "387109d77b8c6f76d4de868158340faf1a38b2dc",
    "colab_type": "text",
    "id": "TUVHsCvR4DCp"
   },
   "source": [
    "## Normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_uuid": "b8ff683f50227c31ee39ec05a7bb8b4e2a8c5f94",
    "colab": {},
    "colab_type": "code",
    "id": "BFgs691V4DCp"
   },
   "outputs": [],
   "source": [
    "#x_train=x/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "614e6245bdf2e3372dca00d5111b3fbe8e993a64",
    "colab_type": "text",
    "id": "R5TxccEk4DCq"
   },
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_uuid": "65e189e8b8c6232146d0dde1fceb773353ad8389",
    "colab": {},
    "colab_type": "code",
    "id": "iPIQfMjR4DCr"
   },
   "outputs": [],
   "source": [
    "#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8f37069db924850a07cd3e98378ae9c61bab1f8f",
    "colab_type": "text",
    "id": "0c7XjTMH4DCs"
   },
   "source": [
    "## Train Test in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_uuid": "709aaea373c664fad6fd42d8779ae091145b8308",
    "colab": {},
    "colab_type": "code",
    "id": "Jst9e0mK4DCs"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# create feature and targets tensor for train set.\n",
    "torch_X_train = torch.from_numpy(x_train.values).type(torch.FloatTensor)\n",
    "torch_y_train = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "\n",
    "# create feature and targets tensor for test set.\n",
    "torch_X_test = torch.from_numpy(x_test.values).type(torch.FloatTensor)\n",
    "torch_y_test = torch.from_numpy(y_test).type(torch.LongTensor)\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train = torch.utils.data.TensorDataset(torch_X_train,torch_y_train)\n",
    "test = torch.utils.data.TensorDataset(torch_X_test,torch_y_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_uuid": "80525db377fe319e7a3fc538ef8b76639c28c995",
    "colab": {},
    "colab_type": "code",
    "id": "Rk2ZdrHj4DCu"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "BATCH_SIZE=64\n",
    "# data loader\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = BATCH_SIZE, shuffle = False)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size = BATCH_SIZE, shuffle = False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "454f4fb8e0a416e60aed471a49850c01a64a77e6",
    "colab_type": "text",
    "id": "0ZOWCRtq4DCw"
   },
   "source": [
    "## Train -Test Split -Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_uuid": "d616496f4e453322efe8aecfa71b17fcdddaa8dd",
    "colab": {},
    "colab_type": "code",
    "id": "ni3rH-Pi4DCw"
   },
   "outputs": [],
   "source": [
    "torch_X_train = torch.from_numpy(x.values).type(torch.FloatTensor)/255\n",
    "torch_y_train = torch.from_numpy(y).type(torch.LongTensor)\n",
    "myDataset = torch.utils.data.TensorDataset(torch_X_train,torch_y_train)\n",
    "valid_no  = int(0.2 * len(myDataset))\n",
    "# so divide the data into trainset and testset\n",
    "trainSet,testSet = torch.utils.data.random_split(myDataset,(len(myDataset)-valid_no,valid_no))\n",
    "print(f\"len of trainSet {len(trainSet)} , len of testSet {len(testSet)}\")\n",
    "batch_size=64\n",
    "train_loader  = DataLoader(trainSet , batch_size=batch_size ,shuffle=True) \n",
    "test_loader  = DataLoader(testSet , batch_size=batch_size ,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a06249ad57104d74d0258fd5972961f720bdc3cf",
    "colab_type": "text",
    "id": "DhlKN0Y34DCy"
   },
   "source": [
    "trainData = torch.from_numpy(x_train.values)\n",
    "trainLabel=torch.from_numpy(y_train)\n",
    "testData = torch.from_numpy(x_test.values)\n",
    "testLabel = torch.from_numpy(y_test)\n",
    "trainData, testData = trainData.type(torch.FloatTensor), testData.type(torch.LongTensor)\n",
    "trainLabel, testLabel = trainLabel.type(torch.FloatTensor), testLabel.type(torch.LongTensor)\n",
    "trainData.shape,testData.shape\n",
    "trainData = trainData.unsqueeze_(dim=1)\n",
    "testData = testData.unsqueeze_(dim=1)\n",
    "trainData.shape,testData.shape\n",
    "transforms =transforms.Compose(transforms.ToTensor())\n",
    "train_dataset = TensorDataset(trainData,trainLabel)\n",
    "train_loader = DataLoader(train_dataset,batch_size=64,shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(testData,testLabel)\n",
    "test_loader = DataLoader(test_dataset,batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "97b2925a24f59b10a16864a76f00e02a4c92b36f",
    "colab_type": "text",
    "id": "_hGrdIVq4DCy"
   },
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_uuid": "8cbe1c508bacadbb875014318a35fed17ab6a3a1",
    "colab": {},
    "colab_type": "code",
    "id": "nW1wypfS4DCy"
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "        # Dropout module with 0.2 drop probability\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # make sure input tensor is flattened\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        # Now with dropout\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "\n",
    "        # output so no dropout here\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "\n",
    "        return x\n",
    "        \n",
    "model=Network()\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.01)\n",
    "criterion=nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2bea512cd5bd9f4f41bd77044f471e644505a5fa",
    "colab_type": "text",
    "id": "wr91w0-X4DCz"
   },
   "source": [
    "## Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_uuid": "2df4882ed86f9b17b4bba52d56adfde46d1f718d",
    "colab": {},
    "colab_type": "code",
    "id": "9x_1PS6x4DC0"
   },
   "outputs": [],
   "source": [
    "epochs=5\n",
    "train_losses,test_losses=[],[]\n",
    "for e in range(epochs):\n",
    "    running_loss=0\n",
    "    for images,labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        log_ps=model(images)\n",
    "        loss=criterion(log_ps,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss+=loss.item()\n",
    "        \n",
    "    else:\n",
    "        test_loss=0\n",
    "        accuracy=0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for images,labels in test_loader:\n",
    "                log_ps=model(images)\n",
    "                test_loss+=criterion(log_ps,labels)\n",
    "                ps=torch.exp(log_ps)\n",
    "                top_p,top_class=ps.topk(1,dim=1)\n",
    "                equals=top_class==labels.view(*top_class.shape)\n",
    "                accuracy+=torch.mean(equals.type(torch.FloatTensor))\n",
    "        model.train()\n",
    "        train_losses.append(running_loss/len(train_loader))\n",
    "        test_losses.append(test_loss/len(test_loader))\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9373aea13cc5891684fb8b801cbcd0ac17eff458",
    "colab_type": "text",
    "id": "_vC0Y7z34DC1"
   },
   "source": [
    "## Save our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_uuid": "bfcc3f17cadca0bf48cec130586b907965905ed6",
    "colab": {},
    "colab_type": "code",
    "id": "5gmUDHdA4DC2"
   },
   "outputs": [],
   "source": [
    "print(\"Our model: \\n\\n\", model, '\\n')\n",
    "print(\"The state dict keys: \\n\\n\", model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_uuid": "f83335753469344d38ac362053a74fad30b0ca3e",
    "colab": {},
    "colab_type": "code",
    "id": "5xfl0hTJ4DC3"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "70b1a508fd748a8823a9e1af57538e4cacb0621d",
    "colab_type": "text",
    "id": "9zyso_in4DC4"
   },
   "source": [
    "## Load our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_uuid": "abd854b1c8bfed532cb4e64578c40fd29dea9a36",
    "colab": {},
    "colab_type": "code",
    "id": "nnS5Suqe4DC4"
   },
   "outputs": [],
   "source": [
    "state_dict = torch.load('checkpoint.pth')\n",
    "print(state_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_uuid": "7a889737952161eb1834f521476f0f1c8448570a",
    "colab": {},
    "colab_type": "code",
    "id": "0iHEd3Nk4DC6"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_uuid": "a08eff1adeb3a8f8f7a31356828ee732a557c3d5",
    "colab": {},
    "colab_type": "code",
    "id": "EOVzZilI4DC7"
   },
   "outputs": [],
   "source": [
    "checkpoint = {'input_size': 784,\n",
    "              'output_size': 10,\n",
    "              'hidden_layers': [256,128,64],\n",
    "              'state_dict': model.state_dict()}\n",
    "\n",
    "torch.save(checkpoint, 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b3356c9580d6c01685a52a11f906ee1c9dbe7ef1",
    "colab_type": "text",
    "id": "B-j6vcfk4DC9"
   },
   "source": [
    "## Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_uuid": "34abb15aa48ad4f133ee15a2f9a5268b45692c36",
    "colab": {},
    "colab_type": "code",
    "id": "8oA5JqIJ4DC9"
   },
   "outputs": [],
   "source": [
    "test_images = pd.read_csv(\"../input/digit-recognizer/test.csv\")\n",
    "test_image = test_images.loc[:,test_images.columns != \"label\"].values\n",
    "test_dataset = torch.from_numpy(test_image).type(torch.FloatTensor)/255\n",
    "print(test_dataset.shape)\n",
    "#test_dataset = torch.utils.data.TensorDataset(test_dataset)\n",
    "new_test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 100, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_uuid": "790dd7f94c59a6de5441827b999b6cff6f686154",
    "colab": {},
    "colab_type": "code",
    "id": "dwpwU0h04DC-"
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for images in new_test_loader:\n",
    "        output = model(images)\n",
    "        ps = torch.exp(output)\n",
    "        top_p, top_class = ps.topk(1, dim = 1)\n",
    "        results += top_class.numpy().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0f9b334b1c25c4bb1a48fda6b64634f1f90b7565",
    "colab_type": "text",
    "id": "4ZwCEHs24DC_"
   },
   "source": [
    "## Check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_uuid": "56ffd3051274596232af3ca4d1a9ee7d6322881a",
    "colab": {},
    "colab_type": "code",
    "id": "iJ2mowPf4DDA"
   },
   "outputs": [],
   "source": [
    "predictions = np.array(results).flatten()\n",
    "print(predictions[:5])\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f946013a3eab6274d1becd93dfe99aa9f7491cf9",
    "colab_type": "text",
    "id": "dMLPVy7c4DDB"
   },
   "source": [
    "## Submit for Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_uuid": "655160a6e2d490651c0fe70b8ba7480ed8ba1fcc",
    "colab": {},
    "colab_type": "code",
    "id": "xFG3HrNH4DDC"
   },
   "outputs": [],
   "source": [
    "submissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n",
    "                         \"Label\": predictions})\n",
    "submissions.to_csv(\"my_submissions.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "177c548a264bbaaa76e216eeaf1d747db88b1030",
    "colab_type": "text",
    "id": "psW9Ie4t4DDF"
   },
   "source": [
    "# Reference\n",
    "\n",
    "[Introduction to Pytorch-Udacity](https://github.com/udacity/deep-learning-v2-pytorch/tree/master/intro-to-pytorch)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "DL with Pytorch-MNIST Classification.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
